[
  {
    "objectID": "lectures/lecture-15-content.html",
    "href": "lectures/lecture-15-content.html",
    "title": "API Example: OpenAlexR",
    "section": "",
    "text": "Use the “Polite Pool” if you have an API Key!\n\nOur goal will be to retrieve publications by researchers at Memorial University who have authored more than 10 publications (indexed in OpenAlex) using the OpenAlex API, and to begin working with the data objects returned from the API.\n\nNote that some of the code in this notebook will take some time to run, especially when downloading data. Be patient, and change the query parameters if you must.\n\nWe’ll load the openalexR and tidyverse packages. Don’t forget to install openalexR in your PostCloud if you haven’t already done so!\n\nlibrary(openalexR)\n\nThank you for using openalexR!\nTo acknowledge our work, please cite the package by calling `citation(\"openalexR\")`.\nTo suppress this message, add `openalexR.message = suppressed` to your .Renviron file.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\n\n\n\nTo start, we need to find Memorial’s “Institutional ID”. We can do this by using the OpenAlex website.\n\n\n\nOpenAlex search\n\n\nClick on the Institution button and start typing “Memorial University” into the OpenAlex search.\n\n\n\nSearch for Memorial University under “Institution”\n\n\nTake a moment to review the results page – it’s the same page we saw when searching authors and topics in previous classes, only this time it’s for all of Memorial University. As of March 2025, there are almost 50,000 indexed publications.\n\n\n\nThe results page\n\n\nClick on “Memorial University” in the search field.\n\n\n\nFinding an Institutional ID\n\n\nYou should see an Institution ID under “Memorial University of Newfoundland.” I’ve highlighted it below to make it easier to see. This is the number we want to use when we query the OpenAlexAPI!\n\n\n\nCopying the Institutional ID for an API query\n\n\nYou can click to view MUN’s “Institutional Profile” on Open Alex.\n\n\n\nAn OpenAlex institution profile page\n\n\n\n\n\nNow we know that Memorial’s Institutional ID is i130438778. We can use this to setup an API query. Let’s start by creating a list with our query parameters.\nRecall that a list in R is like a container that holds several pieces of information. In this case, our list will contain three key-value pairs:\n\nentity = \"authors\" tells the API that we are interested in data about authors.\nlast_known_institutions.id = \"i130438778\" specifies that we want authors who are or were affiliated with a particular institution (identified by “i130438778”).\nworks_count = \"&gt;10\" means we want authors who have more than 10 published works.\n\nLet’s set it up!\n\nmy_arguments &lt;- list(\n    entity = \"authors\",\n    last_known_institutions.id = \"i130438778\",\n    works_count = \"&gt;10\"\n)\n\nNow let’s we’ll make an API call!\n\ndo.call(oa_fetch, c(my_arguments, list(count_only = TRUE)))\n\n     count db_response_time_ms page per_page\n[1,]  2307                 169    1        1\n\n\ndo.call() is a function that calls another function – in this case oa_fetch – using a list of arguments.\nHere, we combine our my_arguments list with an extra argument list(count_only = TRUE). This tells the function oa_fetch to only return a count (the number of matching records) instead of all the detailed information OpenAlex has about our search results. Essentially, we’re asking the API: “How many authors match these criteria?”\nSo now we’ve defined the search criteria for authors in a list, and we’ve checked if there are any authors matching the criteria by asking for just a count. If there are results (i.e., there is 1 or more authors in the OpenAlex database), then we can make another request to collect detailed information for those authors.\nRun the code block below.\n\nif (do.call(oa_fetch, c(my_arguments, list(count_only = TRUE)))[1] &gt; 0) {\n    do.call(oa_fetch, my_arguments) |&gt;\n        show_authors() |&gt;\n        knitr::kable()\n}\n\nWarning: Unknown or uninitialised column: `name`.\n\n\nWarning: Unknown or uninitialised column: `display_name`.\n\n\nWarning: Unknown or uninitialised column: `name`.\n\n\nWarning: Unknown or uninitialised column: `display_name`.\n\n\nWarning: Unknown or uninitialised column: `name`.\n\n\nWarning: Unknown or uninitialised column: `display_name`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ndisplay_name\norcid\nworks_count\ncited_by_count\naffiliation_display_name\ntop_concepts\n\n\n\n\nA5026509039\nFereidoon Shahidi\n0000-0002-9912-0330\n1113\n79559\nMemorial University of Newfoundland\nBiochemistry, Animal Science and Zoology, Molecular Biology\n\n\nA5077149719\nOctavia A. Dobre\n0000-0001-8528-0512\n949\n20777\nMemorial University of Newfoundland\nElectrical and Electronic Engineering, Electrical and Electronic Engineering, Electrical and Electronic Engineering\n\n\nA5010428924\nDavid C. Schneider\n0000-0003-4771-2155\n798\n6532\nMemorial University of Newfoundland\nGlobal and Planetary Change, Insect Science, Ecology, Evolution, Behavior and Systematics\n\n\nA5049089848\nTrung Q. Duong\n0000-0002-4703-4836\n726\n18629\nMemorial University of Newfoundland\nElectrical and Electronic Engineering, Computer Networks and Communications, Electrical and Electronic Engineering\n\n\nA5032069177\nIan Fleming\n0000-0002-5541-824X\n701\n23299\nMemorial University of Newfoundland\nOrganic Chemistry, Organic Chemistry, Nature and Landscape Conservation\n\n\nA5102982237\nRobert A. Brown\n0000-0003-2350-110X\n528\n18534\nMemorial University of Newfoundland\nMaterials Chemistry, Astronomy and Astrophysics, Astronomy and Astrophysics\n\n\n\n\n\nIn the code above, we check if the count returned by the previous call is greater than zero by using an if statement. Then do.call(oa_fetch, c(my_arguments, list(count_only = TRUE)))[1] retrieves the first element of the result, which is the number of matching authors. If that number is greater than 0 (meaning there is at least one author that meets the criteria), then the code inside the if block ({ ... }) block will run.\nInside the if block, do.call(oa_fetch, my_arguments) calls the oa_fetch function again with our original arguments, only this time we don’t use count_only = TRUE. This tells to API to fetch all the details of the matching authors. We then use the pipe operator |&gt; to pass the results of that function on to the next function, show_authors(). The show_authors() function formats or selects relevant author information. Finally, we pass the formatted data to knitr::kable(), which converts it into a nicely formatted table.\n\n\n\nSo far our code fetches data and processes it for display, but it doesn’t retain the data in memory or write it to disk. If we want to keep it in memory and analyze that data in some way, we need to assign the result to a variable. Recall from previous classes that we want to minimize our APIs calls to be considerate of the servers providing our data.\nLet’s do that now, making yet another API call.\n\nauthors_data &lt;- do.call(oa_fetch, my_arguments)\n\nNow our data in stored in authors_data. Let’s take a look at the column names.\n\nnames(authors_data)\n\n [1] \"id\"                        \"display_name\"             \n [3] \"display_name_alternatives\" \"ids\"                      \n [5] \"orcid\"                     \"works_count\"              \n [7] \"cited_by_count\"            \"counts_by_year\"           \n [9] \"affiliation_display_name\"  \"affiliation_id\"           \n[11] \"affiliation_ror\"           \"affiliation_country_code\" \n[13] \"affiliation_type\"          \"affiliation_lineage\"      \n[15] \"affiliations_other\"        \"topics\"                   \n[17] \"works_api_url\"            \n\n\nThere are 17 variables for us to work with here! We’ll focus on a few today, including display_name, cited_by_count, works_count, counts_by_year, and topics.\nWe can print a preview of the tibble like any other. Let’s print 30 rows:\n\nprint(authors_data, n = 30)\n\n# A tibble: 2,307 × 17\n   id                display_name display_name_alterna…¹ ids   orcid works_count\n   &lt;chr&gt;             &lt;chr&gt;        &lt;list&gt;                 &lt;lis&gt; &lt;chr&gt;       &lt;int&gt;\n 1 https://openalex… Fereidoon S… &lt;chr [3]&gt;              &lt;chr&gt; http…        1113\n 2 https://openalex… Octavia A. … &lt;chr [7]&gt;              &lt;chr&gt; http…         949\n 3 https://openalex… David C. Sc… &lt;chr [6]&gt;              &lt;chr&gt; http…         798\n 4 https://openalex… Trung Q. Du… &lt;chr [5]&gt;              &lt;chr&gt; http…         726\n 5 https://openalex… Ian Fleming  &lt;chr [8]&gt;              &lt;chr&gt; http…         701\n 6 https://openalex… Robert A. B… &lt;chr [6]&gt;              &lt;chr&gt; http…         528\n 7 https://openalex… Weimin Huang &lt;chr [10]&gt;             &lt;chr&gt; http…         525\n 8 https://openalex… Laurence K.… &lt;chr [6]&gt;              &lt;chr&gt; &lt;NA&gt;          523\n 9 https://openalex… G.F. Naterer &lt;chr [4]&gt;              &lt;chr&gt; http…         523\n10 https://openalex… Proton Rahm… &lt;chr [5]&gt;              &lt;chr&gt; http…         492\n11 https://openalex… David G. Be… &lt;chr [6]&gt;              &lt;chr&gt; http…         485\n12 https://openalex… David Molyn… &lt;chr [6]&gt;              &lt;chr&gt; http…         478\n13 https://openalex… Lynn H. Ger… &lt;chr [13]&gt;             &lt;chr&gt; http…         454\n14 https://openalex… M. P. Searle &lt;chr [9]&gt;              &lt;chr&gt; http…         434\n15 https://openalex… Baiyu Zhang  &lt;chr [9]&gt;              &lt;chr&gt; http…         430\n16 https://openalex… Steven M. R… &lt;chr [8]&gt;              &lt;chr&gt; http…         424\n17 https://openalex… Rosemary Ri… &lt;chr [5]&gt;              &lt;chr&gt; http…         412\n18 https://openalex… E. Jacobsen  &lt;chr [4]&gt;              &lt;chr&gt; &lt;NA&gt;          394\n19 https://openalex… Lev Tarasov  &lt;chr [4]&gt;              &lt;chr&gt; http…         390\n20 https://openalex… Sohrab Zend… &lt;chr [3]&gt;              &lt;chr&gt; http…         376\n21 https://openalex… Patrick S. … &lt;chr [5]&gt;              &lt;chr&gt; http…         348\n22 https://openalex… Neil Bose    &lt;chr [7]&gt;              &lt;chr&gt; http…         344\n23 https://openalex… Jian‐Bin Lin &lt;chr [4]&gt;              &lt;chr&gt; http…         336\n24 https://openalex… John T. Bro… &lt;chr [5]&gt;              &lt;chr&gt; http…         332\n25 https://openalex… Jie Xiao     &lt;chr [5]&gt;              &lt;chr&gt; http…         318\n26 https://openalex… Yuming Zhao  &lt;chr [4]&gt;              &lt;chr&gt; http…         317\n27 https://openalex… M. Tariq Iq… &lt;chr [15]&gt;             &lt;chr&gt; http…         315\n28 https://openalex… Michael Lei… &lt;chr [3]&gt;              &lt;chr&gt; http…         308\n29 https://openalex… Abir U. Iga… &lt;chr [6]&gt;              &lt;chr&gt; http…         300\n30 https://openalex… Rachel Berk… &lt;chr [5]&gt;              &lt;chr&gt; http…         299\n# ℹ 2,277 more rows\n# ℹ abbreviated name: ¹​display_name_alternatives\n# ℹ 11 more variables: cited_by_count &lt;int&gt;, counts_by_year &lt;list&gt;,\n#   affiliation_display_name &lt;chr&gt;, affiliation_id &lt;chr&gt;,\n#   affiliation_ror &lt;chr&gt;, affiliation_country_code &lt;chr&gt;,\n#   affiliation_type &lt;chr&gt;, affiliation_lineage &lt;chr&gt;,\n#   affiliations_other &lt;list&gt;, topics &lt;list&gt;, works_api_url &lt;chr&gt;\n\n\nLet’s take a look at the topics data first. We’ll get a sense of what is in here and think about how to filter it to a smaller set of results that interest us.\nOne way to proceed is to use the pull() function from the tidyverse. If you run the code below, you’ll see a LOT of text populate your screen – R is printing 2307 dataframes! I won’t print the results here, but you can!\nauthors_data %&gt;% pull(topics)\nWhen we we pipe authors_data into pull(topics), we get the contents of the topics column as a vector. Vectors are useful for lots of things, including quick computations, plotting, or applying vectorized functions. Since it’s a simple vector, there’s no extra metadata like column names or row indices.\nThat’s not always what we want. Instead, we could use the select() function from the tidyverse to get back a tibble containing the column we want. Because it’s a tibble, it preserves additional information such as column names, types, and row names (implicitly). The tibble still has the structure of a table, so we can see the column name and work with it in the context of other columns! And keeping our data in a tibble format makes it easier to perform further data manipulations, or join with other tibbles, since many tidyverse functions expect data to be in a tibble format.\nauthors_data %&gt;% select(topics)\nThis is a complex data structure! Each publication in our dataset has a tibble stored in the topics column! Nested dataframes! Oh my.\n\nauthors_data %&gt;%\n    select(topics) %&gt;%\n    .[[1]] %&gt;%\n    head(10) %&gt;%\n    print()\n\n[[1]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   312 topic    https://openalex.org/T10035         Phytochemicals and …\n 2     1   312 subfield https://openalex.org/subfields/2704 Biochemistry        \n 3     1   312 field    https://openalex.org/fields/27      Medicine            \n 4     1   312 domain   https://openalex.org/domains/4      Health Sciences     \n 5     2   228 topic    https://openalex.org/T10333         Meat and Animal Pro…\n 6     2   228 subfield https://openalex.org/subfields/1103 Animal Science and …\n 7     2   228 field    https://openalex.org/fields/11      Agricultural and Bi…\n 8     2   228 domain   https://openalex.org/domains/1      Life Sciences       \n 9     3   165 topic    https://openalex.org/T11561         Protein Hydrolysis …\n10     3   165 subfield https://openalex.org/subfields/1312 Molecular Biology   \n# ℹ 90 more rows\n\n[[2]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   303 topic    https://openalex.org/T11458         Advanced Wireless C…\n 2     1   303 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n 3     1   303 field    https://openalex.org/fields/22      Engineering         \n 4     1   303 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   186 topic    https://openalex.org/T10148         Advanced MIMO Syste…\n 6     2   186 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n 7     2   186 field    https://openalex.org/fields/22      Engineering         \n 8     2   186 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   116 topic    https://openalex.org/T10851         Optical Wireless Co…\n10     3   116 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n# ℹ 90 more rows\n\n[[3]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1    57 topic    https://openalex.org/T10230         Marine and fisherie…\n 2     1    57 subfield https://openalex.org/subfields/2306 Global and Planetar…\n 3     1    57 field    https://openalex.org/fields/23      Environmental Scien…\n 4     1    57 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2    53 topic    https://openalex.org/T10135         Insect-Plant Intera…\n 6     2    53 subfield https://openalex.org/subfields/1109 Insect Science      \n 7     2    53 field    https://openalex.org/fields/11      Agricultural and Bi…\n 8     2    53 domain   https://openalex.org/domains/1      Life Sciences       \n 9     3    35 topic    https://openalex.org/T12329         Hemiptera Insect St…\n10     3    35 subfield https://openalex.org/subfields/1105 Ecology, Evolution,…\n# ℹ 90 more rows\n\n[[4]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   265 topic    https://openalex.org/T10148         Advanced MIMO Syste…\n 2     1   265 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n 3     1   265 field    https://openalex.org/fields/22      Engineering         \n 4     1   265 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   261 topic    https://openalex.org/T10796         Cooperative Communi…\n 6     2   261 subfield https://openalex.org/subfields/1705 Computer Networks a…\n 7     2   261 field    https://openalex.org/fields/17      Computer Science    \n 8     2   261 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   161 topic    https://openalex.org/T11458         Advanced Wireless C…\n10     3   161 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n# ℹ 90 more rows\n\n[[5]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   210 topic    https://openalex.org/T10013         Asymmetric Synthesi…\n 2     1   210 subfield https://openalex.org/subfields/1605 Organic Chemistry   \n 3     1   210 field    https://openalex.org/fields/16      Chemistry           \n 4     1   210 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   165 topic    https://openalex.org/T11549         Synthetic Organic C…\n 6     2   165 subfield https://openalex.org/subfields/1605 Organic Chemistry   \n 7     2   165 field    https://openalex.org/fields/16      Chemistry           \n 8     2   165 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   133 topic    https://openalex.org/T10302         Fish Ecology and Ma…\n10     3   133 subfield https://openalex.org/subfields/2309 Nature and Landscap…\n# ℹ 90 more rows\n\n[[6]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1    86 topic    https://openalex.org/T11087         Solidification and …\n 2     1    86 subfield https://openalex.org/subfields/2505 Materials Chemistry \n 3     1    86 field    https://openalex.org/fields/25      Materials Science   \n 4     1    86 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2    69 topic    https://openalex.org/T10039         Stellar, planetary,…\n 6     2    69 subfield https://openalex.org/subfields/3103 Astronomy and Astro…\n 7     2    69 field    https://openalex.org/fields/31      Physics and Astrono…\n 8     2    69 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3    68 topic    https://openalex.org/T10325         Astro and Planetary…\n10     3    68 subfield https://openalex.org/subfields/3103 Astronomy and Astro…\n# ℹ 90 more rows\n\n[[7]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   188 topic    https://openalex.org/T11061         Ocean Waves and Rem…\n 2     1   188 subfield https://openalex.org/subfields/1910 Oceanography        \n 3     1   188 field    https://openalex.org/fields/19      Earth and Planetary…\n 4     1   188 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   107 topic    https://openalex.org/T10891         Radar Systems and S…\n 6     2   107 subfield https://openalex.org/subfields/2202 Aerospace Engineeri…\n 7     2   107 field    https://openalex.org/fields/22      Engineering         \n 8     2   107 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3    93 topic    https://openalex.org/T10255         Oceanographic and A…\n10     3    93 subfield https://openalex.org/subfields/1910 Oceanography        \n# ℹ 90 more rows\n\n[[8]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   242 topic    https://openalex.org/T10612         Magnetism in coordi…\n 2     1   242 subfield https://openalex.org/subfields/2504 Electronic, Optical…\n 3     1   242 field    https://openalex.org/fields/25      Materials Science   \n 4     1   242 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   216 topic    https://openalex.org/T11881         Crystallization and…\n 6     2   216 subfield https://openalex.org/subfields/2505 Materials Chemistry \n 7     2   216 field    https://openalex.org/fields/25      Materials Science   \n 8     2   216 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   215 topic    https://openalex.org/T12613         X-ray Diffraction i…\n10     3   215 subfield https://openalex.org/subfields/2505 Materials Chemistry \n# ℹ 90 more rows\n\n[[9]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   120 topic    https://openalex.org/T11802         Chemical Looping an…\n 2     1   120 subfield https://openalex.org/subfields/2204 Biomedical Engineer…\n 3     1   120 field    https://openalex.org/fields/22      Engineering         \n 4     1   120 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2    78 topic    https://openalex.org/T10998         Heat Transfer and O…\n 6     2    78 subfield https://openalex.org/subfields/2210 Mechanical Engineer…\n 7     2    78 field    https://openalex.org/fields/22      Engineering         \n 8     2    78 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3    54 topic    https://openalex.org/T12696         Icing and De-icing …\n10     3    54 subfield https://openalex.org/subfields/2202 Aerospace Engineeri…\n# ℹ 90 more rows\n\n[[10]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   250 topic    https://openalex.org/T11092         Spondyloarthritis S…\n 2     1   250 subfield https://openalex.org/subfields/2745 Rheumatology        \n 3     1   250 field    https://openalex.org/fields/27      Medicine            \n 4     1   250 domain   https://openalex.org/domains/4      Health Sciences     \n 5     2   211 topic    https://openalex.org/T10469         Psoriasis: Treatmen…\n 6     2   211 subfield https://openalex.org/subfields/2403 Immunology          \n 7     2   211 field    https://openalex.org/fields/24      Immunology and Micr…\n 8     2   211 domain   https://openalex.org/domains/1      Life Sciences       \n 9     3   178 topic    https://openalex.org/T10200         Rheumatoid Arthriti…\n10     3   178 subfield https://openalex.org/subfields/2745 Rheumatology        \n# ℹ 90 more rows\n\n\nIf we print some rows from the topics tibble, we can see that it contains information on topic, subfield, field, and domain. We’ll focus on topics for now and will come back to fields later.\n\nauthors_data %&gt;%\n    select(topics) %&gt;%\n    unnest(topics) %&gt;%\n    distinct(display_name) %&gt;%\n    print(n = 30)\n\n# A tibble: 4,285 × 1\n   display_name                                \n   &lt;chr&gt;                                       \n 1 Phytochemicals and Antioxidant Activities   \n 2 Biochemistry                                \n 3 Medicine                                    \n 4 Health Sciences                             \n 5 Meat and Animal Product Quality             \n 6 Animal Science and Zoology                  \n 7 Agricultural and Biological Sciences        \n 8 Life Sciences                               \n 9 Protein Hydrolysis and Bioactive Peptides   \n10 Molecular Biology                           \n11 Biochemistry, Genetics and Molecular Biology\n12 Antioxidant Activity and Oxidative Stress   \n13 Fatty Acid Research and Health              \n14 Nutrition and Dietetics                     \n15 Nursing                                     \n16 Edible Oils Quality and Analysis            \n17 Organic Chemistry                           \n18 Chemistry                                   \n19 Physical Sciences                           \n20 Aquaculture Nutrition and Growth            \n21 Aquatic Science                             \n22 Free Radicals and Antioxidants              \n23 Advanced Chemical Sensor Technologies       \n24 Biomedical Engineering                      \n25 Engineering                                 \n26 Tea Polyphenols and Effects                 \n27 Pathology and Forensic Medicine             \n28 Nuts composition and effects                \n29 Phytoestrogen effects and research          \n30 Food Chemistry and Fat Analysis             \n# ℹ 4,255 more rows\n\n\nLet’s filter the tibble to find authors (rows in authors_data) who have worked on the topic of “migration.”\nLet’s unpack the code below.\nFirst, we create a variable called search_topic and assign it the string “migration”. We will use this value later to filter the data. Then we pipe the authors_data into the select() function, where we select the display_name column (containing author names) and the topics column, which contained nested tibbles with information about the topics on which a specific author has published.\nWe then pipe the author names and topics into the unnest() function, which unnests the topics column. In other words, we will pull the topics tibble out of the row from the dataframe and expand it so that it is it’s own tibble with separate rows. The names_sep = \"_\" parameter specifies that* when unnesting, any new column names coming from the nested structure should be concatenated with the original column name using an underscore.* For example, if the nested tibble has a column named display_name, it might become topics_display_name. Why does that matter? Because the nested tibble has columns with the same names as the tibble it’s embedded in, which can cause… chaos.\nNext, we pipe the unnested data into the filter() function. We use it to filter the rows in author_data based on whether the topics_display_name column contains the text stored in search_topic (which is “migration”). To make that happen, we use the str_detect() function to check if a string contains a specific pattern. We use a “regular expression” that ignores case differences by using the argument ignore_case = TRUE (so “Migration” or “migration” both match).\nNow we can display a list of unique authors who meet our search and filter criteria by piping the results into distinct() and then printing the first n results (in this case, 80).\n\nsearch_topic &lt;- \"migration\"\n\nauthors_data %&gt;%\n    select(display_name, topics) %&gt;%\n    unnest(topics, names_sep = \"_\") %&gt;%\n    filter(str_detect(topics_display_name, regex(search_topic, ignore_case = TRUE))) %&gt;%\n    distinct(display_name) %&gt;%\n    print(n = 80)\n\n# A tibble: 160 × 1\n   display_name             \n   &lt;chr&gt;                    \n 1 Sian Neilson             \n 2 Roger White              \n 3 Ratana Chuenpagdee       \n 4 Tony Fang                \n 5 Trevor Bell              \n 6 Lewis R. Fischer         \n 7 Eric Y. Tenkorang        \n 8 Barbara Neis             \n 9 R. J. Avery              \n10 Yang Zhen                \n11 Amin A. Muhammad Gadit   \n12 Ashlee Cunsolo           \n13 Derek Nurse              \n14 Mark C. J. Stoddart      \n15 Kelly Vodden             \n16 Stephen Bornstein        \n17 Lisa Philpott            \n18 Marilyn Porter           \n19 Shree Mulay              \n20 Tyler D. Eddy            \n21 Yanqing Yi               \n22 Diana L. Gustafson       \n23 Alex Stewart             \n24 Ben Burt                 \n25 A. Lukyn Williams        \n26 Sharon R. Roseman        \n27 Jennifer A. Selby        \n28 Gillian Kolla            \n29 Sulaimon Gıwa            \n30 Diane Tye                \n31 Victor Maddalena         \n32 Christopher P. Youé      \n33 Fern Brunger             \n34 KL MacPherson            \n35 David Close              \n36 Sonja Boon               \n37 T.E. Roche               \n38 Robert Ormsby            \n39 Benjamin Rich Zendel     \n40 Jane G. Zhu              \n41 Adrian Tanner            \n42 Lisa Rankin              \n43 Alexander Y. Shestopaloff\n44 Stephen Czarnuch         \n45 Dale Kirby               \n46 Martha Traverso-Yépez    \n47 María Andrée López Gómez \n48 Nancy Pedri              \n49 Rick Audas               \n50 Alan Hall                \n51 M. J. Anderson           \n52 Delores V. Mullings      \n53 Rochelle R. Côté         \n54 Gordon B. Cooke          \n55 Roselyne N. Okech        \n56 Bill Bigelow             \n57 Isabelle Côté            \n58 Gerald Mugford           \n59 Katherine Side           \n60 Nicholas Wells           \n61 Jaro Stacul              \n62 Maisam Najafizada        \n63 Susan Stuckless          \n64 Peter Narváez            \n65 Jean L. Briggs           \n66 Pauline Duke             \n67 Sarah Gander             \n68 Ahmed Afzal              \n69 Yorck Sommerhäuser       \n70 Natalie Beausoleil       \n71 Rainer Baehre            \n72 Valerie Burton           \n73 Frederick Johnstone      \n74 Yolande Pottie‐Sherman   \n75 Nathalie LaCoste         \n76 Hollý                    \n77 Hugh Whalen              \n78 Lisa‐Jo K. van den Scott \n79 Martin Lovelace          \n80 Jeanne Sinclair          \n# ℹ 80 more rows\n\n\nWhat are we looking at here? These are authors affiliated with Memorial University who have published at least one paper on the topic of “migration.” It also prints the author’s number of publications and citations (as indexed by OpenAlex). We got that data by developing a small pipeline that:\n\nStarts with our original dataset.\nFocuses on just the author names and their topics.\nExpands nested topic information into individual rows.\nFilters rows where the topic matches “migration”.\nRemoves duplicate author names.\nPrints the results, showing up to 80 rows.\n\nNow… change the search_topic above to search for other topics. Try “climate change” (or whatever)!\n\n\n\n\nOK, cool! But, once again, maybe we want to see some other information, like maybe the name of the author, the title of the publication, and the number of topics assigned to that publication. Let’s do that below and print the top 200 results.\n\nsearch_topic &lt;- \"migration\"\n\nauthors_data %&gt;%\n    select(display_name, topics, works_count, cited_by_count) %&gt;%\n    unnest(topics, names_sep = \"_\") %&gt;%\n    filter(str_detect(topics_display_name, regex(search_topic, ignore_case = TRUE))) %&gt;%\n    select(display_name, topics_display_name, topics_count, topics_display_name) %&gt;%\n    print(n = 200)\n\n# A tibble: 207 × 3\n    display_name                topics_display_name                 topics_count\n    &lt;chr&gt;                       &lt;chr&gt;                                      &lt;int&gt;\n  1 Sian Neilson                European Law and Migration                     4\n  2 Sian Neilson                Human Rights and Immigration                   3\n  3 Roger White                 Migration and Labor Dynamics                  31\n  4 Roger White                 Migration, Ethnicity, and Economy             25\n  5 Ratana Chuenpagdee          Climate Change, Adaptation, Migrat…            5\n  6 Tony Fang                   Migration and Labor Dynamics                  30\n  7 Tony Fang                   Migration, Ethnicity, and Economy             27\n  8 Tony Fang                   Diaspora, migration, transnational…            5\n  9 Trevor Bell                 Climate Change, Adaptation, Migrat…            4\n 10 Lewis R. Fischer            Migration, Policy, and Dickens Stu…            1\n 11 Eric Y. Tenkorang           Migration and Labor Dynamics                   3\n 12 Eric Y. Tenkorang           Migration, Health and Trauma                   2\n 13 Barbara Neis                Migration, Aging, and Tourism Stud…            9\n 14 Barbara Neis                Migration and Labor Dynamics                   4\n 15 R. J. Avery                 Migration, Aging, and Tourism Stud…            4\n 16 Yang Zhen                   China's Global Influence and Migra…            1\n 17 Amin A. Muhammad Gadit      Migration, Health and Trauma                   4\n 18 Ashlee Cunsolo              Climate Change, Adaptation, Migrat…            9\n 19 Derek Nurse                 Diaspora, migration, transnational…            1\n 20 Mark C. J. Stoddart         Climate Change, Adaptation, Migrat…            3\n 21 Kelly Vodden                Migration, Aging, and Tourism Stud…            5\n 22 Stephen Bornstein           Migration, Health and Trauma                   2\n 23 Lisa Philpott               Migration, Ethnicity, and Economy              2\n 24 Marilyn Porter              Migration, Ethnicity, and Economy              5\n 25 Marilyn Porter              Migration and Labor Dynamics                   3\n 26 Shree Mulay                 Migration, Health and Trauma                   3\n 27 Tyler D. Eddy               Climate Change, Adaptation, Migrat…            3\n 28 Yanqing Yi                  Migration, Health and Trauma                   7\n 29 Diana L. Gustafson          Migration, Health and Trauma                   9\n 30 Alex Stewart                Migration, Ethnicity, and Economy             14\n 31 Ben Burt                    Climate Change, Adaptation, Migrat…            6\n 32 Ben Burt                    Italian Social Issues and Migration            1\n 33 Ben Burt                    Diaspora, migration, transnational…            1\n 34 A. Lukyn Williams           European Law and Migration                     2\n 35 Sharon R. Roseman           Migration, Aging, and Tourism Stud…           12\n 36 Sharon R. Roseman           Migration and Labor Dynamics                   6\n 37 Sharon R. Roseman           Migration, Ethnicity, and Economy              5\n 38 Sharon R. Roseman           Diaspora, migration, transnational…            4\n 39 Sharon R. Roseman           Immigration and Intercultural Educ…            2\n 40 Sharon R. Roseman           Migration, Refugees, and Integrati…            2\n 41 Jennifer A. Selby           Multiculturalism, Politics, Migrat…           29\n 42 Jennifer A. Selby           Migration, Identity, and Health                3\n 43 Gillian Kolla               Migration, Health and Trauma                   2\n 44 Sulaimon Gıwa               Migration and Labor Dynamics                   5\n 45 Sulaimon Gıwa               Migration, Ethnicity, and Economy              4\n 46 Sulaimon Gıwa               Migration, Health and Trauma                   3\n 47 Sulaimon Gıwa               Migration, Refugees, and Integrati…            3\n 48 Sulaimon Gıwa               Migration, Identity, and Health                2\n 49 Diane Tye                   Migration, Ethnicity, and Economy              1\n 50 Victor Maddalena            Migration, Health and Trauma                   2\n 51 Christopher P. Youé         Migration, Ethnicity, and Economy              1\n 52 Fern Brunger                Migration, Health and Trauma                   3\n 53 KL MacPherson               China's Global Influence and Migra…            2\n 54 David Close                 Diaspora, migration, transnational…            2\n 55 Sonja Boon                  Migration, Ethnicity, and Economy              2\n 56 T.E. Roche                  Macrophage Migration Inhibitory Fa…            2\n 57 Robert Ormsby               Migration, Policy, and Dickens Stu…            1\n 58 Benjamin Rich Zendel        Migration, Aging, and Tourism Stud…            1\n 59 Jane G. Zhu                 Migration, Ethnicity, and Economy              2\n 60 Adrian Tanner               Multiculturalism, Politics, Migrat…            2\n 61 Adrian Tanner               Climate Change, Adaptation, Migrat…            1\n 62 Lisa Rankin                 Migration, Aging, and Tourism Stud…            1\n 63 Alexander Y. Shestopaloff   Migration, Health and Trauma                   2\n 64 Stephen Czarnuch            Migration, Health and Trauma                   2\n 65 Dale Kirby                  Migration, Ethnicity, and Economy              2\n 66 Dale Kirby                  Migration and Labor Dynamics                   2\n 67 Martha Traverso-Yépez       Migration, Racism, and Human Rights            2\n 68 María Andrée López Gómez    Migration, Aging, and Tourism Stud…            2\n 69 Nancy Pedri                 Diaspora, migration, transnational…            1\n 70 Rick Audas                  Migration and Labor Dynamics                   2\n 71 Alan Hall                   Migration, Identity, and Health                1\n 72 M. J. Anderson              Macrophage Migration Inhibitory Fa…            1\n 73 Delores V. Mullings         Migration and Labor Dynamics                   6\n 74 Delores V. Mullings         Migration, Health and Trauma                   4\n 75 Delores V. Mullings         Migration, Ethnicity, and Economy              3\n 76 Rochelle R. Côté            Migration, Ethnicity, and Economy              6\n 77 Rochelle R. Côté            Migration and Labor Dynamics                   3\n 78 Gordon B. Cooke             Migration, Aging, and Tourism Stud…            2\n 79 Roselyne N. Okech           Migration, Ethnicity, and Economy              2\n 80 Bill Bigelow                Migration, Ethnicity, and Economy              1\n 81 Isabelle Côté               Migration and Labor Dynamics                   4\n 82 Isabelle Côté               Migration, Refugees, and Integrati…            4\n 83 Isabelle Côté               Diaspora, migration, transnational…            2\n 84 Isabelle Côté               Migration, Identity, and Health                1\n 85 Gerald Mugford              Migration, Aging, and Tourism Stud…            2\n 86 Katherine Side              Migration, Refugees, and Integrati…            4\n 87 Nicholas Wells              Migration, Aging, and Tourism Stud…            2\n 88 Jaro Stacul                 Italian Social Issues and Migration            1\n 89 Maisam Najafizada           Migration, Health and Trauma                   2\n 90 Susan Stuckless             Migration, Aging, and Tourism Stud…            1\n 91 Peter Narváez               Migration, Ethnicity, and Economy              1\n 92 Jean L. Briggs              Migration, Education, Indigenous S…            2\n 93 Pauline Duke                Migration, Health and Trauma                   2\n 94 Sarah Gander                Migration, Health and Trauma                   4\n 95 Ahmed Afzal                 Diaspora, migration, transnational…            3\n 96 Ahmed Afzal                 Migration and Labor Dynamics                   2\n 97 Ahmed Afzal                 Migration, Ethnicity, and Economy              2\n 98 Yorck Sommerhäuser          Migration, Ethnicity, and Economy              1\n 99 Natalie Beausoleil          Multiculturalism, Politics, Migrat…            1\n100 Rainer Baehre               Migration, Ethnicity, and Economy              1\n101 Rainer Baehre               Migration and Labor Dynamics                   1\n102 Valerie Burton              Migration, Ethnicity, and Economy              3\n103 Frederick Johnstone         Migration, Ethnicity, and Economy              3\n104 Yolande Pottie‐Sherman      Migration and Labor Dynamics                   7\n105 Yolande Pottie‐Sherman      Migration, Ethnicity, and Economy              6\n106 Yolande Pottie‐Sherman      Migration, Refugees, and Integrati…            5\n107 Yolande Pottie‐Sherman      Diaspora, migration, transnational…            3\n108 Yolande Pottie‐Sherman      Migration, Aging, and Tourism Stud…            3\n109 Nathalie LaCoste            Multiculturalism, Politics, Migrat…            1\n110 Hollý                       Migration and Labor Dynamics                   1\n111 Hugh Whalen                 Multiculturalism, Politics, Migrat…            1\n112 Lisa‐Jo K. van den Scott    Diaspora, migration, transnational…            1\n113 Martin Lovelace             Migration, Ethnicity, and Economy              1\n114 Jeanne Sinclair             Migration, Aging, and Tourism Stud…            1\n115 Christopher Patey           Italian Social Issues and Migration            1\n116 Dominique Brégent‐Heald     Migration, Health, Geopolitics, Hi…            2\n117 Daze Jefferies              Migration, Ethnicity, and Economy              1\n118 David Peddle                Human Rights and Immigration                   1\n119 Stephen Harold Riggins      Diaspora, migration, transnational…            2\n120 Stephen Harold Riggins      Migration, Ethnicity, and Economy              1\n121 James Valcour               Climate Change, Adaptation, Migrat…            1\n122 Mercedes Steedman           Migration, Ethnicity, and Economy              2\n123 Ivan Emke                   European Law and Migration                     1\n124 Ivan Emke                   Migration, Health and Trauma                   1\n125 Robin Whitaker              Migration, Refugees, and Integrati…            4\n126 Robin Whitaker              Multiculturalism, Politics, Migrat…            1\n127 Lincoln Addison             Migration, Ethnicity, and Economy              3\n128 Lincoln Addison             Migration and Labor Dynamics                   1\n129 Elizabeth Yeoman            Migration, Refugees, and Integrati…            1\n130 Alessandro Giardino         Multiculturalism, Politics, Migrat…            1\n131 D. Codner                   Macrophage Migration Inhibitory Fa…            1\n132 Lesley Butler               Diaspora, migration, transnational…            1\n133 Lesley Butler               Migration, Ethnicity, and Economy              1\n134 Lesley Butler               Climate Change, Adaptation, Migrat…            1\n135 Julia Temple Newhook        Migration, Ethnicity, and Economy              1\n136 Julia Temple Newhook        Migration and Labor Dynamics                   1\n137 Donald W. Nichol            Migration, Policy, and Dickens Stu…            1\n138 John Mannion                Climate Change, Adaptation, Migrat…            1\n139 Santé A. Viselli            Multiculturalism, Politics, Migrat…            1\n140 Ronald Schwartz             Diaspora, migration, transnational…            1\n141 Brenda A. LeFrançois        Labour Market and Migration                    1\n142 Roza Tchoukaleyska          Migration, Identity, and Health                1\n143 Heidi Coombs-Thorne         Migration and Labor Dynamics                   1\n144 Robert Shea                 Migration, Refugees, and Integrati…            1\n145 Paul Alhassan Issahaku      Migration, Health and Trauma                   1\n146 Amy M. Warren               Migration, Aging, and Tourism Stud…            1\n147 Rowena Mercado              Migration, Health and Trauma                   1\n148 Kwamina Abekah‐Carter       Migration, Aging, and Tourism Stud…            2\n149 Angela J. Hyde              Macrophage Migration Inhibitory Fa…            1\n150 Sylvia Moore                Climate Change, Adaptation, Migrat…            1\n151 Christopher Curran          Migration and Labor Dynamics                   4\n152 Katie Gillespie             Migration, Health and Trauma                   4\n153 Catherine Losier            Migration, Identity, and Health                4\n154 Catherine Losier            Migration, Health, Geopolitics, Hi…            1\n155 Barry C. Gaulton            Migration, Health, Geopolitics, Hi…            1\n156 August Carbonella           Migration, Ethnicity, and Economy              4\n157 August Carbonella           Multiculturalism, Politics, Migrat…            1\n158 Nicholas Lynch              Migration, Aging, and Tourism Stud…            1\n159 Russell Dawe                Migration, Health and Trauma                   1\n160 Kodjo Attikpoé              Migration and Exile Studies                    1\n161 Lorna Bennett               Migration, Health and Trauma                   1\n162 Jennifer L. Buckle          Migration, Health and Trauma                   3\n163 Mariya Lesiv                Diaspora, migration, transnational…            2\n164 Mariya Lesiv                Migration, Ethnicity, and Economy              1\n165 John Bodner                 Multiculturalism, Politics, Migrat…            1\n166 Calvin Hollett              Migration, Aging, and Tourism Stud…            1\n167 A. K. M. Shahidullah        Climate Change, Adaptation, Migrat…            1\n168 Rebecca J. Franklin         Migration, Ethnicity, and Economy              2\n169 Beth Leavenworth DuFault    Migration, Ethnicity, and Economy              1\n170 Raquel Ruiz‐Díaz            Climate Change, Adaptation, Migrat…            3\n171 Leanna Butters              Migration, Aging, and Tourism Stud…            5\n172 Jacqueline Hesson           Migration, Health and Trauma                   1\n173 Jennifer Thorburn           Diaspora, migration, transnational…            7\n174 Jennifer Thorburn           Migration and Labor Dynamics                   7\n175 Madonna M. Murphy           Migration, Health and Trauma                   1\n176 Roberta Buchanan            Multiculturalism, Politics, Migrat…            1\n177 Sean W. D. Gray             Migration, Refugees, and Integrati…            3\n178 Cory W. Thorne              Diaspora, migration, transnational…            1\n179 Michael Skipton             Migration, Policy, and Dickens Stu…            2\n180 Neil J. Vincent             Migration, Health and Trauma                   1\n181 Devonne Ryan                Migration, Aging, and Tourism Stud…            1\n182 Margo Wilson                Migration, Health and Trauma                   1\n183 Michael D. Kirkpatrick      Migration, Ethnicity, and Economy              1\n184 Kate Lahey                  Climate Change, Adaptation, Migrat…            1\n185 Elias Bartellas             Migration, Health and Trauma                   1\n186 Mohamed Salah Eddine Madiou Climate Change, Adaptation, Migrat…            1\n187 Elise Thorburn              Migration, Aging, and Tourism Stud…            1\n188 Leslie J. Cake              Migration, Aging, and Tourism Stud…            1\n189 Hua Que                     Migration, Health and Trauma                   6\n190 Hua Que                     Migration and Labor Dynamics                   3\n191 Hua Que                     Migration, Refugees, and Integrati…            2\n192 Caroline Guinard            Migration, Identity, and Health                1\n193 Ban Younghusband            Macrophage Migration Inhibitory Fa…            1\n194 Jessica Squires             Macrophage Migration Inhibitory Fa…            1\n195 Tyler R. Pritchard          Migration, Health and Trauma                   2\n196 Raleen Murphy               Migration, Health and Trauma                   2\n197 Darren Hynes                Migration, Health, Geopolitics, Hi…            1\n198 Halia Koo                   Multiculturalism, Politics, Migrat…            1\n199 Alka Agarwal-Mawal          Macrophage Migration Inhibitory Fa…            1\n200 Jieying Xiong               Macrophage Migration Inhibitory Fa…            1\n# ℹ 7 more rows\n\n\nLet’s store this subset of data for later.\n\nmigration_authors &lt;- authors_data %&gt;%\n    select(display_name, topics, works_count, cited_by_count) %&gt;%\n    unnest(topics, names_sep = \"_\") %&gt;%\n    filter(str_detect(topics_display_name, regex(search_topic, ignore_case = TRUE))) %&gt;%\n    select(display_name, topics_display_name, topics_count, topics_display_name)\n\n\n\n\nWhat are some of the key concepts that show up in research on migration conducted by Memorial researchers? One simple way to get at this idea is to simply take every unique word that appears across titles and count the number of times it appears. It’s crude, but a useful first pass to get a sense of what we have.\nTo do this, we’ll use another package: tidytext for “natural language processing”. We’ll load the library and then start our pipeline by piping the migration_authors data into the tidytext’s unnest_tokens() function. unnest_tokens() splits the topics_display_name column into individual words (tokens). Each word becomes a separate row in the dataset, and the new column is named word. Then we pipe that output into count(word, sort = TRUE) to counts the occurrences of each unique word in the word column. The sort = TRUE argument sorts the results in descending order of frequency.\n\nlibrary(tidytext)\n\nword_counts &lt;- migration_authors %&gt;%\n    unnest_tokens(word, topics_display_name) %&gt;%\n    count(word, sort = TRUE)\n\nprint(word_counts, n = 50)\n\n# A tibble: 48 × 2\n   word                 n\n   &lt;chr&gt;            &lt;int&gt;\n 1 migration          204\n 2 and                149\n 3 health              44\n 4 economy             36\n 5 ethnicity           36\n 6 trauma              33\n 7 studies             26\n 8 dynamics            24\n 9 identity            23\n10 labor               23\n11 aging               21\n12 tourism             21\n13 adaptation          16\n14 change              16\n15 climate             16\n16 diaspora            16\n17 transnational       16\n18 gender              12\n19 multiculturalism    12\n20 politics            12\n21 integration         10\n22 refugees            10\n23 factor               9\n24 inhibitory           9\n25 macrophage           9\n26 dickens              4\n27 geography            4\n28 geopolitics          4\n29 historical           4\n30 human                4\n31 policy               4\n32 rights               4\n33 social               4\n34 european             3\n35 immigration          3\n36 issues               3\n37 italian              3\n38 law                  3\n39 china's              2\n40 education            2\n41 global               2\n42 influence            2\n43 racism               2\n44 exile                1\n45 indigenous           1\n46 intercultural        1\n47 labour               1\n48 market               1\n\n\n\n\n\nLet’s make a horizontal bar graph (where the words are on the y-axis and word frequency is on the x-axis) to visualize this distribution of words. We’ll also remove “stop words” like “and,” “of,” etc.\n\ndata(\"stop_words\")\nfiltered_word_counts &lt;- word_counts %&gt;%\n    anti_join(stop_words, by = \"word\")\n\nAnd now for the bar graph!\n\nggplot(filtered_word_counts, aes(x = reorder(word, n), y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    labs(\n        title = \"Word Frequency in Migration Research\",\n        x = \"Words\",\n        y = \"Frequency\"\n    ) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nRemember you can save your plot with the ggsave function!\nggsave(\"migration_word_frequency.png\", width = 10, height = 8)\n\n\n\nThe topics data also include “field” classifications. These are multi-level labels attached to publications. By multi-level I mean that some labels are very high-level (e.g., social sciences, sociology) while others are most focused (e.g., sociology of gender, racial inequality). Let’s make a table counting the number of fields in the Memorial Data.\n\nfield_counts &lt;- authors_data %&gt;%\n    select(topics) %&gt;%\n    unnest(topics) %&gt;%\n    count(display_name, sort = TRUE)\n\nprint(field_counts, n = 30)\n\n# A tibble: 4,285 × 2\n   display_name                                             n\n   &lt;chr&gt;                                                &lt;int&gt;\n 1 Physical Sciences                                    19166\n 2 Social Sciences                                      19144\n 3 Health Sciences                                      11962\n 4 Medicine                                              9367\n 5 Life Sciences                                         7845\n 6 Engineering                                           5632\n 7 Environmental Science                                 3947\n 8 Biochemistry, Genetics and Molecular Biology          3740\n 9 Arts and Humanities                                   2519\n10 Computer Science                                      2375\n11 Earth and Planetary Sciences                          2334\n12 Health Professions                                    2107\n13 Agricultural and Biological Sciences                  2075\n14 Molecular Biology                                     1995\n15 Sociology and Political Science                       1958\n16 Psychology                                            1934\n17 Chemistry                                             1408\n18 General Health Professions                            1395\n19 Materials Science                                     1199\n20 Education                                             1189\n21 Neuroscience                                          1164\n22 Ecology                                               1147\n23 Physics and Astronomy                                 1121\n24 Electrical and Electronic Engineering                  943\n25 Surgery                                                903\n26 Genetics                                               894\n27 Public Health, Environmental and Occupational Health   890\n28 Economics, Econometrics and Finance                    885\n29 Business, Management and Accounting                    830\n30 Global and Planetary Change                            776\n# ℹ 4,255 more rows\n\n\nA few things jump out at me from this list of the top 30 topics. First, publication output in the physical and social sciences at Memorial are neck and neck! If you were to combine Health, Medicine, and Life Sciences, they would top the list. Arts and Humanities is pretty high on this list to, claiming the number 9 rank. Sociology and Political Science are at rank 15.\nLet’s ggplot!\n\ntop_n_fields &lt;- field_counts %&gt;%\n    top_n(100, n)\n\nggplot(top_n_fields, aes(x = reorder(display_name, n), y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    labs(\n        title = \"Top 30 Fields in Memorial University Publications\",\n        x = \"Fields\",\n        y = \"Count\"\n    ) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nWe’ll stop there for today. Tomorrow we’ll work on the second Data Stories assignment in class. It’s due on Monday March 10th."
  },
  {
    "objectID": "lectures/lecture-15-content.html#finding-memorials-openalex-institutional-id",
    "href": "lectures/lecture-15-content.html#finding-memorials-openalex-institutional-id",
    "title": "API Example: OpenAlexR",
    "section": "",
    "text": "To start, we need to find Memorial’s “Institutional ID”. We can do this by using the OpenAlex website.\n\n\n\nOpenAlex search\n\n\nClick on the Institution button and start typing “Memorial University” into the OpenAlex search.\n\n\n\nSearch for Memorial University under “Institution”\n\n\nTake a moment to review the results page – it’s the same page we saw when searching authors and topics in previous classes, only this time it’s for all of Memorial University. As of March 2025, there are almost 50,000 indexed publications.\n\n\n\nThe results page\n\n\nClick on “Memorial University” in the search field.\n\n\n\nFinding an Institutional ID\n\n\nYou should see an Institution ID under “Memorial University of Newfoundland.” I’ve highlighted it below to make it easier to see. This is the number we want to use when we query the OpenAlexAPI!\n\n\n\nCopying the Institutional ID for an API query\n\n\nYou can click to view MUN’s “Institutional Profile” on Open Alex.\n\n\n\nAn OpenAlex institution profile page"
  },
  {
    "objectID": "lectures/lecture-15-content.html#query-the-openalex-api",
    "href": "lectures/lecture-15-content.html#query-the-openalex-api",
    "title": "API Example: OpenAlexR",
    "section": "",
    "text": "Now we know that Memorial’s Institutional ID is i130438778. We can use this to setup an API query. Let’s start by creating a list with our query parameters.\nRecall that a list in R is like a container that holds several pieces of information. In this case, our list will contain three key-value pairs:\n\nentity = \"authors\" tells the API that we are interested in data about authors.\nlast_known_institutions.id = \"i130438778\" specifies that we want authors who are or were affiliated with a particular institution (identified by “i130438778”).\nworks_count = \"&gt;10\" means we want authors who have more than 10 published works.\n\nLet’s set it up!\n\nmy_arguments &lt;- list(\n    entity = \"authors\",\n    last_known_institutions.id = \"i130438778\",\n    works_count = \"&gt;10\"\n)\n\nNow let’s we’ll make an API call!\n\ndo.call(oa_fetch, c(my_arguments, list(count_only = TRUE)))\n\n     count db_response_time_ms page per_page\n[1,]  2307                 169    1        1\n\n\ndo.call() is a function that calls another function – in this case oa_fetch – using a list of arguments.\nHere, we combine our my_arguments list with an extra argument list(count_only = TRUE). This tells the function oa_fetch to only return a count (the number of matching records) instead of all the detailed information OpenAlex has about our search results. Essentially, we’re asking the API: “How many authors match these criteria?”\nSo now we’ve defined the search criteria for authors in a list, and we’ve checked if there are any authors matching the criteria by asking for just a count. If there are results (i.e., there is 1 or more authors in the OpenAlex database), then we can make another request to collect detailed information for those authors.\nRun the code block below.\n\nif (do.call(oa_fetch, c(my_arguments, list(count_only = TRUE)))[1] &gt; 0) {\n    do.call(oa_fetch, my_arguments) |&gt;\n        show_authors() |&gt;\n        knitr::kable()\n}\n\nWarning: Unknown or uninitialised column: `name`.\n\n\nWarning: Unknown or uninitialised column: `display_name`.\n\n\nWarning: Unknown or uninitialised column: `name`.\n\n\nWarning: Unknown or uninitialised column: `display_name`.\n\n\nWarning: Unknown or uninitialised column: `name`.\n\n\nWarning: Unknown or uninitialised column: `display_name`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ndisplay_name\norcid\nworks_count\ncited_by_count\naffiliation_display_name\ntop_concepts\n\n\n\n\nA5026509039\nFereidoon Shahidi\n0000-0002-9912-0330\n1113\n79559\nMemorial University of Newfoundland\nBiochemistry, Animal Science and Zoology, Molecular Biology\n\n\nA5077149719\nOctavia A. Dobre\n0000-0001-8528-0512\n949\n20777\nMemorial University of Newfoundland\nElectrical and Electronic Engineering, Electrical and Electronic Engineering, Electrical and Electronic Engineering\n\n\nA5010428924\nDavid C. Schneider\n0000-0003-4771-2155\n798\n6532\nMemorial University of Newfoundland\nGlobal and Planetary Change, Insect Science, Ecology, Evolution, Behavior and Systematics\n\n\nA5049089848\nTrung Q. Duong\n0000-0002-4703-4836\n726\n18629\nMemorial University of Newfoundland\nElectrical and Electronic Engineering, Computer Networks and Communications, Electrical and Electronic Engineering\n\n\nA5032069177\nIan Fleming\n0000-0002-5541-824X\n701\n23299\nMemorial University of Newfoundland\nOrganic Chemistry, Organic Chemistry, Nature and Landscape Conservation\n\n\nA5102982237\nRobert A. Brown\n0000-0003-2350-110X\n528\n18534\nMemorial University of Newfoundland\nMaterials Chemistry, Astronomy and Astrophysics, Astronomy and Astrophysics\n\n\n\n\n\nIn the code above, we check if the count returned by the previous call is greater than zero by using an if statement. Then do.call(oa_fetch, c(my_arguments, list(count_only = TRUE)))[1] retrieves the first element of the result, which is the number of matching authors. If that number is greater than 0 (meaning there is at least one author that meets the criteria), then the code inside the if block ({ ... }) block will run.\nInside the if block, do.call(oa_fetch, my_arguments) calls the oa_fetch function again with our original arguments, only this time we don’t use count_only = TRUE. This tells to API to fetch all the details of the matching authors. We then use the pipe operator |&gt; to pass the results of that function on to the next function, show_authors(). The show_authors() function formats or selects relevant author information. Finally, we pass the formatted data to knitr::kable(), which converts it into a nicely formatted table."
  },
  {
    "objectID": "lectures/lecture-15-content.html#store-the-data",
    "href": "lectures/lecture-15-content.html#store-the-data",
    "title": "API Example: OpenAlexR",
    "section": "",
    "text": "So far our code fetches data and processes it for display, but it doesn’t retain the data in memory or write it to disk. If we want to keep it in memory and analyze that data in some way, we need to assign the result to a variable. Recall from previous classes that we want to minimize our APIs calls to be considerate of the servers providing our data.\nLet’s do that now, making yet another API call.\n\nauthors_data &lt;- do.call(oa_fetch, my_arguments)\n\nNow our data in stored in authors_data. Let’s take a look at the column names.\n\nnames(authors_data)\n\n [1] \"id\"                        \"display_name\"             \n [3] \"display_name_alternatives\" \"ids\"                      \n [5] \"orcid\"                     \"works_count\"              \n [7] \"cited_by_count\"            \"counts_by_year\"           \n [9] \"affiliation_display_name\"  \"affiliation_id\"           \n[11] \"affiliation_ror\"           \"affiliation_country_code\" \n[13] \"affiliation_type\"          \"affiliation_lineage\"      \n[15] \"affiliations_other\"        \"topics\"                   \n[17] \"works_api_url\"            \n\n\nThere are 17 variables for us to work with here! We’ll focus on a few today, including display_name, cited_by_count, works_count, counts_by_year, and topics.\nWe can print a preview of the tibble like any other. Let’s print 30 rows:\n\nprint(authors_data, n = 30)\n\n# A tibble: 2,307 × 17\n   id                display_name display_name_alterna…¹ ids   orcid works_count\n   &lt;chr&gt;             &lt;chr&gt;        &lt;list&gt;                 &lt;lis&gt; &lt;chr&gt;       &lt;int&gt;\n 1 https://openalex… Fereidoon S… &lt;chr [3]&gt;              &lt;chr&gt; http…        1113\n 2 https://openalex… Octavia A. … &lt;chr [7]&gt;              &lt;chr&gt; http…         949\n 3 https://openalex… David C. Sc… &lt;chr [6]&gt;              &lt;chr&gt; http…         798\n 4 https://openalex… Trung Q. Du… &lt;chr [5]&gt;              &lt;chr&gt; http…         726\n 5 https://openalex… Ian Fleming  &lt;chr [8]&gt;              &lt;chr&gt; http…         701\n 6 https://openalex… Robert A. B… &lt;chr [6]&gt;              &lt;chr&gt; http…         528\n 7 https://openalex… Weimin Huang &lt;chr [10]&gt;             &lt;chr&gt; http…         525\n 8 https://openalex… Laurence K.… &lt;chr [6]&gt;              &lt;chr&gt; &lt;NA&gt;          523\n 9 https://openalex… G.F. Naterer &lt;chr [4]&gt;              &lt;chr&gt; http…         523\n10 https://openalex… Proton Rahm… &lt;chr [5]&gt;              &lt;chr&gt; http…         492\n11 https://openalex… David G. Be… &lt;chr [6]&gt;              &lt;chr&gt; http…         485\n12 https://openalex… David Molyn… &lt;chr [6]&gt;              &lt;chr&gt; http…         478\n13 https://openalex… Lynn H. Ger… &lt;chr [13]&gt;             &lt;chr&gt; http…         454\n14 https://openalex… M. P. Searle &lt;chr [9]&gt;              &lt;chr&gt; http…         434\n15 https://openalex… Baiyu Zhang  &lt;chr [9]&gt;              &lt;chr&gt; http…         430\n16 https://openalex… Steven M. R… &lt;chr [8]&gt;              &lt;chr&gt; http…         424\n17 https://openalex… Rosemary Ri… &lt;chr [5]&gt;              &lt;chr&gt; http…         412\n18 https://openalex… E. Jacobsen  &lt;chr [4]&gt;              &lt;chr&gt; &lt;NA&gt;          394\n19 https://openalex… Lev Tarasov  &lt;chr [4]&gt;              &lt;chr&gt; http…         390\n20 https://openalex… Sohrab Zend… &lt;chr [3]&gt;              &lt;chr&gt; http…         376\n21 https://openalex… Patrick S. … &lt;chr [5]&gt;              &lt;chr&gt; http…         348\n22 https://openalex… Neil Bose    &lt;chr [7]&gt;              &lt;chr&gt; http…         344\n23 https://openalex… Jian‐Bin Lin &lt;chr [4]&gt;              &lt;chr&gt; http…         336\n24 https://openalex… John T. Bro… &lt;chr [5]&gt;              &lt;chr&gt; http…         332\n25 https://openalex… Jie Xiao     &lt;chr [5]&gt;              &lt;chr&gt; http…         318\n26 https://openalex… Yuming Zhao  &lt;chr [4]&gt;              &lt;chr&gt; http…         317\n27 https://openalex… M. Tariq Iq… &lt;chr [15]&gt;             &lt;chr&gt; http…         315\n28 https://openalex… Michael Lei… &lt;chr [3]&gt;              &lt;chr&gt; http…         308\n29 https://openalex… Abir U. Iga… &lt;chr [6]&gt;              &lt;chr&gt; http…         300\n30 https://openalex… Rachel Berk… &lt;chr [5]&gt;              &lt;chr&gt; http…         299\n# ℹ 2,277 more rows\n# ℹ abbreviated name: ¹​display_name_alternatives\n# ℹ 11 more variables: cited_by_count &lt;int&gt;, counts_by_year &lt;list&gt;,\n#   affiliation_display_name &lt;chr&gt;, affiliation_id &lt;chr&gt;,\n#   affiliation_ror &lt;chr&gt;, affiliation_country_code &lt;chr&gt;,\n#   affiliation_type &lt;chr&gt;, affiliation_lineage &lt;chr&gt;,\n#   affiliations_other &lt;list&gt;, topics &lt;list&gt;, works_api_url &lt;chr&gt;\n\n\nLet’s take a look at the topics data first. We’ll get a sense of what is in here and think about how to filter it to a smaller set of results that interest us.\nOne way to proceed is to use the pull() function from the tidyverse. If you run the code below, you’ll see a LOT of text populate your screen – R is printing 2307 dataframes! I won’t print the results here, but you can!\nauthors_data %&gt;% pull(topics)\nWhen we we pipe authors_data into pull(topics), we get the contents of the topics column as a vector. Vectors are useful for lots of things, including quick computations, plotting, or applying vectorized functions. Since it’s a simple vector, there’s no extra metadata like column names or row indices.\nThat’s not always what we want. Instead, we could use the select() function from the tidyverse to get back a tibble containing the column we want. Because it’s a tibble, it preserves additional information such as column names, types, and row names (implicitly). The tibble still has the structure of a table, so we can see the column name and work with it in the context of other columns! And keeping our data in a tibble format makes it easier to perform further data manipulations, or join with other tibbles, since many tidyverse functions expect data to be in a tibble format.\nauthors_data %&gt;% select(topics)\nThis is a complex data structure! Each publication in our dataset has a tibble stored in the topics column! Nested dataframes! Oh my.\n\nauthors_data %&gt;%\n    select(topics) %&gt;%\n    .[[1]] %&gt;%\n    head(10) %&gt;%\n    print()\n\n[[1]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   312 topic    https://openalex.org/T10035         Phytochemicals and …\n 2     1   312 subfield https://openalex.org/subfields/2704 Biochemistry        \n 3     1   312 field    https://openalex.org/fields/27      Medicine            \n 4     1   312 domain   https://openalex.org/domains/4      Health Sciences     \n 5     2   228 topic    https://openalex.org/T10333         Meat and Animal Pro…\n 6     2   228 subfield https://openalex.org/subfields/1103 Animal Science and …\n 7     2   228 field    https://openalex.org/fields/11      Agricultural and Bi…\n 8     2   228 domain   https://openalex.org/domains/1      Life Sciences       \n 9     3   165 topic    https://openalex.org/T11561         Protein Hydrolysis …\n10     3   165 subfield https://openalex.org/subfields/1312 Molecular Biology   \n# ℹ 90 more rows\n\n[[2]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   303 topic    https://openalex.org/T11458         Advanced Wireless C…\n 2     1   303 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n 3     1   303 field    https://openalex.org/fields/22      Engineering         \n 4     1   303 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   186 topic    https://openalex.org/T10148         Advanced MIMO Syste…\n 6     2   186 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n 7     2   186 field    https://openalex.org/fields/22      Engineering         \n 8     2   186 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   116 topic    https://openalex.org/T10851         Optical Wireless Co…\n10     3   116 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n# ℹ 90 more rows\n\n[[3]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1    57 topic    https://openalex.org/T10230         Marine and fisherie…\n 2     1    57 subfield https://openalex.org/subfields/2306 Global and Planetar…\n 3     1    57 field    https://openalex.org/fields/23      Environmental Scien…\n 4     1    57 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2    53 topic    https://openalex.org/T10135         Insect-Plant Intera…\n 6     2    53 subfield https://openalex.org/subfields/1109 Insect Science      \n 7     2    53 field    https://openalex.org/fields/11      Agricultural and Bi…\n 8     2    53 domain   https://openalex.org/domains/1      Life Sciences       \n 9     3    35 topic    https://openalex.org/T12329         Hemiptera Insect St…\n10     3    35 subfield https://openalex.org/subfields/1105 Ecology, Evolution,…\n# ℹ 90 more rows\n\n[[4]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   265 topic    https://openalex.org/T10148         Advanced MIMO Syste…\n 2     1   265 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n 3     1   265 field    https://openalex.org/fields/22      Engineering         \n 4     1   265 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   261 topic    https://openalex.org/T10796         Cooperative Communi…\n 6     2   261 subfield https://openalex.org/subfields/1705 Computer Networks a…\n 7     2   261 field    https://openalex.org/fields/17      Computer Science    \n 8     2   261 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   161 topic    https://openalex.org/T11458         Advanced Wireless C…\n10     3   161 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n# ℹ 90 more rows\n\n[[5]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   210 topic    https://openalex.org/T10013         Asymmetric Synthesi…\n 2     1   210 subfield https://openalex.org/subfields/1605 Organic Chemistry   \n 3     1   210 field    https://openalex.org/fields/16      Chemistry           \n 4     1   210 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   165 topic    https://openalex.org/T11549         Synthetic Organic C…\n 6     2   165 subfield https://openalex.org/subfields/1605 Organic Chemistry   \n 7     2   165 field    https://openalex.org/fields/16      Chemistry           \n 8     2   165 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   133 topic    https://openalex.org/T10302         Fish Ecology and Ma…\n10     3   133 subfield https://openalex.org/subfields/2309 Nature and Landscap…\n# ℹ 90 more rows\n\n[[6]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1    86 topic    https://openalex.org/T11087         Solidification and …\n 2     1    86 subfield https://openalex.org/subfields/2505 Materials Chemistry \n 3     1    86 field    https://openalex.org/fields/25      Materials Science   \n 4     1    86 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2    69 topic    https://openalex.org/T10039         Stellar, planetary,…\n 6     2    69 subfield https://openalex.org/subfields/3103 Astronomy and Astro…\n 7     2    69 field    https://openalex.org/fields/31      Physics and Astrono…\n 8     2    69 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3    68 topic    https://openalex.org/T10325         Astro and Planetary…\n10     3    68 subfield https://openalex.org/subfields/3103 Astronomy and Astro…\n# ℹ 90 more rows\n\n[[7]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   188 topic    https://openalex.org/T11061         Ocean Waves and Rem…\n 2     1   188 subfield https://openalex.org/subfields/1910 Oceanography        \n 3     1   188 field    https://openalex.org/fields/19      Earth and Planetary…\n 4     1   188 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   107 topic    https://openalex.org/T10891         Radar Systems and S…\n 6     2   107 subfield https://openalex.org/subfields/2202 Aerospace Engineeri…\n 7     2   107 field    https://openalex.org/fields/22      Engineering         \n 8     2   107 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3    93 topic    https://openalex.org/T10255         Oceanographic and A…\n10     3    93 subfield https://openalex.org/subfields/1910 Oceanography        \n# ℹ 90 more rows\n\n[[8]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   242 topic    https://openalex.org/T10612         Magnetism in coordi…\n 2     1   242 subfield https://openalex.org/subfields/2504 Electronic, Optical…\n 3     1   242 field    https://openalex.org/fields/25      Materials Science   \n 4     1   242 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   216 topic    https://openalex.org/T11881         Crystallization and…\n 6     2   216 subfield https://openalex.org/subfields/2505 Materials Chemistry \n 7     2   216 field    https://openalex.org/fields/25      Materials Science   \n 8     2   216 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   215 topic    https://openalex.org/T12613         X-ray Diffraction i…\n10     3   215 subfield https://openalex.org/subfields/2505 Materials Chemistry \n# ℹ 90 more rows\n\n[[9]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   120 topic    https://openalex.org/T11802         Chemical Looping an…\n 2     1   120 subfield https://openalex.org/subfields/2204 Biomedical Engineer…\n 3     1   120 field    https://openalex.org/fields/22      Engineering         \n 4     1   120 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2    78 topic    https://openalex.org/T10998         Heat Transfer and O…\n 6     2    78 subfield https://openalex.org/subfields/2210 Mechanical Engineer…\n 7     2    78 field    https://openalex.org/fields/22      Engineering         \n 8     2    78 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3    54 topic    https://openalex.org/T12696         Icing and De-icing …\n10     3    54 subfield https://openalex.org/subfields/2202 Aerospace Engineeri…\n# ℹ 90 more rows\n\n[[10]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   250 topic    https://openalex.org/T11092         Spondyloarthritis S…\n 2     1   250 subfield https://openalex.org/subfields/2745 Rheumatology        \n 3     1   250 field    https://openalex.org/fields/27      Medicine            \n 4     1   250 domain   https://openalex.org/domains/4      Health Sciences     \n 5     2   211 topic    https://openalex.org/T10469         Psoriasis: Treatmen…\n 6     2   211 subfield https://openalex.org/subfields/2403 Immunology          \n 7     2   211 field    https://openalex.org/fields/24      Immunology and Micr…\n 8     2   211 domain   https://openalex.org/domains/1      Life Sciences       \n 9     3   178 topic    https://openalex.org/T10200         Rheumatoid Arthriti…\n10     3   178 subfield https://openalex.org/subfields/2745 Rheumatology        \n# ℹ 90 more rows\n\n\nIf we print some rows from the topics tibble, we can see that it contains information on topic, subfield, field, and domain. We’ll focus on topics for now and will come back to fields later.\n\nauthors_data %&gt;%\n    select(topics) %&gt;%\n    unnest(topics) %&gt;%\n    distinct(display_name) %&gt;%\n    print(n = 30)\n\n# A tibble: 4,285 × 1\n   display_name                                \n   &lt;chr&gt;                                       \n 1 Phytochemicals and Antioxidant Activities   \n 2 Biochemistry                                \n 3 Medicine                                    \n 4 Health Sciences                             \n 5 Meat and Animal Product Quality             \n 6 Animal Science and Zoology                  \n 7 Agricultural and Biological Sciences        \n 8 Life Sciences                               \n 9 Protein Hydrolysis and Bioactive Peptides   \n10 Molecular Biology                           \n11 Biochemistry, Genetics and Molecular Biology\n12 Antioxidant Activity and Oxidative Stress   \n13 Fatty Acid Research and Health              \n14 Nutrition and Dietetics                     \n15 Nursing                                     \n16 Edible Oils Quality and Analysis            \n17 Organic Chemistry                           \n18 Chemistry                                   \n19 Physical Sciences                           \n20 Aquaculture Nutrition and Growth            \n21 Aquatic Science                             \n22 Free Radicals and Antioxidants              \n23 Advanced Chemical Sensor Technologies       \n24 Biomedical Engineering                      \n25 Engineering                                 \n26 Tea Polyphenols and Effects                 \n27 Pathology and Forensic Medicine             \n28 Nuts composition and effects                \n29 Phytoestrogen effects and research          \n30 Food Chemistry and Fat Analysis             \n# ℹ 4,255 more rows\n\n\nLet’s filter the tibble to find authors (rows in authors_data) who have worked on the topic of “migration.”\nLet’s unpack the code below.\nFirst, we create a variable called search_topic and assign it the string “migration”. We will use this value later to filter the data. Then we pipe the authors_data into the select() function, where we select the display_name column (containing author names) and the topics column, which contained nested tibbles with information about the topics on which a specific author has published.\nWe then pipe the author names and topics into the unnest() function, which unnests the topics column. In other words, we will pull the topics tibble out of the row from the dataframe and expand it so that it is it’s own tibble with separate rows. The names_sep = \"_\" parameter specifies that* when unnesting, any new column names coming from the nested structure should be concatenated with the original column name using an underscore.* For example, if the nested tibble has a column named display_name, it might become topics_display_name. Why does that matter? Because the nested tibble has columns with the same names as the tibble it’s embedded in, which can cause… chaos.\nNext, we pipe the unnested data into the filter() function. We use it to filter the rows in author_data based on whether the topics_display_name column contains the text stored in search_topic (which is “migration”). To make that happen, we use the str_detect() function to check if a string contains a specific pattern. We use a “regular expression” that ignores case differences by using the argument ignore_case = TRUE (so “Migration” or “migration” both match).\nNow we can display a list of unique authors who meet our search and filter criteria by piping the results into distinct() and then printing the first n results (in this case, 80).\n\nsearch_topic &lt;- \"migration\"\n\nauthors_data %&gt;%\n    select(display_name, topics) %&gt;%\n    unnest(topics, names_sep = \"_\") %&gt;%\n    filter(str_detect(topics_display_name, regex(search_topic, ignore_case = TRUE))) %&gt;%\n    distinct(display_name) %&gt;%\n    print(n = 80)\n\n# A tibble: 160 × 1\n   display_name             \n   &lt;chr&gt;                    \n 1 Sian Neilson             \n 2 Roger White              \n 3 Ratana Chuenpagdee       \n 4 Tony Fang                \n 5 Trevor Bell              \n 6 Lewis R. Fischer         \n 7 Eric Y. Tenkorang        \n 8 Barbara Neis             \n 9 R. J. Avery              \n10 Yang Zhen                \n11 Amin A. Muhammad Gadit   \n12 Ashlee Cunsolo           \n13 Derek Nurse              \n14 Mark C. J. Stoddart      \n15 Kelly Vodden             \n16 Stephen Bornstein        \n17 Lisa Philpott            \n18 Marilyn Porter           \n19 Shree Mulay              \n20 Tyler D. Eddy            \n21 Yanqing Yi               \n22 Diana L. Gustafson       \n23 Alex Stewart             \n24 Ben Burt                 \n25 A. Lukyn Williams        \n26 Sharon R. Roseman        \n27 Jennifer A. Selby        \n28 Gillian Kolla            \n29 Sulaimon Gıwa            \n30 Diane Tye                \n31 Victor Maddalena         \n32 Christopher P. Youé      \n33 Fern Brunger             \n34 KL MacPherson            \n35 David Close              \n36 Sonja Boon               \n37 T.E. Roche               \n38 Robert Ormsby            \n39 Benjamin Rich Zendel     \n40 Jane G. Zhu              \n41 Adrian Tanner            \n42 Lisa Rankin              \n43 Alexander Y. Shestopaloff\n44 Stephen Czarnuch         \n45 Dale Kirby               \n46 Martha Traverso-Yépez    \n47 María Andrée López Gómez \n48 Nancy Pedri              \n49 Rick Audas               \n50 Alan Hall                \n51 M. J. Anderson           \n52 Delores V. Mullings      \n53 Rochelle R. Côté         \n54 Gordon B. Cooke          \n55 Roselyne N. Okech        \n56 Bill Bigelow             \n57 Isabelle Côté            \n58 Gerald Mugford           \n59 Katherine Side           \n60 Nicholas Wells           \n61 Jaro Stacul              \n62 Maisam Najafizada        \n63 Susan Stuckless          \n64 Peter Narváez            \n65 Jean L. Briggs           \n66 Pauline Duke             \n67 Sarah Gander             \n68 Ahmed Afzal              \n69 Yorck Sommerhäuser       \n70 Natalie Beausoleil       \n71 Rainer Baehre            \n72 Valerie Burton           \n73 Frederick Johnstone      \n74 Yolande Pottie‐Sherman   \n75 Nathalie LaCoste         \n76 Hollý                    \n77 Hugh Whalen              \n78 Lisa‐Jo K. van den Scott \n79 Martin Lovelace          \n80 Jeanne Sinclair          \n# ℹ 80 more rows\n\n\nWhat are we looking at here? These are authors affiliated with Memorial University who have published at least one paper on the topic of “migration.” It also prints the author’s number of publications and citations (as indexed by OpenAlex). We got that data by developing a small pipeline that:\n\nStarts with our original dataset.\nFocuses on just the author names and their topics.\nExpands nested topic information into individual rows.\nFilters rows where the topic matches “migration”.\nRemoves duplicate author names.\nPrints the results, showing up to 80 rows.\n\nNow… change the search_topic above to search for other topics. Try “climate change” (or whatever)!"
  },
  {
    "objectID": "lectures/lecture-15-content.html#more-than-names",
    "href": "lectures/lecture-15-content.html#more-than-names",
    "title": "API Example: OpenAlexR",
    "section": "",
    "text": "OK, cool! But, once again, maybe we want to see some other information, like maybe the name of the author, the title of the publication, and the number of topics assigned to that publication. Let’s do that below and print the top 200 results.\n\nsearch_topic &lt;- \"migration\"\n\nauthors_data %&gt;%\n    select(display_name, topics, works_count, cited_by_count) %&gt;%\n    unnest(topics, names_sep = \"_\") %&gt;%\n    filter(str_detect(topics_display_name, regex(search_topic, ignore_case = TRUE))) %&gt;%\n    select(display_name, topics_display_name, topics_count, topics_display_name) %&gt;%\n    print(n = 200)\n\n# A tibble: 207 × 3\n    display_name                topics_display_name                 topics_count\n    &lt;chr&gt;                       &lt;chr&gt;                                      &lt;int&gt;\n  1 Sian Neilson                European Law and Migration                     4\n  2 Sian Neilson                Human Rights and Immigration                   3\n  3 Roger White                 Migration and Labor Dynamics                  31\n  4 Roger White                 Migration, Ethnicity, and Economy             25\n  5 Ratana Chuenpagdee          Climate Change, Adaptation, Migrat…            5\n  6 Tony Fang                   Migration and Labor Dynamics                  30\n  7 Tony Fang                   Migration, Ethnicity, and Economy             27\n  8 Tony Fang                   Diaspora, migration, transnational…            5\n  9 Trevor Bell                 Climate Change, Adaptation, Migrat…            4\n 10 Lewis R. Fischer            Migration, Policy, and Dickens Stu…            1\n 11 Eric Y. Tenkorang           Migration and Labor Dynamics                   3\n 12 Eric Y. Tenkorang           Migration, Health and Trauma                   2\n 13 Barbara Neis                Migration, Aging, and Tourism Stud…            9\n 14 Barbara Neis                Migration and Labor Dynamics                   4\n 15 R. J. Avery                 Migration, Aging, and Tourism Stud…            4\n 16 Yang Zhen                   China's Global Influence and Migra…            1\n 17 Amin A. Muhammad Gadit      Migration, Health and Trauma                   4\n 18 Ashlee Cunsolo              Climate Change, Adaptation, Migrat…            9\n 19 Derek Nurse                 Diaspora, migration, transnational…            1\n 20 Mark C. J. Stoddart         Climate Change, Adaptation, Migrat…            3\n 21 Kelly Vodden                Migration, Aging, and Tourism Stud…            5\n 22 Stephen Bornstein           Migration, Health and Trauma                   2\n 23 Lisa Philpott               Migration, Ethnicity, and Economy              2\n 24 Marilyn Porter              Migration, Ethnicity, and Economy              5\n 25 Marilyn Porter              Migration and Labor Dynamics                   3\n 26 Shree Mulay                 Migration, Health and Trauma                   3\n 27 Tyler D. Eddy               Climate Change, Adaptation, Migrat…            3\n 28 Yanqing Yi                  Migration, Health and Trauma                   7\n 29 Diana L. Gustafson          Migration, Health and Trauma                   9\n 30 Alex Stewart                Migration, Ethnicity, and Economy             14\n 31 Ben Burt                    Climate Change, Adaptation, Migrat…            6\n 32 Ben Burt                    Italian Social Issues and Migration            1\n 33 Ben Burt                    Diaspora, migration, transnational…            1\n 34 A. Lukyn Williams           European Law and Migration                     2\n 35 Sharon R. Roseman           Migration, Aging, and Tourism Stud…           12\n 36 Sharon R. Roseman           Migration and Labor Dynamics                   6\n 37 Sharon R. Roseman           Migration, Ethnicity, and Economy              5\n 38 Sharon R. Roseman           Diaspora, migration, transnational…            4\n 39 Sharon R. Roseman           Immigration and Intercultural Educ…            2\n 40 Sharon R. Roseman           Migration, Refugees, and Integrati…            2\n 41 Jennifer A. Selby           Multiculturalism, Politics, Migrat…           29\n 42 Jennifer A. Selby           Migration, Identity, and Health                3\n 43 Gillian Kolla               Migration, Health and Trauma                   2\n 44 Sulaimon Gıwa               Migration and Labor Dynamics                   5\n 45 Sulaimon Gıwa               Migration, Ethnicity, and Economy              4\n 46 Sulaimon Gıwa               Migration, Health and Trauma                   3\n 47 Sulaimon Gıwa               Migration, Refugees, and Integrati…            3\n 48 Sulaimon Gıwa               Migration, Identity, and Health                2\n 49 Diane Tye                   Migration, Ethnicity, and Economy              1\n 50 Victor Maddalena            Migration, Health and Trauma                   2\n 51 Christopher P. Youé         Migration, Ethnicity, and Economy              1\n 52 Fern Brunger                Migration, Health and Trauma                   3\n 53 KL MacPherson               China's Global Influence and Migra…            2\n 54 David Close                 Diaspora, migration, transnational…            2\n 55 Sonja Boon                  Migration, Ethnicity, and Economy              2\n 56 T.E. Roche                  Macrophage Migration Inhibitory Fa…            2\n 57 Robert Ormsby               Migration, Policy, and Dickens Stu…            1\n 58 Benjamin Rich Zendel        Migration, Aging, and Tourism Stud…            1\n 59 Jane G. Zhu                 Migration, Ethnicity, and Economy              2\n 60 Adrian Tanner               Multiculturalism, Politics, Migrat…            2\n 61 Adrian Tanner               Climate Change, Adaptation, Migrat…            1\n 62 Lisa Rankin                 Migration, Aging, and Tourism Stud…            1\n 63 Alexander Y. Shestopaloff   Migration, Health and Trauma                   2\n 64 Stephen Czarnuch            Migration, Health and Trauma                   2\n 65 Dale Kirby                  Migration, Ethnicity, and Economy              2\n 66 Dale Kirby                  Migration and Labor Dynamics                   2\n 67 Martha Traverso-Yépez       Migration, Racism, and Human Rights            2\n 68 María Andrée López Gómez    Migration, Aging, and Tourism Stud…            2\n 69 Nancy Pedri                 Diaspora, migration, transnational…            1\n 70 Rick Audas                  Migration and Labor Dynamics                   2\n 71 Alan Hall                   Migration, Identity, and Health                1\n 72 M. J. Anderson              Macrophage Migration Inhibitory Fa…            1\n 73 Delores V. Mullings         Migration and Labor Dynamics                   6\n 74 Delores V. Mullings         Migration, Health and Trauma                   4\n 75 Delores V. Mullings         Migration, Ethnicity, and Economy              3\n 76 Rochelle R. Côté            Migration, Ethnicity, and Economy              6\n 77 Rochelle R. Côté            Migration and Labor Dynamics                   3\n 78 Gordon B. Cooke             Migration, Aging, and Tourism Stud…            2\n 79 Roselyne N. Okech           Migration, Ethnicity, and Economy              2\n 80 Bill Bigelow                Migration, Ethnicity, and Economy              1\n 81 Isabelle Côté               Migration and Labor Dynamics                   4\n 82 Isabelle Côté               Migration, Refugees, and Integrati…            4\n 83 Isabelle Côté               Diaspora, migration, transnational…            2\n 84 Isabelle Côté               Migration, Identity, and Health                1\n 85 Gerald Mugford              Migration, Aging, and Tourism Stud…            2\n 86 Katherine Side              Migration, Refugees, and Integrati…            4\n 87 Nicholas Wells              Migration, Aging, and Tourism Stud…            2\n 88 Jaro Stacul                 Italian Social Issues and Migration            1\n 89 Maisam Najafizada           Migration, Health and Trauma                   2\n 90 Susan Stuckless             Migration, Aging, and Tourism Stud…            1\n 91 Peter Narváez               Migration, Ethnicity, and Economy              1\n 92 Jean L. Briggs              Migration, Education, Indigenous S…            2\n 93 Pauline Duke                Migration, Health and Trauma                   2\n 94 Sarah Gander                Migration, Health and Trauma                   4\n 95 Ahmed Afzal                 Diaspora, migration, transnational…            3\n 96 Ahmed Afzal                 Migration and Labor Dynamics                   2\n 97 Ahmed Afzal                 Migration, Ethnicity, and Economy              2\n 98 Yorck Sommerhäuser          Migration, Ethnicity, and Economy              1\n 99 Natalie Beausoleil          Multiculturalism, Politics, Migrat…            1\n100 Rainer Baehre               Migration, Ethnicity, and Economy              1\n101 Rainer Baehre               Migration and Labor Dynamics                   1\n102 Valerie Burton              Migration, Ethnicity, and Economy              3\n103 Frederick Johnstone         Migration, Ethnicity, and Economy              3\n104 Yolande Pottie‐Sherman      Migration and Labor Dynamics                   7\n105 Yolande Pottie‐Sherman      Migration, Ethnicity, and Economy              6\n106 Yolande Pottie‐Sherman      Migration, Refugees, and Integrati…            5\n107 Yolande Pottie‐Sherman      Diaspora, migration, transnational…            3\n108 Yolande Pottie‐Sherman      Migration, Aging, and Tourism Stud…            3\n109 Nathalie LaCoste            Multiculturalism, Politics, Migrat…            1\n110 Hollý                       Migration and Labor Dynamics                   1\n111 Hugh Whalen                 Multiculturalism, Politics, Migrat…            1\n112 Lisa‐Jo K. van den Scott    Diaspora, migration, transnational…            1\n113 Martin Lovelace             Migration, Ethnicity, and Economy              1\n114 Jeanne Sinclair             Migration, Aging, and Tourism Stud…            1\n115 Christopher Patey           Italian Social Issues and Migration            1\n116 Dominique Brégent‐Heald     Migration, Health, Geopolitics, Hi…            2\n117 Daze Jefferies              Migration, Ethnicity, and Economy              1\n118 David Peddle                Human Rights and Immigration                   1\n119 Stephen Harold Riggins      Diaspora, migration, transnational…            2\n120 Stephen Harold Riggins      Migration, Ethnicity, and Economy              1\n121 James Valcour               Climate Change, Adaptation, Migrat…            1\n122 Mercedes Steedman           Migration, Ethnicity, and Economy              2\n123 Ivan Emke                   European Law and Migration                     1\n124 Ivan Emke                   Migration, Health and Trauma                   1\n125 Robin Whitaker              Migration, Refugees, and Integrati…            4\n126 Robin Whitaker              Multiculturalism, Politics, Migrat…            1\n127 Lincoln Addison             Migration, Ethnicity, and Economy              3\n128 Lincoln Addison             Migration and Labor Dynamics                   1\n129 Elizabeth Yeoman            Migration, Refugees, and Integrati…            1\n130 Alessandro Giardino         Multiculturalism, Politics, Migrat…            1\n131 D. Codner                   Macrophage Migration Inhibitory Fa…            1\n132 Lesley Butler               Diaspora, migration, transnational…            1\n133 Lesley Butler               Migration, Ethnicity, and Economy              1\n134 Lesley Butler               Climate Change, Adaptation, Migrat…            1\n135 Julia Temple Newhook        Migration, Ethnicity, and Economy              1\n136 Julia Temple Newhook        Migration and Labor Dynamics                   1\n137 Donald W. Nichol            Migration, Policy, and Dickens Stu…            1\n138 John Mannion                Climate Change, Adaptation, Migrat…            1\n139 Santé A. Viselli            Multiculturalism, Politics, Migrat…            1\n140 Ronald Schwartz             Diaspora, migration, transnational…            1\n141 Brenda A. LeFrançois        Labour Market and Migration                    1\n142 Roza Tchoukaleyska          Migration, Identity, and Health                1\n143 Heidi Coombs-Thorne         Migration and Labor Dynamics                   1\n144 Robert Shea                 Migration, Refugees, and Integrati…            1\n145 Paul Alhassan Issahaku      Migration, Health and Trauma                   1\n146 Amy M. Warren               Migration, Aging, and Tourism Stud…            1\n147 Rowena Mercado              Migration, Health and Trauma                   1\n148 Kwamina Abekah‐Carter       Migration, Aging, and Tourism Stud…            2\n149 Angela J. Hyde              Macrophage Migration Inhibitory Fa…            1\n150 Sylvia Moore                Climate Change, Adaptation, Migrat…            1\n151 Christopher Curran          Migration and Labor Dynamics                   4\n152 Katie Gillespie             Migration, Health and Trauma                   4\n153 Catherine Losier            Migration, Identity, and Health                4\n154 Catherine Losier            Migration, Health, Geopolitics, Hi…            1\n155 Barry C. Gaulton            Migration, Health, Geopolitics, Hi…            1\n156 August Carbonella           Migration, Ethnicity, and Economy              4\n157 August Carbonella           Multiculturalism, Politics, Migrat…            1\n158 Nicholas Lynch              Migration, Aging, and Tourism Stud…            1\n159 Russell Dawe                Migration, Health and Trauma                   1\n160 Kodjo Attikpoé              Migration and Exile Studies                    1\n161 Lorna Bennett               Migration, Health and Trauma                   1\n162 Jennifer L. Buckle          Migration, Health and Trauma                   3\n163 Mariya Lesiv                Diaspora, migration, transnational…            2\n164 Mariya Lesiv                Migration, Ethnicity, and Economy              1\n165 John Bodner                 Multiculturalism, Politics, Migrat…            1\n166 Calvin Hollett              Migration, Aging, and Tourism Stud…            1\n167 A. K. M. Shahidullah        Climate Change, Adaptation, Migrat…            1\n168 Rebecca J. Franklin         Migration, Ethnicity, and Economy              2\n169 Beth Leavenworth DuFault    Migration, Ethnicity, and Economy              1\n170 Raquel Ruiz‐Díaz            Climate Change, Adaptation, Migrat…            3\n171 Leanna Butters              Migration, Aging, and Tourism Stud…            5\n172 Jacqueline Hesson           Migration, Health and Trauma                   1\n173 Jennifer Thorburn           Diaspora, migration, transnational…            7\n174 Jennifer Thorburn           Migration and Labor Dynamics                   7\n175 Madonna M. Murphy           Migration, Health and Trauma                   1\n176 Roberta Buchanan            Multiculturalism, Politics, Migrat…            1\n177 Sean W. D. Gray             Migration, Refugees, and Integrati…            3\n178 Cory W. Thorne              Diaspora, migration, transnational…            1\n179 Michael Skipton             Migration, Policy, and Dickens Stu…            2\n180 Neil J. Vincent             Migration, Health and Trauma                   1\n181 Devonne Ryan                Migration, Aging, and Tourism Stud…            1\n182 Margo Wilson                Migration, Health and Trauma                   1\n183 Michael D. Kirkpatrick      Migration, Ethnicity, and Economy              1\n184 Kate Lahey                  Climate Change, Adaptation, Migrat…            1\n185 Elias Bartellas             Migration, Health and Trauma                   1\n186 Mohamed Salah Eddine Madiou Climate Change, Adaptation, Migrat…            1\n187 Elise Thorburn              Migration, Aging, and Tourism Stud…            1\n188 Leslie J. Cake              Migration, Aging, and Tourism Stud…            1\n189 Hua Que                     Migration, Health and Trauma                   6\n190 Hua Que                     Migration and Labor Dynamics                   3\n191 Hua Que                     Migration, Refugees, and Integrati…            2\n192 Caroline Guinard            Migration, Identity, and Health                1\n193 Ban Younghusband            Macrophage Migration Inhibitory Fa…            1\n194 Jessica Squires             Macrophage Migration Inhibitory Fa…            1\n195 Tyler R. Pritchard          Migration, Health and Trauma                   2\n196 Raleen Murphy               Migration, Health and Trauma                   2\n197 Darren Hynes                Migration, Health, Geopolitics, Hi…            1\n198 Halia Koo                   Multiculturalism, Politics, Migrat…            1\n199 Alka Agarwal-Mawal          Macrophage Migration Inhibitory Fa…            1\n200 Jieying Xiong               Macrophage Migration Inhibitory Fa…            1\n# ℹ 7 more rows\n\n\nLet’s store this subset of data for later.\n\nmigration_authors &lt;- authors_data %&gt;%\n    select(display_name, topics, works_count, cited_by_count) %&gt;%\n    unnest(topics, names_sep = \"_\") %&gt;%\n    filter(str_detect(topics_display_name, regex(search_topic, ignore_case = TRUE))) %&gt;%\n    select(display_name, topics_display_name, topics_count, topics_display_name)"
  },
  {
    "objectID": "lectures/lecture-15-content.html#key-concepts-and-common-words",
    "href": "lectures/lecture-15-content.html#key-concepts-and-common-words",
    "title": "API Example: OpenAlexR",
    "section": "",
    "text": "What are some of the key concepts that show up in research on migration conducted by Memorial researchers? One simple way to get at this idea is to simply take every unique word that appears across titles and count the number of times it appears. It’s crude, but a useful first pass to get a sense of what we have.\nTo do this, we’ll use another package: tidytext for “natural language processing”. We’ll load the library and then start our pipeline by piping the migration_authors data into the tidytext’s unnest_tokens() function. unnest_tokens() splits the topics_display_name column into individual words (tokens). Each word becomes a separate row in the dataset, and the new column is named word. Then we pipe that output into count(word, sort = TRUE) to counts the occurrences of each unique word in the word column. The sort = TRUE argument sorts the results in descending order of frequency.\n\nlibrary(tidytext)\n\nword_counts &lt;- migration_authors %&gt;%\n    unnest_tokens(word, topics_display_name) %&gt;%\n    count(word, sort = TRUE)\n\nprint(word_counts, n = 50)\n\n# A tibble: 48 × 2\n   word                 n\n   &lt;chr&gt;            &lt;int&gt;\n 1 migration          204\n 2 and                149\n 3 health              44\n 4 economy             36\n 5 ethnicity           36\n 6 trauma              33\n 7 studies             26\n 8 dynamics            24\n 9 identity            23\n10 labor               23\n11 aging               21\n12 tourism             21\n13 adaptation          16\n14 change              16\n15 climate             16\n16 diaspora            16\n17 transnational       16\n18 gender              12\n19 multiculturalism    12\n20 politics            12\n21 integration         10\n22 refugees            10\n23 factor               9\n24 inhibitory           9\n25 macrophage           9\n26 dickens              4\n27 geography            4\n28 geopolitics          4\n29 historical           4\n30 human                4\n31 policy               4\n32 rights               4\n33 social               4\n34 european             3\n35 immigration          3\n36 issues               3\n37 italian              3\n38 law                  3\n39 china's              2\n40 education            2\n41 global               2\n42 influence            2\n43 racism               2\n44 exile                1\n45 indigenous           1\n46 intercultural        1\n47 labour               1\n48 market               1"
  },
  {
    "objectID": "lectures/lecture-15-content.html#visualizing-word-frequencies",
    "href": "lectures/lecture-15-content.html#visualizing-word-frequencies",
    "title": "API Example: OpenAlexR",
    "section": "",
    "text": "Let’s make a horizontal bar graph (where the words are on the y-axis and word frequency is on the x-axis) to visualize this distribution of words. We’ll also remove “stop words” like “and,” “of,” etc.\n\ndata(\"stop_words\")\nfiltered_word_counts &lt;- word_counts %&gt;%\n    anti_join(stop_words, by = \"word\")\n\nAnd now for the bar graph!\n\nggplot(filtered_word_counts, aes(x = reorder(word, n), y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    labs(\n        title = \"Word Frequency in Migration Research\",\n        x = \"Words\",\n        y = \"Frequency\"\n    ) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nRemember you can save your plot with the ggsave function!\nggsave(\"migration_word_frequency.png\", width = 10, height = 8)"
  },
  {
    "objectID": "lectures/lecture-15-content.html#fields",
    "href": "lectures/lecture-15-content.html#fields",
    "title": "API Example: OpenAlexR",
    "section": "",
    "text": "The topics data also include “field” classifications. These are multi-level labels attached to publications. By multi-level I mean that some labels are very high-level (e.g., social sciences, sociology) while others are most focused (e.g., sociology of gender, racial inequality). Let’s make a table counting the number of fields in the Memorial Data.\n\nfield_counts &lt;- authors_data %&gt;%\n    select(topics) %&gt;%\n    unnest(topics) %&gt;%\n    count(display_name, sort = TRUE)\n\nprint(field_counts, n = 30)\n\n# A tibble: 4,285 × 2\n   display_name                                             n\n   &lt;chr&gt;                                                &lt;int&gt;\n 1 Physical Sciences                                    19166\n 2 Social Sciences                                      19144\n 3 Health Sciences                                      11962\n 4 Medicine                                              9367\n 5 Life Sciences                                         7845\n 6 Engineering                                           5632\n 7 Environmental Science                                 3947\n 8 Biochemistry, Genetics and Molecular Biology          3740\n 9 Arts and Humanities                                   2519\n10 Computer Science                                      2375\n11 Earth and Planetary Sciences                          2334\n12 Health Professions                                    2107\n13 Agricultural and Biological Sciences                  2075\n14 Molecular Biology                                     1995\n15 Sociology and Political Science                       1958\n16 Psychology                                            1934\n17 Chemistry                                             1408\n18 General Health Professions                            1395\n19 Materials Science                                     1199\n20 Education                                             1189\n21 Neuroscience                                          1164\n22 Ecology                                               1147\n23 Physics and Astronomy                                 1121\n24 Electrical and Electronic Engineering                  943\n25 Surgery                                                903\n26 Genetics                                               894\n27 Public Health, Environmental and Occupational Health   890\n28 Economics, Econometrics and Finance                    885\n29 Business, Management and Accounting                    830\n30 Global and Planetary Change                            776\n# ℹ 4,255 more rows\n\n\nA few things jump out at me from this list of the top 30 topics. First, publication output in the physical and social sciences at Memorial are neck and neck! If you were to combine Health, Medicine, and Life Sciences, they would top the list. Arts and Humanities is pretty high on this list to, claiming the number 9 rank. Sociology and Political Science are at rank 15.\nLet’s ggplot!\n\ntop_n_fields &lt;- field_counts %&gt;%\n    top_n(100, n)\n\nggplot(top_n_fields, aes(x = reorder(display_name, n), y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    labs(\n        title = \"Top 30 Fields in Memorial University Publications\",\n        x = \"Fields\",\n        y = \"Count\"\n    ) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nWe’ll stop there for today. Tomorrow we’ll work on the second Data Stories assignment in class. It’s due on Monday March 10th."
  },
  {
    "objectID": "syllabus/syllabus.html",
    "href": "syllabus/syllabus.html",
    "title": " Quantitative Research Methods",
    "section": "",
    "text": "Course Instructor John McLevey (he/him) Professor, Department of Sociology Memorial University\n\n  mclevey@mun.ca Note: I do not check or respond to email in the evenings or on weekends.\n\n\nGraduate Assistant Felix Morrow, PhD Student Department of Sociology, Memorial University fpcmorrow@mun.ca\n\nWhere is class? CP-2003 (Chemistry-Physics, Computer Lab) When is class? Tuesdays & Thursdays, 1:30 - 2:50 pm Office Hours: A4054, Tuesdays & Thursdays, 3:00 - 4:00 pm\n\nSOCI 3040, Quantitative Research Methods, will familiarize students with the procedures for understanding and conducting quantitative social science research. It will introduce students to the quantitative research process, hypothesis development and testing, and the application of appropriate tools for analyzing quantitative data. All sections of this course count towards the HSS Quantitative Reasoning Requirement (see mun.ca/hss/qr). (PR: SOCI 1000 or the former SOCI 2000)\nThis section of SOCI 3440 is an introduction to quantitative research methods, from planning an analysis to sharing the final results. Following the workflow from Rohan Alexander’s (2023) Telling Stories with Data, you will learn how to:\nYou will use this workflow in the context of learning foundational quantitative research skills, including conducting exploratory data analyses and fitting, assessing, and interpreting linear and generalized linear models. Reproducibility and research ethics are considered throughout the workflow, and the entire course.",
    "crumbs": [
      "Syllabus",
      "<strong>SYLLABUS</strong>",
      "&nbsp;&nbsp;SOCI 3040"
    ]
  },
  {
    "objectID": "syllabus/syllabus.html#alexander2023telling-telling-stories-with-data",
    "href": "syllabus/syllabus.html#alexander2023telling-telling-stories-with-data",
    "title": " Quantitative Research Methods",
    "section": " Alexander (2023) Telling Stories with Data",
    "text": "Alexander (2023) Telling Stories with Data\n\n“This is not another statistics book. It is much better than that. It is a book about doing quantitative research, about scientific justification, about quality control, about communication and epistemic humility. It’s a valuable supplement to any methods curriculum, and useful for self-learners as well.” – Richard McElreath\n\n\n\n\n\n“This clean and fun book covers a wide range of topics on statistical communication, programming, and modeling in a way that should be a useful supplement to any statistics course or self-learning program. I absolutely love this book!” – Andrew Gelman\n\n\n“Every data analyst has to tell stories with data, and yet traditional textbooks focus on statistical methods alone. Telling Stories with Data teaches the entire data science workflow, including data acquisition, communication, and reproducibility. I highly recommend this unique book!” – Kosuke Imai\n\n\n“Telling (true) Stories with Data requires more than fancy statistical models and big data. With a series of fascinating case studies, Rohan Alexander teaches us how to ask good questions, acquire data, estimate models, and communicate our results. This holistic approach is explained with crisp and engaging prose. The pages are filled with detailed R examples, which emphasize the importance of transparency and reproducibility. I absolutely love this book and recommend it to all my students.” – Vincent Arel-Bundock\n\n\n“An excellent book. Communication and reproducibility are of increasing concern in statistics, and this book covers these topics and more in a practical, appealing, and truly unique way.” – Daniela Witten",
    "crumbs": [
      "Syllabus",
      "<strong>SYLLABUS</strong>",
      "&nbsp;&nbsp;SOCI 3040"
    ]
  },
  {
    "objectID": "syllabus/syllabus.html#recommended-optional",
    "href": "syllabus/syllabus.html#recommended-optional",
    "title": " Quantitative Research Methods",
    "section": "Recommended / Optional",
    "text": "Recommended / Optional\nYou may also wish to consult Kieran Healy’s (2019) Data Visualization: A Practical Introduction, which is also available for free online, in full.\n\n Healy (2019) Data Visualization\n\n“Finally! A data visualization guide that is simultaneously practical and elegant. … Data Visualization is brimming with insights into how quantitative analysts can use visualization as a tool for understanding and communication. A must-read for anyone who works with data.” – Elizabeth Bruch\n\n\n\n\n\n“Healy’s fun and readable book is unusual in covering the ‘why do’ as well as the ‘how to’ of data visualization, demonstrating how dataviz is a key step in all stages of social science – from theory construction to measurement to modeling and interpretation of analyses―and giving readers the tools to integrate visualization into their own work.” – Andrew Gelman\n\n\n“Data Visualization is a brilliant book that not only teaches the reader how to visualize data but also carefully considers why data visualization is essential for good social science. The book is broadly relevant, beautifully rendered, and engagingly written. It is easily accessible for students at any level and will be an incredible teaching resource for courses on research methods, statistics, and data visualization. It is packed full of clear-headed and sage insights.” – Becky Pettit\n\n\n“Kieran Healy has written a wonderful book that fills an important niche in an increasingly crowded landscape of materials about software in R. Data Visualization is clear, beautifully formatted, and full of careful insights.” – Brandon Stewart",
    "crumbs": [
      "Syllabus",
      "<strong>SYLLABUS</strong>",
      "&nbsp;&nbsp;SOCI 3040"
    ]
  },
  {
    "objectID": "lectures/lecture-03-content.html",
    "href": "lectures/lecture-03-content.html",
    "title": "Drinking From the Firehose",
    "section": "",
    "text": "flowchart LR\n  p[[Plan]]\n  sim[[Simulate]]\n  a[[Acquire]]\n  e[[Explore/Understand]]\n  s[[Share]]\n\n  p --&gt; sim --&gt; a --&gt; e --&gt; s\n\n\n Rohan Alexander’s [-@alexander2023telling] Telling Stories with Data workflow \n\n\n\n\n\nAustralian elections\nToronto shelters\nNeonatal mortality rates (NMR)\n\n\n\n\n\nWhenever you’re learning a new tool, for a long time, you’re going to suck\\(\\dots\\) But the good news is that is typical; that’s something that happens to everyone, and it’s only temporary.\nHadley Wickham as quoted by @citeBarrett\n\n\n\nYou will be guided thoroughly here. Hopefully by experiencing the excitement of telling stories with data, you will feel empowered to stick with it.\nRohan @alexander2023telling\n\n\n\n\n\n\n\nlibrary(\"janitor\")\nlibrary(\"knitr\")\nlibrary(\"lubridate\")\nlibrary(\"opendatatoronto\")\nlibrary(\"tidyverse\")\nlibrary(\"here\")"
  },
  {
    "objectID": "lectures/lecture-03-content.html#the-firehose",
    "href": "lectures/lecture-03-content.html#the-firehose",
    "title": "Drinking From the Firehose",
    "section": "",
    "text": "flowchart LR\n  p[[Plan]]\n  sim[[Simulate]]\n  a[[Acquire]]\n  e[[Explore/Understand]]\n  s[[Share]]\n\n  p --&gt; sim --&gt; a --&gt; e --&gt; s\n\n\n Rohan Alexander’s [-@alexander2023telling] Telling Stories with Data workflow \n\n\n\n\n\nAustralian elections\nToronto shelters\nNeonatal mortality rates (NMR)"
  },
  {
    "objectID": "lectures/lecture-03-content.html#the-firehose-1",
    "href": "lectures/lecture-03-content.html#the-firehose-1",
    "title": "Drinking From the Firehose",
    "section": "",
    "text": "Whenever you’re learning a new tool, for a long time, you’re going to suck\\(\\dots\\) But the good news is that is typical; that’s something that happens to everyone, and it’s only temporary.\nHadley Wickham as quoted by @citeBarrett\n\n\n\nYou will be guided thoroughly here. Hopefully by experiencing the excitement of telling stories with data, you will feel empowered to stick with it.\nRohan @alexander2023telling"
  },
  {
    "objectID": "lectures/lecture-03-content.html#import-libraries",
    "href": "lectures/lecture-03-content.html#import-libraries",
    "title": "Drinking From the Firehose",
    "section": "",
    "text": "library(\"janitor\")\nlibrary(\"knitr\")\nlibrary(\"lubridate\")\nlibrary(\"opendatatoronto\")\nlibrary(\"tidyverse\")\nlibrary(\"here\")"
  },
  {
    "objectID": "lectures/lecture-03-content.html#plan-1",
    "href": "lectures/lecture-03-content.html#plan-1",
    "title": "Drinking From the Firehose",
    "section": "plan",
    "text": "plan\n\n\nAustralian Elections\n\n\n\n\n\n\nHow many seats did each political party win in the 2022 Australian Federal Election?\n\n\n\n Australia is a parliamentary democracywith 151 seats in the House of Representatives. \nMajor parties: Liberal and Labour Minor parties: Nationals and Greens Many smaller parties and independents"
  },
  {
    "objectID": "lectures/lecture-03-content.html#plan-2",
    "href": "lectures/lecture-03-content.html#plan-2",
    "title": "Drinking From the Firehose",
    "section": "plan",
    "text": "plan\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch of a possible dataset to create a graph\n\n\n\n\n\n\n\n\n\n\n\n(b) Sketch of a possible graph to answer our question\n\n\n\n\n\n\n\nFigure 1: Sketches of a potential dataset and graph related to an Australian election. The basic requirement for the dataset is that it has the name of the seat (i.e., a “division” in Australia) and the party of the person elected."
  },
  {
    "objectID": "lectures/lecture-03-content.html#simulate-1",
    "href": "lectures/lecture-03-content.html#simulate-1",
    "title": "Drinking From the Firehose",
    "section": "simulate",
    "text": "simulate\n\n\nlibrary(tidyverse)\nlibrary(janitor)"
  },
  {
    "objectID": "lectures/lecture-03-content.html#simulate-2",
    "href": "lectures/lecture-03-content.html#simulate-2",
    "title": "Drinking From the Firehose",
    "section": "simulate",
    "text": "simulate\n\nWe’ll simulate a dataset with two variables,Division and Party, and some values for each.\n\ndivisionthe name of one of the 131 Australian divisions  partythe name of one of the political partiesLiberal, Labor, National, Green, or Other"
  },
  {
    "objectID": "lectures/lecture-03-content.html#simulate-3",
    "href": "lectures/lecture-03-content.html#simulate-3",
    "title": "Drinking From the Firehose",
    "section": "simulate",
    "text": "simulate\n\n\nsimulated_data &lt;-\n    tibble(\n        # Use 1 through to 151 to represent each division\n        \"Division\" = 1:151,\n        # Randomly pick an option, with replacement, 151 times\n        \"Party\" = sample(\n            x = c(\"Liberal\", \"Labor\", \"National\", \"Green\", \"Other\"),\n            size = 151,\n            replace = TRUE\n        )\n    )\n\n\nThe &lt;- symbol is an assignment operator in R. It assigns the value on the right to the variable name on the left. Here, we’re creating a new data object called simulated_data, which will store a table of simulated information.\ntibble() is a function from the tidyverse package that creates a data frame, which is a type of table used to organize data. Unlike traditional data frames, tibble handles data more cleanly and is especially useful in data analysis.\nInside the tibble() function, we specify columns and the values we want in each. On Line 4, we create a column named “Division”. 1:151 generates a sequence of numbers from 1 to 151. This sequence will represent each unique division (or group) in our simulated dataset and helps to identify each row in the data.\nThen we create another column in our tibble called Party. sample() is a function that randomly selects values from a specified set. Here, it’s used to pick a political party for each division, simulating party representation across divisions.\nx defines the set of values that sample() will pick from. The c() function combines these five options — “Liberal”, “Labor”, “National”, “Green”, and “Other” — into a list of possible parties. In other words, each division will be randomly assigned one of these five party names, representing the political party that wins the division in our simulation. size = 151 specifies that sample() should generate 151 random selections, matching the number of divisions we created in the “Division” column.\nWhen sampling, replace = TRUE allows each party name to be selected multiple times, as though we’re picking “with replacement” (i.e., once we sample a party name, it goes back into the bag so it can be drawn again). Without this, each party could only be chosen once, which wouldn’t match our goal of assigning a random party to each division.\nWe can print the simulated_data object to view the simulated dataset. When we run this line, R will display the table with two columns, Division and Party, where each division is assigned one of the five parties randomly."
  },
  {
    "objectID": "lectures/lecture-03-content.html#simulate-4",
    "href": "lectures/lecture-03-content.html#simulate-4",
    "title": "Drinking From the Firehose",
    "section": "simulate",
    "text": "simulate\n🤘 We have our fake data!\n\nsimulated_data\n\n# A tibble: 151 × 2\n   Division Party   \n      &lt;int&gt; &lt;chr&gt;   \n 1        1 Green   \n 2        2 Liberal \n 3        3 Other   \n 4        4 Other   \n 5        5 National\n 6        6 Green   \n 7        7 Green   \n 8        8 Other   \n 9        9 Liberal \n10       10 Labor   \n# ℹ 141 more rows"
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-1",
    "href": "lectures/lecture-03-content.html#acquire-1",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\nThe data we want is provided by the Australian Electoral Commission (AEC), which is the non-partisan agency that organizes Australian federal elections. We can download the data using this link, but we want to do it programatically, storing the results to a dataframe object called raw_elections_data.\n\n\ndata_url &lt;- \"https://results.aec.gov.au/27966/website/Downloads/HouseMembersElectedDownload-27966.csv\"\n\nraw_elections_data &lt;-\n    read_csv(\n        file = data_url,\n        show_col_types = FALSE,\n        skip = 1\n    )"
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-2",
    "href": "lectures/lecture-03-content.html#acquire-2",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\nWe’ll save the data as a CSV file.\n\nlibrary(here)\n\nwrite_csv(\n    x = raw_elections_data,\n    file = here(\"data\", \"australian_voting.csv\")\n)\n\n\n\n\n\n\n\n\n✌️ R Tip\nThe here() function, from the here library, simplifies file paths by always referencing the root directory for a project. This makes code more reproducible and eliminates issues with working directories, especially when you are using more than one machine, collaborating, or sharing code with someone else. Jenny Bryan wrote a brief “Ode to the here package,” “here here,” which you can read… here."
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-3",
    "href": "lectures/lecture-03-content.html#acquire-3",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n🤘 We have our real data!\n\n\nraw_elections_data\n\n# A tibble: 151 × 8\n   DivisionID DivisionNm StateAb CandidateID GivenNm Surname\n        &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1        179 Adelaide   SA            36973 Steve   GEORGA…\n 2        197 Aston      VIC           36704 Alan    TUDGE  \n 3        198 Ballarat   VIC           36409 Cather… KING   \n 4        103 Banks      NSW           37018 David   COLEMAN\n 5        180 Barker     SA            37083 Tony    PASIN  \n 6        104 Barton     NSW           36820 Linda   BURNEY \n 7        192 Bass       TAS           37134 Bridge… ARCHER \n 8        318 Bean       ACT           36231 David   SMITH  \n 9        200 Bendigo    VIC           36424 Lisa    CHESTE…\n10        105 Bennelong  NSW           36827 Jerome  LAXALE \n# ℹ 141 more rows\n# ℹ 2 more variables: PartyNm &lt;chr&gt;, PartyAb &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-4",
    "href": "lectures/lecture-03-content.html#acquire-4",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\nhead() shows the first six rows.\n\n\nhead(raw_elections_data)\n\n# A tibble: 6 × 8\n  DivisionID DivisionNm StateAb CandidateID GivenNm  Surname\n       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  \n1        179 Adelaide   SA            36973 Steve    GEORGA…\n2        197 Aston      VIC           36704 Alan     TUDGE  \n3        198 Ballarat   VIC           36409 Catheri… KING   \n4        103 Banks      NSW           37018 David    COLEMAN\n5        180 Barker     SA            37083 Tony     PASIN  \n6        104 Barton     NSW           36820 Linda    BURNEY \n# ℹ 2 more variables: PartyNm &lt;chr&gt;, PartyAb &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-5",
    "href": "lectures/lecture-03-content.html#acquire-5",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\ntail() shows the last six rows.\n\n\ntail(raw_elections_data)\n\n# A tibble: 6 × 8\n  DivisionID DivisionNm StateAb CandidateID GivenNm  Surname\n       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  \n1        152 Wentworth  NSW           37451 Allegra  SPENDER\n2        153 Werriwa    NSW           36810 Anne Ma… STANLEY\n3        150 Whitlam    NSW           36811 Stephen  JONES  \n4        178 Wide Bay   QLD           37506 Llew     O'BRIEN\n5        234 Wills      VIC           36452 Peter    KHALIL \n6        316 Wright     QLD           37500 Scott    BUCHHO…\n# ℹ 2 more variables: PartyNm &lt;chr&gt;, PartyAb &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-6",
    "href": "lectures/lecture-03-content.html#acquire-6",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\n“We are trying to make it similar to the dataset that we thought we wanted in the planning stage. While it is fine to move away from the plan, this needs to be a deliberate, reasoned decision.” [@alexander2023telling]\n\n\nLet’s clean.\n\naus_voting_data &lt;- here(\"data\", \"australian_voting.csv\")\n\nraw_elections_data &lt;-\n    read_csv(\n        file = aus_voting_data,\n        show_col_types = FALSE\n    )"
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-7",
    "href": "lectures/lecture-03-content.html#acquire-7",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\nclean_names() makes variables easier to type.\n\ncleaned_elections_data &lt;- clean_names(raw_elections_data)\n\n Let’s look at the first 6 rows.\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 8\n  division_id division_nm state_ab candidate_id given_nm \n        &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;    \n1         179 Adelaide    SA              36973 Steve    \n2         197 Aston       VIC             36704 Alan     \n3         198 Ballarat    VIC             36409 Catherine\n4         103 Banks       NSW             37018 David    \n5         180 Barker      SA              37083 Tony     \n6         104 Barton      NSW             36820 Linda    \n# ℹ 3 more variables: surname &lt;chr&gt;, party_nm &lt;chr&gt;,\n#   party_ab &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-8",
    "href": "lectures/lecture-03-content.html#acquire-8",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\n\n\n\n\n\n✌️ R Tip\nWe can choose certain variables of interest with select() from dplyr, which we loaded as part of the tidyverse. The pipe operator |&gt; pushes the output of one line to be the first input of the function on the next line.\n\n\n\n\nWe are primarily interested in two variables:\ndivision_nm (division name)party_nm (party name)\n\n\ncleaned_elections_data &lt;-\n    cleaned_elections_data |&gt;\n    select(\n        division_nm,\n        party_nm\n    )"
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-9",
    "href": "lectures/lecture-03-content.html#acquire-9",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division_nm party_nm              \n  &lt;chr&gt;       &lt;chr&gt;                 \n1 Adelaide    Australian Labor Party\n2 Aston       Liberal               \n3 Ballarat    Australian Labor Party\n4 Banks       Liberal               \n5 Barker      Liberal               \n6 Barton      Australian Labor Party\n\n\n\nThis looks good, but some of the variable names are still not obvious because they are abbreviated."
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-10",
    "href": "lectures/lecture-03-content.html#acquire-10",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\n\n\n\n\n\n\n✌️ R Tip\nWe can look at the names of the columns (i.e., variables) in a dataset using names(). We can change them using rename() from dplyr.\n\n\n\n\nnames(cleaned_elections_data)\n\n[1] \"division_nm\" \"party_nm\"   \n\n\n\nLet’s rename."
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-11",
    "href": "lectures/lecture-03-content.html#acquire-11",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\n\ncleaned_elections_data &lt;-\n    cleaned_elections_data |&gt;\n    rename(\n        division = division_nm,\n        elected_party = party_nm\n    )\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division elected_party         \n  &lt;chr&gt;    &lt;chr&gt;                 \n1 Adelaide Australian Labor Party\n2 Aston    Liberal               \n3 Ballarat Australian Labor Party\n4 Banks    Liberal               \n5 Barker   Liberal               \n6 Barton   Australian Labor Party"
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-12",
    "href": "lectures/lecture-03-content.html#acquire-12",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\nWhat are the unique values in elected_party?\n\ncleaned_elections_data$elected_party |&gt;\n    unique()\n\n[1] \"Australian Labor Party\"              \n[2] \"Liberal\"                             \n[3] \"Liberal National Party of Queensland\"\n[4] \"The Greens\"                          \n[5] \"The Nationals\"                       \n[6] \"Independent\"                         \n[7] \"Katter's Australian Party (KAP)\"     \n[8] \"Centre Alliance\"                     \n\n\n\nCool, but let’s simplify the party names in elected_party to match what we simulated. We can do this with case_match() from dplyr."
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-13",
    "href": "lectures/lecture-03-content.html#acquire-13",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\n\ncleaned_elections_data &lt;-\n    cleaned_elections_data |&gt;\n    mutate(\n        elected_party =\n            case_match(\n                elected_party,\n                \"Australian Labor Party\" ~ \"Labor\",\n                \"Liberal National Party of Queensland\" ~ \"Liberal\",\n                \"Liberal\" ~ \"Liberal\",\n                \"The Nationals\" ~ \"Nationals\",\n                \"The Greens\" ~ \"Greens\",\n                \"Independent\" ~ \"Other\",\n                \"Katter's Australian Party (KAP)\" ~ \"Other\",\n                \"Centre Alliance\" ~ \"Other\"\n            )\n    )"
  },
  {
    "objectID": "lectures/lecture-03-content.html#acquire-14",
    "href": "lectures/lecture-03-content.html#acquire-14",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division elected_party\n  &lt;chr&gt;    &lt;chr&gt;        \n1 Adelaide Labor        \n2 Aston    Liberal      \n3 Ballarat Labor        \n4 Banks    Liberal      \n5 Barker   Liberal      \n6 Barton   Labor        \n\n\n\nOur data now matches our plan! 😎"
  },
  {
    "objectID": "lectures/lecture-03-content.html#aus_elections_clean_path",
    "href": "lectures/lecture-03-content.html#aus_elections_clean_path",
    "title": "Drinking From the Firehose",
    "section": "acquire",
    "text": "acquire\n\nLet’s save the cleaned data so that we can start with it data in the next stage. We’ll use a new filename to preserve the original and make it easy to identify the clean version.\n\naus_elections_clean_path &lt;- here(\"data\", \"cleaned_elections_data.csv\")\n\nwrite_csv(\n    x = cleaned_elections_data,\n    file = aus_elections_clean_path\n)"
  },
  {
    "objectID": "lectures/lecture-03-content.html#explore-understand-1",
    "href": "lectures/lecture-03-content.html#explore-understand-1",
    "title": "Drinking From the Firehose",
    "section": "explore / understand",
    "text": "explore / understand\n\n\n\n How do we build the graph that we planned?"
  },
  {
    "objectID": "lectures/lecture-03-content.html#explore-understand-2",
    "href": "lectures/lecture-03-content.html#explore-understand-2",
    "title": "Drinking From the Firehose",
    "section": "explore / understand",
    "text": "explore / understand\n\nFirst, we read in the cleaned dataset that we just created.\n\ncleaned_elections_data &lt;-\n    read_csv(\n        file = aus_elections_clean_path,\n        show_col_types = FALSE\n    )\n\n\n\n\n\n\n\n\n✌️ R Tip\n\n\n\nI’m using the filepath object I previously created: aus_elections_clean_path.\n\naus_elections_clean_path\n\n[1] \"/Users/johnmclevey/SOCI3040/data/cleaned_elections_data.csv\"\n\n\n This won’t work in a new script unless we re-create the object. Can you explain why?"
  },
  {
    "objectID": "lectures/lecture-03-content.html#explore-understand-3",
    "href": "lectures/lecture-03-content.html#explore-understand-3",
    "title": "Drinking From the Firehose",
    "section": "explore / understand",
    "text": "explore / understand\n\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division elected_party\n  &lt;chr&gt;    &lt;chr&gt;        \n1 Adelaide Labor        \n2 Aston    Liberal      \n3 Ballarat Labor        \n4 Banks    Liberal      \n5 Barker   Liberal      \n6 Barton   Labor        \n\n\n😎"
  },
  {
    "objectID": "lectures/lecture-03-content.html#explore-understand-4",
    "href": "lectures/lecture-03-content.html#explore-understand-4",
    "title": "Drinking From the Firehose",
    "section": "explore / understand",
    "text": "explore / understand\n\n\n\n\n\n\nHow many seats did each party win?\n\n\n\n\nWe can get a quick count with count() from dplyr.\n\ncleaned_elections_data |&gt;\n    count(elected_party)\n\n# A tibble: 5 × 2\n  elected_party     n\n  &lt;chr&gt;         &lt;int&gt;\n1 Greens            4\n2 Labor            77\n3 Liberal          48\n4 Nationals        10\n5 Other            12"
  },
  {
    "objectID": "lectures/lecture-03-content.html#explore-understand-5",
    "href": "lectures/lecture-03-content.html#explore-understand-5",
    "title": "Drinking From the Firehose",
    "section": "explore / understand",
    "text": "explore / understand\n\n\n\n\n\n\nRemember, we’re trying to make something like this.\n\n\n\n\n\n\n\n\n\n✌️ R Tip\n\n\n\nThe grammar of graphics is a conceptual framework for constructing data visualizations. It breaks down plots to their most basic elements, like data, scales, geoms (geometric objects), coordinates, and statistical transformations. The idea is to plan and build our vizualizations by layering these basic elements together rather than mindlessly relying on generic chart types.\nggplot2, a data visualization library from the tidyverse, is designed around the grammar of graphics idea. We build data visualizations by layering the desired elements of our plots. For example, we use aes() to specify aesthetic mappings that link our data to visual elements like position, color, size, shape, and transparency. We can create and tweak just about any visualization we want by layering data, aesthetics, and geoms using the add operator, +.\n\n\n\n\n\n, allowing the viewer to interpret the values and relationships in the dataset visually. By mapping data to these properties, we can layer information on the same plot and enhance the viewer’s understanding of patterns, trends, and differences.\nIn ggplot2, aesthetics are specified within the aes() function, where each aesthetic is mapped to a data variable. For instance, x and y represent positions on the axes, while color, fill, size, and shape control other visual aspects. By carefully selecting aesthetics, we can add depth to the plot without clutter, guiding the viewer’s eye to the most important parts."
  },
  {
    "objectID": "lectures/lecture-03-content.html#explore-understand-6",
    "href": "lectures/lecture-03-content.html#explore-understand-6",
    "title": "Drinking From the Firehose",
    "section": "explore / understand",
    "text": "explore / understand\n\nLet’s visualize the counts as vertical bars using geom_bar() from ggplot2.\n\nggplot(\n    cleaned_elections_data, # specify the data\n    aes(x = elected_party) # specify aesthetics\n) + # add a layer with the + operator\n    geom_bar() # specify a geometric shape (bar)\n\n\nBut it’s cleaner to use the pipe operator |&gt;.\n\ncleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar()\n\n\n\n\n\n\n\nFigure 2: Meh. We can do better."
  },
  {
    "objectID": "lectures/lecture-03-content.html#explore-understand-7",
    "href": "lectures/lecture-03-content.html#explore-understand-7",
    "title": "Drinking From the Firehose",
    "section": "explore / understand",
    "text": "explore / understand\n\n\ncleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar() +\n    theme_minimal() + # Improve the theme\n    labs(x = \"Party\", y = \"Number of seats\") # Improve the labels\n\n\n\n\n\n\n\nFigure 3: Number of seats won, by political party, at the 2022 Australian Federal Election. 😎"
  },
  {
    "objectID": "lectures/lecture-03-content.html#section",
    "href": "lectures/lecture-03-content.html#section",
    "title": "Drinking From the Firehose",
    "section": "",
    "text": "cleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar()\n\ncleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar() +\n    theme_minimal() +\n    labs(x = \"Party\", y = \"Number of seats\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Default theme and labels\n\n\n\n\n\n\n\n\n\n\n\n(b) Improved theme and labels\n\n\n\n\n\n\n\nFigure 4: Both versions of the plot, and the code that produced them, side-by-side for comparison."
  },
  {
    "objectID": "lectures/lecture-03-content.html#share-1",
    "href": "lectures/lecture-03-content.html#share-1",
    "title": "Drinking From the Firehose",
    "section": "share",
    "text": "share\nExample taken directly from @alexander2023telling, here.\n\n\n\n\n\n\nAustralia is a parliamentary democracy with 151 seats in the House of Representatives, which is the house from which government is formed. There are two major parties—“Liberal” and “Labor”—two minor parties—“Nationals” and “Greens”—and many smaller parties. The 2022 Federal Election occurred on 21 May, and around 15 million votes were cast. We were interested in the number of seats that were won by each party.\nWe downloaded the results, on a seat-specific basis, from the Australian Electoral Commission website. We cleaned and tidied the dataset using the statistical programming language R [@citeR] including the tidyverse [@tidyverse] and janitor [@janitor]. We then created a graph of the number of seats that each political party won (Figure 3).\nWe found that the Labor Party won 77 seats, followed by the Liberal Party with 48 seats. The minor parties won the following number of seats: the Nationals won 10 seats and the Greens won 4 seats. Finally, there were 10 Independents elected as well as candidates from smaller parties.\nThe distribution of seats is skewed toward the two major parties which could reflect relatively stable preferences on the part of Australian voters, or possibly inertia due to the benefits of already being a major party such a national network or funding. A better understanding of the reasons for this distribution are of interest in future work. While the dataset consists of everyone who voted, it worth noting that in Australia some are systematically excluded from voting, and it is much more difficult for some to vote than others.\n\n\n\n\nOne aspect to be especially concerned with is making sure that this communication is focused on the needs of the audience and telling a story. Data journalism provides some excellent examples of how analysis needs to be tailored to the audience, for instance, @biasbehindbars and @bronnerftw."
  },
  {
    "objectID": "lectures/lecture-03-notes.html",
    "href": "lectures/lecture-03-notes.html",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "",
    "text": "Lecture Slides\nView slides in full screen\nClass Notes"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#the-firehose",
    "href": "lectures/lecture-03-notes.html#the-firehose",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.1 the firehose",
    "text": "1.1 the firehose\n\n\n\n\n\nflowchart LR\n  p[[Plan]]\n  sim[[Simulate]]\n  a[[Acquire]]\n  e[[Explore/Understand]]\n  s[[Share]]\n\n  p --&gt; sim --&gt; a --&gt; e --&gt; s\n\n\n Rohan Alexander’s (2023) Telling Stories with Data workflow \n\n\n\n\n\nAustralian elections\nToronto shelters\nNeonatal mortality rates (NMR)"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#the-firehose-1",
    "href": "lectures/lecture-03-notes.html#the-firehose-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.2 the firehose",
    "text": "1.2 the firehose\n\nWhenever you’re learning a new tool, for a long time, you’re going to suck\\(\\dots\\) But the good news is that is typical; that’s something that happens to everyone, and it’s only temporary.\nHadley Wickham as quoted by Barrett (2021)\n\n\n\nYou will be guided thoroughly here. Hopefully by experiencing the excitement of telling stories with data, you will feel empowered to stick with it.\nRohan Alexander (2023)"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#import-libraries",
    "href": "lectures/lecture-03-notes.html#import-libraries",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.3 import libraries",
    "text": "1.3 import libraries\n\n\nlibrary(\"janitor\")\nlibrary(\"knitr\")\nlibrary(\"lubridate\")\nlibrary(\"opendatatoronto\")\nlibrary(\"tidyverse\")\nlibrary(\"here\")"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#plan-1",
    "href": "lectures/lecture-03-notes.html#plan-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "2.1 plan",
    "text": "2.1 plan\n\n\n2.1.1 Australian Elections\n\n\n\n\n\n\nHow many seats did each political party win in the 2022 Australian Federal Election?\n\n\n\n Australia is a parliamentary democracywith 151 seats in the House of Representatives. \nMajor parties: Liberal and Labour Minor parties: Nationals and Greens Many smaller parties and independents"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#plan-2",
    "href": "lectures/lecture-03-notes.html#plan-2",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "2.2 plan",
    "text": "2.2 plan\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch of a possible dataset to create a graph\n\n\n\n\n\n\n\n\n\n\n\n(b) Sketch of a possible graph to answer our question\n\n\n\n\n\n\n\nFigure 1: Sketches of a potential dataset and graph related to an Australian election. The basic requirement for the dataset is that it has the name of the seat (i.e., a “division” in Australia) and the party of the person elected."
  },
  {
    "objectID": "lectures/lecture-03-notes.html#simulate-1",
    "href": "lectures/lecture-03-notes.html#simulate-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "3.1 simulate",
    "text": "3.1 simulate\n\n\nlibrary(tidyverse)\nlibrary(janitor)"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#simulate-2",
    "href": "lectures/lecture-03-notes.html#simulate-2",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "3.2 simulate",
    "text": "3.2 simulate\n\nWe’ll simulate a dataset with two variables,Division and Party, and some values for each.\n\ndivisionthe name of one of the 131 Australian divisions  partythe name of one of the political partiesLiberal, Labor, National, Green, or Other"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#simulate-3",
    "href": "lectures/lecture-03-notes.html#simulate-3",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "3.3 simulate",
    "text": "3.3 simulate\n\n\nsimulated_data &lt;-\n    tibble(\n        # Use 1 through to 151 to represent each division\n        \"Division\" = 1:151,\n        # Randomly pick an option, with replacement, 151 times\n        \"Party\" = sample(\n            x = c(\"Liberal\", \"Labor\", \"National\", \"Green\", \"Other\"),\n            size = 151,\n            replace = TRUE\n        )\n    )\n\n\nThe &lt;- symbol is an assignment operator in R. It assigns the value on the right to the variable name on the left. Here, we’re creating a new data object called simulated_data, which will store a table of simulated information.\ntibble() is a function from the tidyverse package that creates a data frame, which is a type of table used to organize data. Unlike traditional data frames, tibble handles data more cleanly and is especially useful in data analysis.\nInside the tibble() function, we specify columns and the values we want in each. On Line 4, we create a column named “Division”. 1:151 generates a sequence of numbers from 1 to 151. This sequence will represent each unique division (or group) in our simulated dataset and helps to identify each row in the data.\nThen we create another column in our tibble called Party. sample() is a function that randomly selects values from a specified set. Here, it’s used to pick a political party for each division, simulating party representation across divisions.\nx defines the set of values that sample() will pick from. The c() function combines these five options — “Liberal”, “Labor”, “National”, “Green”, and “Other” — into a list of possible parties. In other words, each division will be randomly assigned one of these five party names, representing the political party that wins the division in our simulation. size = 151 specifies that sample() should generate 151 random selections, matching the number of divisions we created in the “Division” column.\nWhen sampling, replace = TRUE allows each party name to be selected multiple times, as though we’re picking “with replacement” (i.e., once we sample a party name, it goes back into the bag so it can be drawn again). Without this, each party could only be chosen once, which wouldn’t match our goal of assigning a random party to each division.\nWe can print the simulated_data object to view the simulated dataset. When we run this line, R will display the table with two columns, Division and Party, where each division is assigned one of the five parties randomly."
  },
  {
    "objectID": "lectures/lecture-03-notes.html#simulate-4",
    "href": "lectures/lecture-03-notes.html#simulate-4",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "3.4 simulate",
    "text": "3.4 simulate\n🤘 We have our fake data!\n\nsimulated_data\n\n# A tibble: 151 × 2\n   Division Party   \n      &lt;int&gt; &lt;chr&gt;   \n 1        1 Liberal \n 2        2 Other   \n 3        3 Liberal \n 4        4 Green   \n 5        5 Labor   \n 6        6 Labor   \n 7        7 Other   \n 8        8 Labor   \n 9        9 Other   \n10       10 National\n# ℹ 141 more rows"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-1",
    "href": "lectures/lecture-03-notes.html#acquire-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.1 acquire",
    "text": "4.1 acquire\n\nThe data we want is provided by the Australian Electoral Commission (AEC), which is the non-partisan agency that organizes Australian federal elections. We can download the data using this link, but we want to do it programatically, storing the results to a dataframe object called raw_elections_data.\n\n\ndata_url &lt;- \"https://results.aec.gov.au/27966/website/Downloads/HouseMembersElectedDownload-27966.csv\"\n\nraw_elections_data &lt;-\n    read_csv(\n        file = data_url,\n        show_col_types = FALSE,\n        skip = 1\n    )"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-2",
    "href": "lectures/lecture-03-notes.html#acquire-2",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.2 acquire",
    "text": "4.2 acquire\n\nWe’ll save the data as a CSV file.\n\nlibrary(here)\n\nwrite_csv(\n    x = raw_elections_data,\n    file = here(\"data\", \"australian_voting.csv\")\n)\n\n\n\n\n\n\n\n\n✌️ R Tip\nThe here() function, from the here library, simplifies file paths by always referencing the root directory for a project. This makes code more reproducible and eliminates issues with working directories, especially when you are using more than one machine, collaborating, or sharing code with someone else. Jenny Bryan wrote a brief “Ode to the here package,” “here here,” which you can read… here."
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-3",
    "href": "lectures/lecture-03-notes.html#acquire-3",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.3 acquire",
    "text": "4.3 acquire\n🤘 We have our real data!\n\n\nraw_elections_data\n\n# A tibble: 151 × 8\n   DivisionID DivisionNm StateAb CandidateID GivenNm Surname\n        &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1        179 Adelaide   SA            36973 Steve   GEORGA…\n 2        197 Aston      VIC           36704 Alan    TUDGE  \n 3        198 Ballarat   VIC           36409 Cather… KING   \n 4        103 Banks      NSW           37018 David   COLEMAN\n 5        180 Barker     SA            37083 Tony    PASIN  \n 6        104 Barton     NSW           36820 Linda   BURNEY \n 7        192 Bass       TAS           37134 Bridge… ARCHER \n 8        318 Bean       ACT           36231 David   SMITH  \n 9        200 Bendigo    VIC           36424 Lisa    CHESTE…\n10        105 Bennelong  NSW           36827 Jerome  LAXALE \n# ℹ 141 more rows\n# ℹ 2 more variables: PartyNm &lt;chr&gt;, PartyAb &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-4",
    "href": "lectures/lecture-03-notes.html#acquire-4",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.4 acquire",
    "text": "4.4 acquire\nhead() shows the first six rows.\n\n\nhead(raw_elections_data)\n\n# A tibble: 6 × 8\n  DivisionID DivisionNm StateAb CandidateID GivenNm  Surname\n       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  \n1        179 Adelaide   SA            36973 Steve    GEORGA…\n2        197 Aston      VIC           36704 Alan     TUDGE  \n3        198 Ballarat   VIC           36409 Catheri… KING   \n4        103 Banks      NSW           37018 David    COLEMAN\n5        180 Barker     SA            37083 Tony     PASIN  \n6        104 Barton     NSW           36820 Linda    BURNEY \n# ℹ 2 more variables: PartyNm &lt;chr&gt;, PartyAb &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-5",
    "href": "lectures/lecture-03-notes.html#acquire-5",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.5 acquire",
    "text": "4.5 acquire\ntail() shows the last six rows.\n\n\ntail(raw_elections_data)\n\n# A tibble: 6 × 8\n  DivisionID DivisionNm StateAb CandidateID GivenNm  Surname\n       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  \n1        152 Wentworth  NSW           37451 Allegra  SPENDER\n2        153 Werriwa    NSW           36810 Anne Ma… STANLEY\n3        150 Whitlam    NSW           36811 Stephen  JONES  \n4        178 Wide Bay   QLD           37506 Llew     O'BRIEN\n5        234 Wills      VIC           36452 Peter    KHALIL \n6        316 Wright     QLD           37500 Scott    BUCHHO…\n# ℹ 2 more variables: PartyNm &lt;chr&gt;, PartyAb &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-6",
    "href": "lectures/lecture-03-notes.html#acquire-6",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.6 acquire",
    "text": "4.6 acquire\n\n“We are trying to make it similar to the dataset that we thought we wanted in the planning stage. While it is fine to move away from the plan, this needs to be a deliberate, reasoned decision.” (Alexander 2023)\n\n\nLet’s clean.\n\naus_voting_data &lt;- here(\"data\", \"australian_voting.csv\")\n\nraw_elections_data &lt;-\n    read_csv(\n        file = aus_voting_data,\n        show_col_types = FALSE\n    )"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-7",
    "href": "lectures/lecture-03-notes.html#acquire-7",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.7 acquire",
    "text": "4.7 acquire\n\nclean_names() makes variables easier to type.\n\ncleaned_elections_data &lt;- clean_names(raw_elections_data)\n\n Let’s look at the first 6 rows.\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 8\n  division_id division_nm state_ab candidate_id given_nm \n        &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;    \n1         179 Adelaide    SA              36973 Steve    \n2         197 Aston       VIC             36704 Alan     \n3         198 Ballarat    VIC             36409 Catherine\n4         103 Banks       NSW             37018 David    \n5         180 Barker      SA              37083 Tony     \n6         104 Barton      NSW             36820 Linda    \n# ℹ 3 more variables: surname &lt;chr&gt;, party_nm &lt;chr&gt;,\n#   party_ab &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-8",
    "href": "lectures/lecture-03-notes.html#acquire-8",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.8 acquire",
    "text": "4.8 acquire\n\n\n\n\n\n\n✌️ R Tip\nWe can choose certain variables of interest with select() from dplyr, which we loaded as part of the tidyverse. The pipe operator |&gt; pushes the output of one line to be the first input of the function on the next line.\n\n\n\n\nWe are primarily interested in two variables:\ndivision_nm (division name)party_nm (party name)\n\n\ncleaned_elections_data &lt;-\n    cleaned_elections_data |&gt;\n    select(\n        division_nm,\n        party_nm\n    )"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-9",
    "href": "lectures/lecture-03-notes.html#acquire-9",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.9 acquire",
    "text": "4.9 acquire\n\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division_nm party_nm              \n  &lt;chr&gt;       &lt;chr&gt;                 \n1 Adelaide    Australian Labor Party\n2 Aston       Liberal               \n3 Ballarat    Australian Labor Party\n4 Banks       Liberal               \n5 Barker      Liberal               \n6 Barton      Australian Labor Party\n\n\n\nThis looks good, but some of the variable names are still not obvious because they are abbreviated."
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-10",
    "href": "lectures/lecture-03-notes.html#acquire-10",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.10 acquire",
    "text": "4.10 acquire\n\n\n\n\n\n\n\n✌️ R Tip\nWe can look at the names of the columns (i.e., variables) in a dataset using names(). We can change them using rename() from dplyr.\n\n\n\n\nnames(cleaned_elections_data)\n\n[1] \"division_nm\" \"party_nm\"   \n\n\n\nLet’s rename."
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-11",
    "href": "lectures/lecture-03-notes.html#acquire-11",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.11 acquire",
    "text": "4.11 acquire\n\n\ncleaned_elections_data &lt;-\n    cleaned_elections_data |&gt;\n    rename(\n        division = division_nm,\n        elected_party = party_nm\n    )\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division elected_party         \n  &lt;chr&gt;    &lt;chr&gt;                 \n1 Adelaide Australian Labor Party\n2 Aston    Liberal               \n3 Ballarat Australian Labor Party\n4 Banks    Liberal               \n5 Barker   Liberal               \n6 Barton   Australian Labor Party"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-12",
    "href": "lectures/lecture-03-notes.html#acquire-12",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.12 acquire",
    "text": "4.12 acquire\n\nWhat are the unique values in elected_party?\n\ncleaned_elections_data$elected_party |&gt;\n    unique()\n\n[1] \"Australian Labor Party\"              \n[2] \"Liberal\"                             \n[3] \"Liberal National Party of Queensland\"\n[4] \"The Greens\"                          \n[5] \"The Nationals\"                       \n[6] \"Independent\"                         \n[7] \"Katter's Australian Party (KAP)\"     \n[8] \"Centre Alliance\"                     \n\n\n\nCool, but let’s simplify the party names in elected_party to match what we simulated. We can do this with case_match() from dplyr."
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-13",
    "href": "lectures/lecture-03-notes.html#acquire-13",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.13 acquire",
    "text": "4.13 acquire\n\n\ncleaned_elections_data &lt;-\n    cleaned_elections_data |&gt;\n    mutate(\n        elected_party =\n            case_match(\n                elected_party,\n                \"Australian Labor Party\" ~ \"Labor\",\n                \"Liberal National Party of Queensland\" ~ \"Liberal\",\n                \"Liberal\" ~ \"Liberal\",\n                \"The Nationals\" ~ \"Nationals\",\n                \"The Greens\" ~ \"Greens\",\n                \"Independent\" ~ \"Other\",\n                \"Katter's Australian Party (KAP)\" ~ \"Other\",\n                \"Centre Alliance\" ~ \"Other\"\n            )\n    )"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#acquire-14",
    "href": "lectures/lecture-03-notes.html#acquire-14",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.14 acquire",
    "text": "4.14 acquire\n\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division elected_party\n  &lt;chr&gt;    &lt;chr&gt;        \n1 Adelaide Labor        \n2 Aston    Liberal      \n3 Ballarat Labor        \n4 Banks    Liberal      \n5 Barker   Liberal      \n6 Barton   Labor        \n\n\n\nOur data now matches our plan! 😎"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#aus_elections_clean_path",
    "href": "lectures/lecture-03-notes.html#aus_elections_clean_path",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.15 acquire",
    "text": "4.15 acquire\n\nLet’s save the cleaned data so that we can start with it data in the next stage. We’ll use a new filename to preserve the original and make it easy to identify the clean version.\n\naus_elections_clean_path &lt;- here(\"data\", \"cleaned_elections_data.csv\")\n\nwrite_csv(\n    x = cleaned_elections_data,\n    file = aus_elections_clean_path\n)"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#explore-understand-1",
    "href": "lectures/lecture-03-notes.html#explore-understand-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.1 explore / understand",
    "text": "5.1 explore / understand\n\n\n\n How do we build the graph that we planned?"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#explore-understand-2",
    "href": "lectures/lecture-03-notes.html#explore-understand-2",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.2 explore / understand",
    "text": "5.2 explore / understand\n\nFirst, we read in the cleaned dataset that we just created.\n\ncleaned_elections_data &lt;-\n    read_csv(\n        file = aus_elections_clean_path,\n        show_col_types = FALSE\n    )\n\n\n\n\n\n\n\n\n✌️ R Tip\n\n\n\nI’m using the filepath object I previously created: aus_elections_clean_path.\n\naus_elections_clean_path\n\n[1] \"/Users/johnmclevey/SOCI3040/data/cleaned_elections_data.csv\"\n\n\n This won’t work in a new script unless we re-create the object. Can you explain why?"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#explore-understand-3",
    "href": "lectures/lecture-03-notes.html#explore-understand-3",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.3 explore / understand",
    "text": "5.3 explore / understand\n\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division elected_party\n  &lt;chr&gt;    &lt;chr&gt;        \n1 Adelaide Labor        \n2 Aston    Liberal      \n3 Ballarat Labor        \n4 Banks    Liberal      \n5 Barker   Liberal      \n6 Barton   Labor        \n\n\n😎"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#explore-understand-4",
    "href": "lectures/lecture-03-notes.html#explore-understand-4",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.4 explore / understand",
    "text": "5.4 explore / understand\n\n\n\n\n\n\nHow many seats did each party win?\n\n\n\n\nWe can get a quick count with count() from dplyr.\n\ncleaned_elections_data |&gt;\n    count(elected_party)\n\n# A tibble: 5 × 2\n  elected_party     n\n  &lt;chr&gt;         &lt;int&gt;\n1 Greens            4\n2 Labor            77\n3 Liberal          48\n4 Nationals        10\n5 Other            12"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#explore-understand-5",
    "href": "lectures/lecture-03-notes.html#explore-understand-5",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.5 explore / understand",
    "text": "5.5 explore / understand\n\n\n\n\n\n\nRemember, we’re trying to make something like this.\n\n\n\n\n\n\n\n\n\n✌️ R Tip\n\n\n\nThe grammar of graphics is a conceptual framework for constructing data visualizations. It breaks down plots to their most basic elements, like data, scales, geoms (geometric objects), coordinates, and statistical transformations. The idea is to plan and build our vizualizations by layering these basic elements together rather than mindlessly relying on generic chart types.\nggplot2, a data visualization library from the tidyverse, is designed around the grammar of graphics idea. We build data visualizations by layering the desired elements of our plots. For example, we use aes() to specify aesthetic mappings that link our data to visual elements like position, color, size, shape, and transparency. We can create and tweak just about any visualization we want by layering data, aesthetics, and geoms using the add operator, +.\n\n\n\n\n\n, allowing the viewer to interpret the values and relationships in the dataset visually. By mapping data to these properties, we can layer information on the same plot and enhance the viewer’s understanding of patterns, trends, and differences.\nIn ggplot2, aesthetics are specified within the aes() function, where each aesthetic is mapped to a data variable. For instance, x and y represent positions on the axes, while color, fill, size, and shape control other visual aspects. By carefully selecting aesthetics, we can add depth to the plot without clutter, guiding the viewer’s eye to the most important parts."
  },
  {
    "objectID": "lectures/lecture-03-notes.html#explore-understand-6",
    "href": "lectures/lecture-03-notes.html#explore-understand-6",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.6 explore / understand",
    "text": "5.6 explore / understand\n\nLet’s visualize the counts as vertical bars using geom_bar() from ggplot2.\n\nggplot(\n    cleaned_elections_data, # specify the data\n    aes(x = elected_party) # specify aesthetics\n) + # add a layer with the + operator\n    geom_bar() # specify a geometric shape (bar)\n\n\nBut it’s cleaner to use the pipe operator |&gt;.\n\ncleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar()\n\n\n\n\n\n\n\nFigure 2: Meh. We can do better."
  },
  {
    "objectID": "lectures/lecture-03-notes.html#explore-understand-7",
    "href": "lectures/lecture-03-notes.html#explore-understand-7",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.7 explore / understand",
    "text": "5.7 explore / understand\n\n\ncleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar() +\n    theme_minimal() + # Improve the theme\n    labs(x = \"Party\", y = \"Number of seats\") # Improve the labels\n\n\n\n\n\n\n\nFigure 3: Number of seats won, by political party, at the 2022 Australian Federal Election. 😎"
  },
  {
    "objectID": "lectures/lecture-03-notes.html#section",
    "href": "lectures/lecture-03-notes.html#section",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.8 ",
    "text": "5.8 \ncleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar()\n\ncleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar() +\n    theme_minimal() +\n    labs(x = \"Party\", y = \"Number of seats\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Default theme and labels\n\n\n\n\n\n\n\n\n\n\n\n(b) Improved theme and labels\n\n\n\n\n\n\n\nFigure 4: Both versions of the plot, and the code that produced them, side-by-side for comparison."
  },
  {
    "objectID": "lectures/lecture-03-notes.html#share-1",
    "href": "lectures/lecture-03-notes.html#share-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "6.1 share",
    "text": "6.1 share\nExample taken directly from Alexander (2023), here.\n\n\n\n\n\n\nAustralia is a parliamentary democracy with 151 seats in the House of Representatives, which is the house from which government is formed. There are two major parties—“Liberal” and “Labor”—two minor parties—“Nationals” and “Greens”—and many smaller parties. The 2022 Federal Election occurred on 21 May, and around 15 million votes were cast. We were interested in the number of seats that were won by each party.\nWe downloaded the results, on a seat-specific basis, from the Australian Electoral Commission website. We cleaned and tidied the dataset using the statistical programming language R (R Core Team 2023) including the tidyverse (Wickham et al. 2019) and janitor (Firke 2023). We then created a graph of the number of seats that each political party won (Figure 3).\nWe found that the Labor Party won 77 seats, followed by the Liberal Party with 48 seats. The minor parties won the following number of seats: the Nationals won 10 seats and the Greens won 4 seats. Finally, there were 10 Independents elected as well as candidates from smaller parties.\nThe distribution of seats is skewed toward the two major parties which could reflect relatively stable preferences on the part of Australian voters, or possibly inertia due to the benefits of already being a major party such a national network or funding. A better understanding of the reasons for this distribution are of interest in future work. While the dataset consists of everyone who voted, it worth noting that in Australia some are systematically excluded from voting, and it is much more difficult for some to vote than others.\n\n\n\n\nOne aspect to be especially concerned with is making sure that this communication is focused on the needs of the audience and telling a story. Data journalism provides some excellent examples of how analysis needs to be tailored to the audience, for instance, Cardoso (2020) and Bronner (2020)."
  },
  {
    "objectID": "lectures/lecture-25-notes.html",
    "href": "lectures/lecture-25-notes.html",
    "title": "Project Work",
    "section": "",
    "text": "Required: ?meta:assigned_reading\nRecommended: ?meta:recommended_reading\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-25-notes.html#reading-assignment",
    "href": "lectures/lecture-25-notes.html#reading-assignment",
    "title": "Project Work",
    "section": "",
    "text": "Required: ?meta:assigned_reading\nRecommended: ?meta:recommended_reading"
  },
  {
    "objectID": "lectures/lecture-25-notes.html#lecture-slides",
    "href": "lectures/lecture-25-notes.html#lecture-slides",
    "title": "Project Work",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-23-notes.html",
    "href": "lectures/lecture-23-notes.html",
    "title": "Generalized Linear Models (GLMs)",
    "section": "",
    "text": "Required:   Ch 13\nRecommended:   Ch 6\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-23-notes.html#reading-assignment",
    "href": "lectures/lecture-23-notes.html#reading-assignment",
    "title": "Generalized Linear Models (GLMs)",
    "section": "",
    "text": "Required:   Ch 13\nRecommended:   Ch 6"
  },
  {
    "objectID": "lectures/lecture-23-notes.html#lecture-slides",
    "href": "lectures/lecture-23-notes.html#lecture-slides",
    "title": "Generalized Linear Models (GLMs)",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-21-notes.html",
    "href": "lectures/lecture-21-notes.html",
    "title": "Linear Models",
    "section": "",
    "text": "Required:   Ch 12\nRecommended:   Geocentric Models\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-21-notes.html#reading-assignment",
    "href": "lectures/lecture-21-notes.html#reading-assignment",
    "title": "Linear Models",
    "section": "",
    "text": "Required:   Ch 12\nRecommended:   Geocentric Models"
  },
  {
    "objectID": "lectures/lecture-21-notes.html#lecture-slides",
    "href": "lectures/lecture-21-notes.html#lecture-slides",
    "title": "Linear Models",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-19-notes.html",
    "href": "lectures/lecture-19-notes.html",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Required:   Ch 11\nRecommended:   The Garden of Forking Data\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-19-notes.html#reading-assignment",
    "href": "lectures/lecture-19-notes.html#reading-assignment",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Required:   Ch 11\nRecommended:   The Garden of Forking Data"
  },
  {
    "objectID": "lectures/lecture-19-notes.html#lecture-slides",
    "href": "lectures/lecture-19-notes.html#lecture-slides",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-17-notes.html",
    "href": "lectures/lecture-17-notes.html",
    "title": "Cleaning, Preparing, and Testing",
    "section": "",
    "text": "Required:   Ch 9\nRecommended:   Statistical Golems\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-17-notes.html#reading-assignment",
    "href": "lectures/lecture-17-notes.html#reading-assignment",
    "title": "Cleaning, Preparing, and Testing",
    "section": "",
    "text": "Required:   Ch 9\nRecommended:   Statistical Golems"
  },
  {
    "objectID": "lectures/lecture-17-notes.html#lecture-slides",
    "href": "lectures/lecture-17-notes.html#lecture-slides",
    "title": "Cleaning, Preparing, and Testing",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-09-notes.html",
    "href": "lectures/lecture-09-notes.html",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "",
    "text": "Required:   Ch 5\nRecommended:   Ch 4\nGraphs are an essential component of data storytelling. They help us recognize patterns, understand distributions, and communicate findings effectively. This notebook introduces best practices for graphing in R using ggplot2 and demonstrates how summary statistics can sometimes be misleading if we do not visualize our data."
  },
  {
    "objectID": "lectures/lecture-09-notes.html#reading-assignment",
    "href": "lectures/lecture-09-notes.html#reading-assignment",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "",
    "text": "Required:   Ch 5\nRecommended:   Ch 4"
  },
  {
    "objectID": "lectures/lecture-09-notes.html#learning-objectives",
    "href": "lectures/lecture-09-notes.html#learning-objectives",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "0.1 Learning Objectives",
    "text": "0.1 Learning Objectives\nBy the end of this session, students will: - Understand the importance of graphing raw data before relying on summary statistics. - Learn to use ggplot2 for scatterplots, bar charts, line plots, and faceted plots. - Explore different themes, color palettes, and aesthetic modifications. - Apply these techniques to real-world datasets."
  },
  {
    "objectID": "lectures/lecture-09-notes.html#setup-loading-required-packages",
    "href": "lectures/lecture-09-notes.html#setup-loading-required-packages",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "0.2 Setup: Loading Required Packages",
    "text": "0.2 Setup: Loading Required Packages\n\n# Load necessary libraries\nlibrary(tidyverse) # Core tidyverse package for data wrangling & visualization\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(datasauRus) # Fun dataset illustrating the importance of visualization\nlibrary(ggplot2) # Graphing package\nlibrary(janitor) # Cleaning column names\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(WDI) # Accessing World Bank economic indicators\nlibrary(carData) # British Election Panel Study dataset\nlibrary(patchwork) # Combining multiple plots\nlibrary(tidygeocoder) # Geocoding support\nlibrary(tinytable) # Nice formatted tables\n\n# Set theme for all plots\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "lectures/lecture-09-notes.html#why-graphing-your-data-is-important",
    "href": "lectures/lecture-09-notes.html#why-graphing-your-data-is-important",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "0.3 Why Graphing Your Data is Important",
    "text": "0.3 Why Graphing Your Data is Important\n\n0.3.1 Example 1: The Datasaurus Dozen\nThe datasaurus_dozen dataset illustrates why we should always plot our data instead of relying solely on summary statistics.\n\n# Display the dataset\ndatasaurus_dozen\n\n# A tibble: 1,846 × 3\n   dataset     x     y\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 dino     55.4  97.2\n 2 dino     51.5  96.0\n 3 dino     46.2  94.5\n 4 dino     42.8  91.4\n 5 dino     40.8  88.3\n 6 dino     38.7  84.9\n 7 dino     35.6  79.9\n 8 dino     33.1  77.6\n 9 dino     29.0  74.5\n10 dino     26.2  71.4\n# ℹ 1,836 more rows\n\n\nEach subset of this dataset has the same mean and standard deviation for x and y, yet their visual patterns are completely different.\n\n0.3.1.1 Computing Summary Statistics\nThis code below is a pipeline that processes the datasaurus_dozen dataset to compute and display summary statistics (mean and standard deviation) for four selected datasets: “dino”, “star”, “away”, and “bullseye”. The pipeline begins by using filter(dataset %in% c(“dino”, “star”, “away”, “bullseye”)), which subsets the data to only include these four specific datasets. The summarise() function then calculates the mean and standard deviation for both the x and y variables, applying the across() function to compute these statistics for each dataset separately. The .by = dataset argument ensures that the summary statistics are grouped by dataset, so each subset receives its own computed values.\nAfter computing the summary statistics, the code formats the output into a visually appealing table. The tt() function (from the tinytable package) is used to create a neatly formatted table, and style_tt(j = 2:5, align = “r”) aligns the numeric columns (x mean, x sd, y mean, y sd) to the right for better readability. The format_tt(digits = 1, num_fmt = “decimal”) function ensures that numerical values are displayed with one decimal place. Finally, setNames(c(“Dataset”, “x mean”, “x sd”, “y mean”, “y sd”)) renames the columns to more descriptive labels for clarity. This pipeline efficiently extracts, summarizes, and presents key statistical insights from the datasaurus_dozen dataset while emphasizing the importance of looking beyond summary statistics to understand data distributions visually.\n\ndatasaurus_dozen |&gt;\n    filter(dataset %in% c(\"dino\", \"star\", \"away\", \"bullseye\")) |&gt;\n    summarise(\n        across(c(x, y), list(mean = mean, sd = sd)),\n        .by = dataset\n    ) |&gt;\n    tt() |&gt;\n    style_tt(j = 2:5, align = \"r\") |&gt;\n    format_tt(digits = 1, num_fmt = \"decimal\") |&gt;\n    setNames(c(\"Dataset\", \"x mean\", \"x sd\", \"y mean\", \"y sd\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Dataset\n                x mean\n                x sd\n                y mean\n                y sd\n              \n        \n        \n        \n                \n                  dino\n                  54.3\n                  16.8\n                  47.8\n                  26.9\n                \n                \n                  away\n                  54.3\n                  16.8\n                  47.8\n                  26.9\n                \n                \n                  star\n                  54.3\n                  16.8\n                  47.8\n                  26.9\n                \n                \n                  bullseye\n                  54.3\n                  16.8\n                  47.8\n                  26.9\n                \n        \n      \n    \n\n\n\n👉 Key Takeaway: These datasets appear identical in summary statistics, but let’s plot them.\nRecall that the mean, or average, is a measure of central tendency that represents the typical value in a dataset. It is calculated by adding up all the values and dividing by the total number of values. The mean gives us a sense of where most of the data points are centered. The standard deviation measures how spread out the values are from the mean. If the standard deviation is small, most values are close to the mean; if it’s large, the values are more spread out.\nIn short:\n\nlow standard deviation = data points are close together\nhigh standard deviation = data points are more spread out\n\nThese concepts help us understand how typical or how varied our data is.\n\n\n0.3.1.2 Visualizing the Datasaurus Dozen\n\n# Plot the datasets\ndatasaurus_dozen |&gt;\n    filter(dataset %in% c(\"dino\", \"star\", \"away\", \"bullseye\")) |&gt;\n    ggplot(aes(x = x, y = y, colour = dataset)) +\n    geom_point() +\n    facet_wrap(vars(dataset), nrow = 2, ncol = 2) +\n    labs(color = \"Dataset\")\n\n\n\n\n\n\n\n\n👉 Observation: Despite having identical summary statistics, each dataset has a distinct shape!\n\n\n\n0.3.2 Example 2: Anscombe’s Quartet\nFrank Anscombe developed Anscombe’s Quartet to highlight the same issue.\n\nhead(anscombe)\n\n  x1 x2 x3 x4   y1   y2    y3   y4\n1 10 10 10  8 8.04 9.14  7.46 6.58\n2  8  8  8  8 6.95 8.14  6.77 5.76\n3 13 13 13  8 7.58 8.74 12.74 7.71\n4  9  9  9  8 8.81 8.77  7.11 8.84\n5 11 11 11  8 8.33 9.26  7.81 8.47\n6 14 14 14  8 9.96 8.10  8.84 7.04\n\n\nThis dataset contains four sets of (x, y) values that share identical means, variances, and regression lines.\n\n0.3.2.1 Tidying the Data\nWe use pivot_longer() to convert it into tidy format.\n\ntidy_anscombe &lt;- anscombe |&gt; pivot_longer(\n    everything(),\n    names_to = c(\".value\", \"set\"),\n    names_pattern = \"(.)(.)\"\n)\ntidy_anscombe\n\n# A tibble: 44 × 3\n   set       x     y\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 1        10  8.04\n 2 2        10  9.14\n 3 3        10  7.46\n 4 4         8  6.58\n 5 1         8  6.95\n 6 2         8  8.14\n 7 3         8  6.77\n 8 4         8  5.76\n 9 1        13  7.58\n10 2        13  8.74\n# ℹ 34 more rows\n\n\nThis code reshapes the anscombe dataset into a tidy format using the pivot_longer() function. The tidy format (or tidy data) is a structured way of organizing data where each row represents an observation, each column represents a variable, and each cell contains a single value. This format, introduced by Hadley Wickham, makes data easier to manipulate, visualize, and analyze using tools like ggplot2 and dplyr. For example, in a non-tidy format, you might have separate columns for x1, y1, x2, y2, etc. (like in Anscombe’s Quartet). In a tidy format, you would restructure the data so that there are only three columns: set (indicating the dataset), x, and y, with each row representing one observation. Tidy data is particularly useful because it works seamlessly with the tidyverse, allowing for easier grouping, filtering, summarizing, and plotting.\nThe everything() argument ensures that all columns in the dataset are transformed. The names_to = c(“.value”, “set”) argument tells pivot_longer() to split the original column names into two parts: one representing the variable (x or y) and the other representing the dataset number (1, 2, 3, or 4). The names_pattern = “(.)(.)” uses regular expressions to separate column names based on their structure (e.g., x1, y1 → x, y for dataset 1). As a result, the tidy_anscombe dataset now has three columns: set (identifying the dataset number), x (the independent variable), and y (the dependent variable). This transformation makes the data more structured and easier to work with, particularly for grouped analysis and visualization in ggplot2.\n\n\n0.3.2.2 Computing Summary Statistics\n\ntidy_anscombe |&gt;\n    summarise(\n        across(c(x, y), list(mean = mean, sd = sd)),\n        .by = set\n    ) |&gt;\n    tt() |&gt;\n    style_tt(j = 2:5, align = \"r\") |&gt;\n    format_tt(digits = 1, num_fmt = \"decimal\") |&gt;\n    setNames(c(\"Dataset\", \"x mean\", \"x sd\", \"y mean\", \"y sd\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Dataset\n                x mean\n                x sd\n                y mean\n                y sd\n              \n        \n        \n        \n                \n                  1\n                  9\n                  3.3\n                  7.5\n                  2\n                \n                \n                  2\n                  9\n                  3.3\n                  7.5\n                  2\n                \n                \n                  3\n                  9\n                  3.3\n                  7.5\n                  2\n                \n                \n                  4\n                  9\n                  3.3\n                  7.5\n                  2\n                \n        \n      \n    \n\n\n\n\n\n0.3.2.3 Visualizing Anscombe’s Quartet\n\ntidy_anscombe |&gt;\n    ggplot(aes(x = x, y = y, colour = set)) +\n    geom_point() +\n    geom_smooth(method = lm, se = FALSE) +\n    facet_wrap(vars(set), nrow = 2, ncol = 2) +\n    labs(colour = \"Dataset\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n👉 Insight: Again, summary statistics don’t tell the full story!"
  },
  {
    "objectID": "lectures/lecture-09-notes.html#bar-charts-comparing-categorical-variables",
    "href": "lectures/lecture-09-notes.html#bar-charts-comparing-categorical-variables",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "0.4 Bar Charts: Comparing Categorical Variables",
    "text": "0.4 Bar Charts: Comparing Categorical Variables\nWe now explore bar charts using the British Election Panel Study.\n\n0.4.1 Loading and Cleaning the Data\n\nbeps &lt;-\n    BEPS |&gt;\n    as_tibble() |&gt;\n    clean_names() |&gt;\n    select(age, vote, gender, political_knowledge)\n\n\n\n0.4.2 Creating Age Groups\n\nbeps &lt;- beps |&gt;\n    mutate(\n        age_group = case_when(\n            age &lt; 35 ~ \"&lt;35\",\n            age &lt; 50 ~ \"35-49\",\n            age &lt; 65 ~ \"50-64\",\n            age &lt; 80 ~ \"65-79\",\n            age &lt; 100 ~ \"80-99\"\n        ),\n        age_group = factor(age_group, levels = c(\"&lt;35\", \"35-49\", \"50-64\", \"65-79\", \"80-99\"))\n    )\n\n\n\n0.4.3 Plotting the Distribution of Age Groups\n\nbeps |&gt; ggplot(aes(x = age_group)) +\n    geom_bar() +\n    labs(x = \"Age group\", y = \"Number of respondents\")"
  },
  {
    "objectID": "lectures/lecture-09-notes.html#scatterplots-exploring-relationships-between-variables",
    "href": "lectures/lecture-09-notes.html#scatterplots-exploring-relationships-between-variables",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "0.5 Scatterplots: Exploring Relationships Between Variables",
    "text": "0.5 Scatterplots: Exploring Relationships Between Variables\nUsing World Bank Data, we analyze GDP growth and inflation.\n\n0.5.1 Downloading the Data\n\nworld_bank_data &lt;- WDI(\n    indicator = c(\"FP.CPI.TOTL.ZG\", \"NY.GDP.MKTP.KD.ZG\"),\n    country = c(\"AU\", \"ET\", \"IN\", \"US\")\n) |&gt;\n    rename(inflation = FP.CPI.TOTL.ZG, gdp_growth = NY.GDP.MKTP.KD.ZG)\n\n\n\n0.5.2 Plotting GDP Growth vs. Inflation\n\nworld_bank_data |&gt;\n    ggplot(aes(x = gdp_growth, y = inflation, color = country)) +\n    geom_point() +\n    labs(x = \"GDP Growth\", y = \"Inflation\", color = \"Country\")\n\nWarning: Removed 9 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "lectures/lecture-09-notes.html#line-plots-time-series-data",
    "href": "lectures/lecture-09-notes.html#line-plots-time-series-data",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "0.6 Line Plots: Time-Series Data",
    "text": "0.6 Line Plots: Time-Series Data\nLet’s analyze US GDP growth over time.\n\nworld_bank_data |&gt;\n    filter(country == \"United States\") |&gt;\n    ggplot(aes(x = year, y = gdp_growth)) +\n    geom_line() +\n    labs(x = \"Year\", y = \"GDP Growth\")\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`)."
  },
  {
    "objectID": "lectures/lecture-02-notes.html",
    "href": "lectures/lecture-02-notes.html",
    "title": "Telling Stories with Data + R & the Tidyverse",
    "section": "",
    "text": "Required:   Ch 1\nRecommended:   Appendix A\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-02-notes.html#reading-assignment",
    "href": "lectures/lecture-02-notes.html#reading-assignment",
    "title": "Telling Stories with Data + R & the Tidyverse",
    "section": "",
    "text": "Required:   Ch 1\nRecommended:   Appendix A"
  },
  {
    "objectID": "lectures/lecture-02-notes.html#lecture-slides",
    "href": "lectures/lecture-02-notes.html#lecture-slides",
    "title": "Telling Stories with Data + R & the Tidyverse",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-15-notes.html",
    "href": "lectures/lecture-15-notes.html",
    "title": "Experiments and Surveys",
    "section": "",
    "text": "Required:   Ch 8\nRecommended:   Ch 8"
  },
  {
    "objectID": "lectures/lecture-15-notes.html#reading-assignment",
    "href": "lectures/lecture-15-notes.html#reading-assignment",
    "title": "Experiments and Surveys",
    "section": "",
    "text": "Required:   Ch 8\nRecommended:   Ch 8"
  },
  {
    "objectID": "lectures/lecture-15-notes.html#finding-memorials-openalex-institutional-id",
    "href": "lectures/lecture-15-notes.html#finding-memorials-openalex-institutional-id",
    "title": "Experiments and Surveys",
    "section": "1.1 Finding Memorial’s OpenAlex Institutional ID",
    "text": "1.1 Finding Memorial’s OpenAlex Institutional ID\nTo start, we need to find Memorial’s “Institutional ID”. We can do this by using the OpenAlex website.\n\n\n\nOpenAlex search\n\n\nClick on the Institution button and start typing “Memorial University” into the OpenAlex search.\n\n\n\nSearch for Memorial University under “Institution”\n\n\nTake a moment to review the results page – it’s the same page we saw when searching authors and topics in previous classes, only this time it’s for all of Memorial University. As of March 2025, there are almost 50,000 indexed publications.\n\n\n\nThe results page\n\n\nClick on “Memorial University” in the search field.\n\n\n\nFinding an Institutional ID\n\n\nYou should see an Institution ID under “Memorial University of Newfoundland.” I’ve highlighted it below to make it easier to see. This is the number we want to use when we query the OpenAlexAPI!\n\n\n\nCopying the Institutional ID for an API query\n\n\nYou can click to view MUN’s “Institutional Profile” on Open Alex.\n\n\n\nAn OpenAlex institution profile page"
  },
  {
    "objectID": "lectures/lecture-15-notes.html#query-the-openalex-api",
    "href": "lectures/lecture-15-notes.html#query-the-openalex-api",
    "title": "Experiments and Surveys",
    "section": "1.2 Query the OpenAlex API",
    "text": "1.2 Query the OpenAlex API\nNow we know that Memorial’s Institutional ID is i130438778. We can use this to setup an API query. Let’s start by creating a list with our query parameters.\nRecall that a list in R is like a container that holds several pieces of information. In this case, our list will contain three key-value pairs:\n\nentity = \"authors\" tells the API that we are interested in data about authors.\nlast_known_institutions.id = \"i130438778\" specifies that we want authors who are or were affiliated with a particular institution (identified by “i130438778”).\nworks_count = \"&gt;10\" means we want authors who have more than 10 published works.\n\nLet’s set it up!\n\nmy_arguments &lt;- list(\n    entity = \"authors\",\n    last_known_institutions.id = \"i130438778\",\n    works_count = \"&gt;10\"\n)\n\nNow let’s we’ll make an API call!\n\ndo.call(oa_fetch, c(my_arguments, list(count_only = TRUE)))\n\n     count db_response_time_ms page per_page\n[1,]  2307                 169    1        1\n\n\ndo.call() is a function that calls another function – in this case oa_fetch – using a list of arguments.\nHere, we combine our my_arguments list with an extra argument list(count_only = TRUE). This tells the function oa_fetch to only return a count (the number of matching records) instead of all the detailed information OpenAlex has about our search results. Essentially, we’re asking the API: “How many authors match these criteria?”\nSo now we’ve defined the search criteria for authors in a list, and we’ve checked if there are any authors matching the criteria by asking for just a count. If there are results (i.e., there is 1 or more authors in the OpenAlex database), then we can make another request to collect detailed information for those authors.\nRun the code block below.\n\nif (do.call(oa_fetch, c(my_arguments, list(count_only = TRUE)))[1] &gt; 0) {\n    do.call(oa_fetch, my_arguments) |&gt;\n        show_authors() |&gt;\n        knitr::kable()\n}\n\nWarning: Unknown or uninitialised column: `name`.\n\n\nWarning: Unknown or uninitialised column: `display_name`.\n\n\nWarning: Unknown or uninitialised column: `name`.\n\n\nWarning: Unknown or uninitialised column: `display_name`.\n\n\nWarning: Unknown or uninitialised column: `name`.\n\n\nWarning: Unknown or uninitialised column: `display_name`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ndisplay_name\norcid\nworks_count\ncited_by_count\naffiliation_display_name\ntop_concepts\n\n\n\n\nA5026509039\nFereidoon Shahidi\n0000-0002-9912-0330\n1113\n79559\nMemorial University of Newfoundland\nBiochemistry, Animal Science and Zoology, Molecular Biology\n\n\nA5077149719\nOctavia A. Dobre\n0000-0001-8528-0512\n949\n20777\nMemorial University of Newfoundland\nElectrical and Electronic Engineering, Electrical and Electronic Engineering, Electrical and Electronic Engineering\n\n\nA5010428924\nDavid C. Schneider\n0000-0003-4771-2155\n798\n6532\nMemorial University of Newfoundland\nGlobal and Planetary Change, Insect Science, Ecology, Evolution, Behavior and Systematics\n\n\nA5049089848\nTrung Q. Duong\n0000-0002-4703-4836\n726\n18629\nMemorial University of Newfoundland\nElectrical and Electronic Engineering, Computer Networks and Communications, Electrical and Electronic Engineering\n\n\nA5032069177\nIan Fleming\n0000-0002-5541-824X\n701\n23299\nMemorial University of Newfoundland\nOrganic Chemistry, Organic Chemistry, Nature and Landscape Conservation\n\n\nA5102982237\nRobert A. Brown\n0000-0003-2350-110X\n528\n18534\nMemorial University of Newfoundland\nMaterials Chemistry, Astronomy and Astrophysics, Astronomy and Astrophysics\n\n\n\n\n\nIn the code above, we check if the count returned by the previous call is greater than zero by using an if statement. Then do.call(oa_fetch, c(my_arguments, list(count_only = TRUE)))[1] retrieves the first element of the result, which is the number of matching authors. If that number is greater than 0 (meaning there is at least one author that meets the criteria), then the code inside the if block ({ ... }) block will run.\nInside the if block, do.call(oa_fetch, my_arguments) calls the oa_fetch function again with our original arguments, only this time we don’t use count_only = TRUE. This tells to API to fetch all the details of the matching authors. We then use the pipe operator |&gt; to pass the results of that function on to the next function, show_authors(). The show_authors() function formats or selects relevant author information. Finally, we pass the formatted data to knitr::kable(), which converts it into a nicely formatted table."
  },
  {
    "objectID": "lectures/lecture-15-notes.html#store-the-data",
    "href": "lectures/lecture-15-notes.html#store-the-data",
    "title": "Experiments and Surveys",
    "section": "1.3 Store the Data!",
    "text": "1.3 Store the Data!\nSo far our code fetches data and processes it for display, but it doesn’t retain the data in memory or write it to disk. If we want to keep it in memory and analyze that data in some way, we need to assign the result to a variable. Recall from previous classes that we want to minimize our APIs calls to be considerate of the servers providing our data.\nLet’s do that now, making yet another API call.\n\nauthors_data &lt;- do.call(oa_fetch, my_arguments)\n\nNow our data in stored in authors_data. Let’s take a look at the column names.\n\nnames(authors_data)\n\n [1] \"id\"                        \"display_name\"             \n [3] \"display_name_alternatives\" \"ids\"                      \n [5] \"orcid\"                     \"works_count\"              \n [7] \"cited_by_count\"            \"counts_by_year\"           \n [9] \"affiliation_display_name\"  \"affiliation_id\"           \n[11] \"affiliation_ror\"           \"affiliation_country_code\" \n[13] \"affiliation_type\"          \"affiliation_lineage\"      \n[15] \"affiliations_other\"        \"topics\"                   \n[17] \"works_api_url\"            \n\n\nThere are 17 variables for us to work with here! We’ll focus on a few today, including display_name, cited_by_count, works_count, counts_by_year, and topics.\nWe can print a preview of the tibble like any other. Let’s print 30 rows:\n\nprint(authors_data, n = 30)\n\n# A tibble: 2,307 × 17\n   id                display_name display_name_alterna…¹ ids   orcid works_count\n   &lt;chr&gt;             &lt;chr&gt;        &lt;list&gt;                 &lt;lis&gt; &lt;chr&gt;       &lt;int&gt;\n 1 https://openalex… Fereidoon S… &lt;chr [3]&gt;              &lt;chr&gt; http…        1113\n 2 https://openalex… Octavia A. … &lt;chr [7]&gt;              &lt;chr&gt; http…         949\n 3 https://openalex… David C. Sc… &lt;chr [6]&gt;              &lt;chr&gt; http…         798\n 4 https://openalex… Trung Q. Du… &lt;chr [5]&gt;              &lt;chr&gt; http…         726\n 5 https://openalex… Ian Fleming  &lt;chr [8]&gt;              &lt;chr&gt; http…         701\n 6 https://openalex… Robert A. B… &lt;chr [6]&gt;              &lt;chr&gt; http…         528\n 7 https://openalex… Weimin Huang &lt;chr [10]&gt;             &lt;chr&gt; http…         525\n 8 https://openalex… Laurence K.… &lt;chr [6]&gt;              &lt;chr&gt; &lt;NA&gt;          523\n 9 https://openalex… G.F. Naterer &lt;chr [4]&gt;              &lt;chr&gt; http…         523\n10 https://openalex… Proton Rahm… &lt;chr [5]&gt;              &lt;chr&gt; http…         492\n11 https://openalex… David G. Be… &lt;chr [6]&gt;              &lt;chr&gt; http…         485\n12 https://openalex… David Molyn… &lt;chr [6]&gt;              &lt;chr&gt; http…         478\n13 https://openalex… Lynn H. Ger… &lt;chr [13]&gt;             &lt;chr&gt; http…         454\n14 https://openalex… M. P. Searle &lt;chr [9]&gt;              &lt;chr&gt; http…         434\n15 https://openalex… Baiyu Zhang  &lt;chr [9]&gt;              &lt;chr&gt; http…         430\n16 https://openalex… Steven M. R… &lt;chr [8]&gt;              &lt;chr&gt; http…         424\n17 https://openalex… Rosemary Ri… &lt;chr [5]&gt;              &lt;chr&gt; http…         412\n18 https://openalex… E. Jacobsen  &lt;chr [4]&gt;              &lt;chr&gt; &lt;NA&gt;          394\n19 https://openalex… Lev Tarasov  &lt;chr [4]&gt;              &lt;chr&gt; http…         390\n20 https://openalex… Sohrab Zend… &lt;chr [3]&gt;              &lt;chr&gt; http…         376\n21 https://openalex… Patrick S. … &lt;chr [5]&gt;              &lt;chr&gt; http…         348\n22 https://openalex… Neil Bose    &lt;chr [7]&gt;              &lt;chr&gt; http…         344\n23 https://openalex… Jian‐Bin Lin &lt;chr [4]&gt;              &lt;chr&gt; http…         336\n24 https://openalex… John T. Bro… &lt;chr [5]&gt;              &lt;chr&gt; http…         332\n25 https://openalex… Jie Xiao     &lt;chr [5]&gt;              &lt;chr&gt; http…         318\n26 https://openalex… Yuming Zhao  &lt;chr [4]&gt;              &lt;chr&gt; http…         317\n27 https://openalex… M. Tariq Iq… &lt;chr [15]&gt;             &lt;chr&gt; http…         315\n28 https://openalex… Michael Lei… &lt;chr [3]&gt;              &lt;chr&gt; http…         308\n29 https://openalex… Abir U. Iga… &lt;chr [6]&gt;              &lt;chr&gt; http…         300\n30 https://openalex… Rachel Berk… &lt;chr [5]&gt;              &lt;chr&gt; http…         299\n# ℹ 2,277 more rows\n# ℹ abbreviated name: ¹​display_name_alternatives\n# ℹ 11 more variables: cited_by_count &lt;int&gt;, counts_by_year &lt;list&gt;,\n#   affiliation_display_name &lt;chr&gt;, affiliation_id &lt;chr&gt;,\n#   affiliation_ror &lt;chr&gt;, affiliation_country_code &lt;chr&gt;,\n#   affiliation_type &lt;chr&gt;, affiliation_lineage &lt;chr&gt;,\n#   affiliations_other &lt;list&gt;, topics &lt;list&gt;, works_api_url &lt;chr&gt;\n\n\nLet’s take a look at the topics data first. We’ll get a sense of what is in here and think about how to filter it to a smaller set of results that interest us.\nOne way to proceed is to use the pull() function from the tidyverse. If you run the code below, you’ll see a LOT of text populate your screen – R is printing 2307 dataframes! I won’t print the results here, but you can!\nauthors_data %&gt;% pull(topics)\nWhen we we pipe authors_data into pull(topics), we get the contents of the topics column as a vector. Vectors are useful for lots of things, including quick computations, plotting, or applying vectorized functions. Since it’s a simple vector, there’s no extra metadata like column names or row indices.\nThat’s not always what we want. Instead, we could use the select() function from the tidyverse to get back a tibble containing the column we want. Because it’s a tibble, it preserves additional information such as column names, types, and row names (implicitly). The tibble still has the structure of a table, so we can see the column name and work with it in the context of other columns! And keeping our data in a tibble format makes it easier to perform further data manipulations, or join with other tibbles, since many tidyverse functions expect data to be in a tibble format.\nauthors_data %&gt;% select(topics)\nThis is a complex data structure! Each publication in our dataset has a tibble stored in the topics column! Nested dataframes! Oh my.\n\nauthors_data %&gt;%\n    select(topics) %&gt;%\n    .[[1]] %&gt;%\n    head(10) %&gt;%\n    print()\n\n[[1]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   312 topic    https://openalex.org/T10035         Phytochemicals and …\n 2     1   312 subfield https://openalex.org/subfields/2704 Biochemistry        \n 3     1   312 field    https://openalex.org/fields/27      Medicine            \n 4     1   312 domain   https://openalex.org/domains/4      Health Sciences     \n 5     2   228 topic    https://openalex.org/T10333         Meat and Animal Pro…\n 6     2   228 subfield https://openalex.org/subfields/1103 Animal Science and …\n 7     2   228 field    https://openalex.org/fields/11      Agricultural and Bi…\n 8     2   228 domain   https://openalex.org/domains/1      Life Sciences       \n 9     3   165 topic    https://openalex.org/T11561         Protein Hydrolysis …\n10     3   165 subfield https://openalex.org/subfields/1312 Molecular Biology   \n# ℹ 90 more rows\n\n[[2]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   303 topic    https://openalex.org/T11458         Advanced Wireless C…\n 2     1   303 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n 3     1   303 field    https://openalex.org/fields/22      Engineering         \n 4     1   303 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   186 topic    https://openalex.org/T10148         Advanced MIMO Syste…\n 6     2   186 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n 7     2   186 field    https://openalex.org/fields/22      Engineering         \n 8     2   186 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   116 topic    https://openalex.org/T10851         Optical Wireless Co…\n10     3   116 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n# ℹ 90 more rows\n\n[[3]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1    57 topic    https://openalex.org/T10230         Marine and fisherie…\n 2     1    57 subfield https://openalex.org/subfields/2306 Global and Planetar…\n 3     1    57 field    https://openalex.org/fields/23      Environmental Scien…\n 4     1    57 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2    53 topic    https://openalex.org/T10135         Insect-Plant Intera…\n 6     2    53 subfield https://openalex.org/subfields/1109 Insect Science      \n 7     2    53 field    https://openalex.org/fields/11      Agricultural and Bi…\n 8     2    53 domain   https://openalex.org/domains/1      Life Sciences       \n 9     3    35 topic    https://openalex.org/T12329         Hemiptera Insect St…\n10     3    35 subfield https://openalex.org/subfields/1105 Ecology, Evolution,…\n# ℹ 90 more rows\n\n[[4]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   265 topic    https://openalex.org/T10148         Advanced MIMO Syste…\n 2     1   265 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n 3     1   265 field    https://openalex.org/fields/22      Engineering         \n 4     1   265 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   261 topic    https://openalex.org/T10796         Cooperative Communi…\n 6     2   261 subfield https://openalex.org/subfields/1705 Computer Networks a…\n 7     2   261 field    https://openalex.org/fields/17      Computer Science    \n 8     2   261 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   161 topic    https://openalex.org/T11458         Advanced Wireless C…\n10     3   161 subfield https://openalex.org/subfields/2208 Electrical and Elec…\n# ℹ 90 more rows\n\n[[5]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   210 topic    https://openalex.org/T10013         Asymmetric Synthesi…\n 2     1   210 subfield https://openalex.org/subfields/1605 Organic Chemistry   \n 3     1   210 field    https://openalex.org/fields/16      Chemistry           \n 4     1   210 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   165 topic    https://openalex.org/T11549         Synthetic Organic C…\n 6     2   165 subfield https://openalex.org/subfields/1605 Organic Chemistry   \n 7     2   165 field    https://openalex.org/fields/16      Chemistry           \n 8     2   165 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   133 topic    https://openalex.org/T10302         Fish Ecology and Ma…\n10     3   133 subfield https://openalex.org/subfields/2309 Nature and Landscap…\n# ℹ 90 more rows\n\n[[6]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1    86 topic    https://openalex.org/T11087         Solidification and …\n 2     1    86 subfield https://openalex.org/subfields/2505 Materials Chemistry \n 3     1    86 field    https://openalex.org/fields/25      Materials Science   \n 4     1    86 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2    69 topic    https://openalex.org/T10039         Stellar, planetary,…\n 6     2    69 subfield https://openalex.org/subfields/3103 Astronomy and Astro…\n 7     2    69 field    https://openalex.org/fields/31      Physics and Astrono…\n 8     2    69 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3    68 topic    https://openalex.org/T10325         Astro and Planetary…\n10     3    68 subfield https://openalex.org/subfields/3103 Astronomy and Astro…\n# ℹ 90 more rows\n\n[[7]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   188 topic    https://openalex.org/T11061         Ocean Waves and Rem…\n 2     1   188 subfield https://openalex.org/subfields/1910 Oceanography        \n 3     1   188 field    https://openalex.org/fields/19      Earth and Planetary…\n 4     1   188 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   107 topic    https://openalex.org/T10891         Radar Systems and S…\n 6     2   107 subfield https://openalex.org/subfields/2202 Aerospace Engineeri…\n 7     2   107 field    https://openalex.org/fields/22      Engineering         \n 8     2   107 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3    93 topic    https://openalex.org/T10255         Oceanographic and A…\n10     3    93 subfield https://openalex.org/subfields/1910 Oceanography        \n# ℹ 90 more rows\n\n[[8]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   242 topic    https://openalex.org/T10612         Magnetism in coordi…\n 2     1   242 subfield https://openalex.org/subfields/2504 Electronic, Optical…\n 3     1   242 field    https://openalex.org/fields/25      Materials Science   \n 4     1   242 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2   216 topic    https://openalex.org/T11881         Crystallization and…\n 6     2   216 subfield https://openalex.org/subfields/2505 Materials Chemistry \n 7     2   216 field    https://openalex.org/fields/25      Materials Science   \n 8     2   216 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3   215 topic    https://openalex.org/T12613         X-ray Diffraction i…\n10     3   215 subfield https://openalex.org/subfields/2505 Materials Chemistry \n# ℹ 90 more rows\n\n[[9]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   120 topic    https://openalex.org/T11802         Chemical Looping an…\n 2     1   120 subfield https://openalex.org/subfields/2204 Biomedical Engineer…\n 3     1   120 field    https://openalex.org/fields/22      Engineering         \n 4     1   120 domain   https://openalex.org/domains/3      Physical Sciences   \n 5     2    78 topic    https://openalex.org/T10998         Heat Transfer and O…\n 6     2    78 subfield https://openalex.org/subfields/2210 Mechanical Engineer…\n 7     2    78 field    https://openalex.org/fields/22      Engineering         \n 8     2    78 domain   https://openalex.org/domains/3      Physical Sciences   \n 9     3    54 topic    https://openalex.org/T12696         Icing and De-icing …\n10     3    54 subfield https://openalex.org/subfields/2202 Aerospace Engineeri…\n# ℹ 90 more rows\n\n[[10]]\n# A tibble: 100 × 5\n       i count name     id                                  display_name        \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                               &lt;chr&gt;               \n 1     1   250 topic    https://openalex.org/T11092         Spondyloarthritis S…\n 2     1   250 subfield https://openalex.org/subfields/2745 Rheumatology        \n 3     1   250 field    https://openalex.org/fields/27      Medicine            \n 4     1   250 domain   https://openalex.org/domains/4      Health Sciences     \n 5     2   211 topic    https://openalex.org/T10469         Psoriasis: Treatmen…\n 6     2   211 subfield https://openalex.org/subfields/2403 Immunology          \n 7     2   211 field    https://openalex.org/fields/24      Immunology and Micr…\n 8     2   211 domain   https://openalex.org/domains/1      Life Sciences       \n 9     3   178 topic    https://openalex.org/T10200         Rheumatoid Arthriti…\n10     3   178 subfield https://openalex.org/subfields/2745 Rheumatology        \n# ℹ 90 more rows\n\n\nIf we print some rows from the topics tibble, we can see that it contains information on topic, subfield, field, and domain. We’ll focus on topics for now and will come back to fields later.\n\nauthors_data %&gt;%\n    select(topics) %&gt;%\n    unnest(topics) %&gt;%\n    distinct(display_name) %&gt;%\n    print(n = 30)\n\n# A tibble: 4,285 × 1\n   display_name                                \n   &lt;chr&gt;                                       \n 1 Phytochemicals and Antioxidant Activities   \n 2 Biochemistry                                \n 3 Medicine                                    \n 4 Health Sciences                             \n 5 Meat and Animal Product Quality             \n 6 Animal Science and Zoology                  \n 7 Agricultural and Biological Sciences        \n 8 Life Sciences                               \n 9 Protein Hydrolysis and Bioactive Peptides   \n10 Molecular Biology                           \n11 Biochemistry, Genetics and Molecular Biology\n12 Antioxidant Activity and Oxidative Stress   \n13 Fatty Acid Research and Health              \n14 Nutrition and Dietetics                     \n15 Nursing                                     \n16 Edible Oils Quality and Analysis            \n17 Organic Chemistry                           \n18 Chemistry                                   \n19 Physical Sciences                           \n20 Aquaculture Nutrition and Growth            \n21 Aquatic Science                             \n22 Free Radicals and Antioxidants              \n23 Advanced Chemical Sensor Technologies       \n24 Biomedical Engineering                      \n25 Engineering                                 \n26 Tea Polyphenols and Effects                 \n27 Pathology and Forensic Medicine             \n28 Nuts composition and effects                \n29 Phytoestrogen effects and research          \n30 Food Chemistry and Fat Analysis             \n# ℹ 4,255 more rows\n\n\nLet’s filter the tibble to find authors (rows in authors_data) who have worked on the topic of “migration.”\nLet’s unpack the code below.\nFirst, we create a variable called search_topic and assign it the string “migration”. We will use this value later to filter the data. Then we pipe the authors_data into the select() function, where we select the display_name column (containing author names) and the topics column, which contained nested tibbles with information about the topics on which a specific author has published.\nWe then pipe the author names and topics into the unnest() function, which unnests the topics column. In other words, we will pull the topics tibble out of the row from the dataframe and expand it so that it is it’s own tibble with separate rows. The names_sep = \"_\" parameter specifies that* when unnesting, any new column names coming from the nested structure should be concatenated with the original column name using an underscore.* For example, if the nested tibble has a column named display_name, it might become topics_display_name. Why does that matter? Because the nested tibble has columns with the same names as the tibble it’s embedded in, which can cause… chaos.\nNext, we pipe the unnested data into the filter() function. We use it to filter the rows in author_data based on whether the topics_display_name column contains the text stored in search_topic (which is “migration”). To make that happen, we use the str_detect() function to check if a string contains a specific pattern. We use a “regular expression” that ignores case differences by using the argument ignore_case = TRUE (so “Migration” or “migration” both match).\nNow we can display a list of unique authors who meet our search and filter criteria by piping the results into distinct() and then printing the first n results (in this case, 80).\n\nsearch_topic &lt;- \"migration\"\n\nauthors_data %&gt;%\n    select(display_name, topics) %&gt;%\n    unnest(topics, names_sep = \"_\") %&gt;%\n    filter(str_detect(topics_display_name, regex(search_topic, ignore_case = TRUE))) %&gt;%\n    distinct(display_name) %&gt;%\n    print(n = 80)\n\n# A tibble: 160 × 1\n   display_name             \n   &lt;chr&gt;                    \n 1 Sian Neilson             \n 2 Roger White              \n 3 Ratana Chuenpagdee       \n 4 Tony Fang                \n 5 Trevor Bell              \n 6 Lewis R. Fischer         \n 7 Eric Y. Tenkorang        \n 8 Barbara Neis             \n 9 R. J. Avery              \n10 Yang Zhen                \n11 Amin A. Muhammad Gadit   \n12 Ashlee Cunsolo           \n13 Derek Nurse              \n14 Mark C. J. Stoddart      \n15 Kelly Vodden             \n16 Stephen Bornstein        \n17 Lisa Philpott            \n18 Marilyn Porter           \n19 Shree Mulay              \n20 Tyler D. Eddy            \n21 Yanqing Yi               \n22 Diana L. Gustafson       \n23 Alex Stewart             \n24 Ben Burt                 \n25 A. Lukyn Williams        \n26 Sharon R. Roseman        \n27 Jennifer A. Selby        \n28 Gillian Kolla            \n29 Sulaimon Gıwa            \n30 Diane Tye                \n31 Victor Maddalena         \n32 Christopher P. Youé      \n33 Fern Brunger             \n34 KL MacPherson            \n35 David Close              \n36 Sonja Boon               \n37 T.E. Roche               \n38 Robert Ormsby            \n39 Benjamin Rich Zendel     \n40 Jane G. Zhu              \n41 Adrian Tanner            \n42 Lisa Rankin              \n43 Alexander Y. Shestopaloff\n44 Stephen Czarnuch         \n45 Dale Kirby               \n46 Martha Traverso-Yépez    \n47 María Andrée López Gómez \n48 Nancy Pedri              \n49 Rick Audas               \n50 Alan Hall                \n51 M. J. Anderson           \n52 Delores V. Mullings      \n53 Rochelle R. Côté         \n54 Gordon B. Cooke          \n55 Roselyne N. Okech        \n56 Bill Bigelow             \n57 Isabelle Côté            \n58 Gerald Mugford           \n59 Katherine Side           \n60 Nicholas Wells           \n61 Jaro Stacul              \n62 Maisam Najafizada        \n63 Susan Stuckless          \n64 Peter Narváez            \n65 Jean L. Briggs           \n66 Pauline Duke             \n67 Sarah Gander             \n68 Ahmed Afzal              \n69 Yorck Sommerhäuser       \n70 Natalie Beausoleil       \n71 Rainer Baehre            \n72 Valerie Burton           \n73 Frederick Johnstone      \n74 Yolande Pottie‐Sherman   \n75 Nathalie LaCoste         \n76 Hollý                    \n77 Hugh Whalen              \n78 Lisa‐Jo K. van den Scott \n79 Martin Lovelace          \n80 Jeanne Sinclair          \n# ℹ 80 more rows\n\n\nWhat are we looking at here? These are authors affiliated with Memorial University who have published at least one paper on the topic of “migration.” It also prints the author’s number of publications and citations (as indexed by OpenAlex). We got that data by developing a small pipeline that:\n\nStarts with our original dataset.\nFocuses on just the author names and their topics.\nExpands nested topic information into individual rows.\nFilters rows where the topic matches “migration”.\nRemoves duplicate author names.\nPrints the results, showing up to 80 rows.\n\nNow… change the search_topic above to search for other topics. Try “climate change” (or whatever)!"
  },
  {
    "objectID": "lectures/lecture-15-notes.html#more-than-names",
    "href": "lectures/lecture-15-notes.html#more-than-names",
    "title": "Experiments and Surveys",
    "section": "1.4 More than Names",
    "text": "1.4 More than Names\n\nOK, cool! But, once again, maybe we want to see some other information, like maybe the name of the author, the title of the publication, and the number of topics assigned to that publication. Let’s do that below and print the top 200 results.\n\nsearch_topic &lt;- \"migration\"\n\nauthors_data %&gt;%\n    select(display_name, topics, works_count, cited_by_count) %&gt;%\n    unnest(topics, names_sep = \"_\") %&gt;%\n    filter(str_detect(topics_display_name, regex(search_topic, ignore_case = TRUE))) %&gt;%\n    select(display_name, topics_display_name, topics_count, topics_display_name) %&gt;%\n    print(n = 200)\n\n# A tibble: 207 × 3\n    display_name                topics_display_name                 topics_count\n    &lt;chr&gt;                       &lt;chr&gt;                                      &lt;int&gt;\n  1 Sian Neilson                European Law and Migration                     4\n  2 Sian Neilson                Human Rights and Immigration                   3\n  3 Roger White                 Migration and Labor Dynamics                  31\n  4 Roger White                 Migration, Ethnicity, and Economy             25\n  5 Ratana Chuenpagdee          Climate Change, Adaptation, Migrat…            5\n  6 Tony Fang                   Migration and Labor Dynamics                  30\n  7 Tony Fang                   Migration, Ethnicity, and Economy             27\n  8 Tony Fang                   Diaspora, migration, transnational…            5\n  9 Trevor Bell                 Climate Change, Adaptation, Migrat…            4\n 10 Lewis R. Fischer            Migration, Policy, and Dickens Stu…            1\n 11 Eric Y. Tenkorang           Migration and Labor Dynamics                   3\n 12 Eric Y. Tenkorang           Migration, Health and Trauma                   2\n 13 Barbara Neis                Migration, Aging, and Tourism Stud…            9\n 14 Barbara Neis                Migration and Labor Dynamics                   4\n 15 R. J. Avery                 Migration, Aging, and Tourism Stud…            4\n 16 Yang Zhen                   China's Global Influence and Migra…            1\n 17 Amin A. Muhammad Gadit      Migration, Health and Trauma                   4\n 18 Ashlee Cunsolo              Climate Change, Adaptation, Migrat…            9\n 19 Derek Nurse                 Diaspora, migration, transnational…            1\n 20 Mark C. J. Stoddart         Climate Change, Adaptation, Migrat…            3\n 21 Kelly Vodden                Migration, Aging, and Tourism Stud…            5\n 22 Stephen Bornstein           Migration, Health and Trauma                   2\n 23 Lisa Philpott               Migration, Ethnicity, and Economy              2\n 24 Marilyn Porter              Migration, Ethnicity, and Economy              5\n 25 Marilyn Porter              Migration and Labor Dynamics                   3\n 26 Shree Mulay                 Migration, Health and Trauma                   3\n 27 Tyler D. Eddy               Climate Change, Adaptation, Migrat…            3\n 28 Yanqing Yi                  Migration, Health and Trauma                   7\n 29 Diana L. Gustafson          Migration, Health and Trauma                   9\n 30 Alex Stewart                Migration, Ethnicity, and Economy             14\n 31 Ben Burt                    Climate Change, Adaptation, Migrat…            6\n 32 Ben Burt                    Italian Social Issues and Migration            1\n 33 Ben Burt                    Diaspora, migration, transnational…            1\n 34 A. Lukyn Williams           European Law and Migration                     2\n 35 Sharon R. Roseman           Migration, Aging, and Tourism Stud…           12\n 36 Sharon R. Roseman           Migration and Labor Dynamics                   6\n 37 Sharon R. Roseman           Migration, Ethnicity, and Economy              5\n 38 Sharon R. Roseman           Diaspora, migration, transnational…            4\n 39 Sharon R. Roseman           Immigration and Intercultural Educ…            2\n 40 Sharon R. Roseman           Migration, Refugees, and Integrati…            2\n 41 Jennifer A. Selby           Multiculturalism, Politics, Migrat…           29\n 42 Jennifer A. Selby           Migration, Identity, and Health                3\n 43 Gillian Kolla               Migration, Health and Trauma                   2\n 44 Sulaimon Gıwa               Migration and Labor Dynamics                   5\n 45 Sulaimon Gıwa               Migration, Ethnicity, and Economy              4\n 46 Sulaimon Gıwa               Migration, Health and Trauma                   3\n 47 Sulaimon Gıwa               Migration, Refugees, and Integrati…            3\n 48 Sulaimon Gıwa               Migration, Identity, and Health                2\n 49 Diane Tye                   Migration, Ethnicity, and Economy              1\n 50 Victor Maddalena            Migration, Health and Trauma                   2\n 51 Christopher P. Youé         Migration, Ethnicity, and Economy              1\n 52 Fern Brunger                Migration, Health and Trauma                   3\n 53 KL MacPherson               China's Global Influence and Migra…            2\n 54 David Close                 Diaspora, migration, transnational…            2\n 55 Sonja Boon                  Migration, Ethnicity, and Economy              2\n 56 T.E. Roche                  Macrophage Migration Inhibitory Fa…            2\n 57 Robert Ormsby               Migration, Policy, and Dickens Stu…            1\n 58 Benjamin Rich Zendel        Migration, Aging, and Tourism Stud…            1\n 59 Jane G. Zhu                 Migration, Ethnicity, and Economy              2\n 60 Adrian Tanner               Multiculturalism, Politics, Migrat…            2\n 61 Adrian Tanner               Climate Change, Adaptation, Migrat…            1\n 62 Lisa Rankin                 Migration, Aging, and Tourism Stud…            1\n 63 Alexander Y. Shestopaloff   Migration, Health and Trauma                   2\n 64 Stephen Czarnuch            Migration, Health and Trauma                   2\n 65 Dale Kirby                  Migration, Ethnicity, and Economy              2\n 66 Dale Kirby                  Migration and Labor Dynamics                   2\n 67 Martha Traverso-Yépez       Migration, Racism, and Human Rights            2\n 68 María Andrée López Gómez    Migration, Aging, and Tourism Stud…            2\n 69 Nancy Pedri                 Diaspora, migration, transnational…            1\n 70 Rick Audas                  Migration and Labor Dynamics                   2\n 71 Alan Hall                   Migration, Identity, and Health                1\n 72 M. J. Anderson              Macrophage Migration Inhibitory Fa…            1\n 73 Delores V. Mullings         Migration and Labor Dynamics                   6\n 74 Delores V. Mullings         Migration, Health and Trauma                   4\n 75 Delores V. Mullings         Migration, Ethnicity, and Economy              3\n 76 Rochelle R. Côté            Migration, Ethnicity, and Economy              6\n 77 Rochelle R. Côté            Migration and Labor Dynamics                   3\n 78 Gordon B. Cooke             Migration, Aging, and Tourism Stud…            2\n 79 Roselyne N. Okech           Migration, Ethnicity, and Economy              2\n 80 Bill Bigelow                Migration, Ethnicity, and Economy              1\n 81 Isabelle Côté               Migration and Labor Dynamics                   4\n 82 Isabelle Côté               Migration, Refugees, and Integrati…            4\n 83 Isabelle Côté               Diaspora, migration, transnational…            2\n 84 Isabelle Côté               Migration, Identity, and Health                1\n 85 Gerald Mugford              Migration, Aging, and Tourism Stud…            2\n 86 Katherine Side              Migration, Refugees, and Integrati…            4\n 87 Nicholas Wells              Migration, Aging, and Tourism Stud…            2\n 88 Jaro Stacul                 Italian Social Issues and Migration            1\n 89 Maisam Najafizada           Migration, Health and Trauma                   2\n 90 Susan Stuckless             Migration, Aging, and Tourism Stud…            1\n 91 Peter Narváez               Migration, Ethnicity, and Economy              1\n 92 Jean L. Briggs              Migration, Education, Indigenous S…            2\n 93 Pauline Duke                Migration, Health and Trauma                   2\n 94 Sarah Gander                Migration, Health and Trauma                   4\n 95 Ahmed Afzal                 Diaspora, migration, transnational…            3\n 96 Ahmed Afzal                 Migration and Labor Dynamics                   2\n 97 Ahmed Afzal                 Migration, Ethnicity, and Economy              2\n 98 Yorck Sommerhäuser          Migration, Ethnicity, and Economy              1\n 99 Natalie Beausoleil          Multiculturalism, Politics, Migrat…            1\n100 Rainer Baehre               Migration, Ethnicity, and Economy              1\n101 Rainer Baehre               Migration and Labor Dynamics                   1\n102 Valerie Burton              Migration, Ethnicity, and Economy              3\n103 Frederick Johnstone         Migration, Ethnicity, and Economy              3\n104 Yolande Pottie‐Sherman      Migration and Labor Dynamics                   7\n105 Yolande Pottie‐Sherman      Migration, Ethnicity, and Economy              6\n106 Yolande Pottie‐Sherman      Migration, Refugees, and Integrati…            5\n107 Yolande Pottie‐Sherman      Diaspora, migration, transnational…            3\n108 Yolande Pottie‐Sherman      Migration, Aging, and Tourism Stud…            3\n109 Nathalie LaCoste            Multiculturalism, Politics, Migrat…            1\n110 Hollý                       Migration and Labor Dynamics                   1\n111 Hugh Whalen                 Multiculturalism, Politics, Migrat…            1\n112 Lisa‐Jo K. van den Scott    Diaspora, migration, transnational…            1\n113 Martin Lovelace             Migration, Ethnicity, and Economy              1\n114 Jeanne Sinclair             Migration, Aging, and Tourism Stud…            1\n115 Christopher Patey           Italian Social Issues and Migration            1\n116 Dominique Brégent‐Heald     Migration, Health, Geopolitics, Hi…            2\n117 Daze Jefferies              Migration, Ethnicity, and Economy              1\n118 David Peddle                Human Rights and Immigration                   1\n119 Stephen Harold Riggins      Diaspora, migration, transnational…            2\n120 Stephen Harold Riggins      Migration, Ethnicity, and Economy              1\n121 James Valcour               Climate Change, Adaptation, Migrat…            1\n122 Mercedes Steedman           Migration, Ethnicity, and Economy              2\n123 Ivan Emke                   European Law and Migration                     1\n124 Ivan Emke                   Migration, Health and Trauma                   1\n125 Robin Whitaker              Migration, Refugees, and Integrati…            4\n126 Robin Whitaker              Multiculturalism, Politics, Migrat…            1\n127 Lincoln Addison             Migration, Ethnicity, and Economy              3\n128 Lincoln Addison             Migration and Labor Dynamics                   1\n129 Elizabeth Yeoman            Migration, Refugees, and Integrati…            1\n130 Alessandro Giardino         Multiculturalism, Politics, Migrat…            1\n131 D. Codner                   Macrophage Migration Inhibitory Fa…            1\n132 Lesley Butler               Diaspora, migration, transnational…            1\n133 Lesley Butler               Migration, Ethnicity, and Economy              1\n134 Lesley Butler               Climate Change, Adaptation, Migrat…            1\n135 Julia Temple Newhook        Migration, Ethnicity, and Economy              1\n136 Julia Temple Newhook        Migration and Labor Dynamics                   1\n137 Donald W. Nichol            Migration, Policy, and Dickens Stu…            1\n138 John Mannion                Climate Change, Adaptation, Migrat…            1\n139 Santé A. Viselli            Multiculturalism, Politics, Migrat…            1\n140 Ronald Schwartz             Diaspora, migration, transnational…            1\n141 Brenda A. LeFrançois        Labour Market and Migration                    1\n142 Roza Tchoukaleyska          Migration, Identity, and Health                1\n143 Heidi Coombs-Thorne         Migration and Labor Dynamics                   1\n144 Robert Shea                 Migration, Refugees, and Integrati…            1\n145 Paul Alhassan Issahaku      Migration, Health and Trauma                   1\n146 Amy M. Warren               Migration, Aging, and Tourism Stud…            1\n147 Rowena Mercado              Migration, Health and Trauma                   1\n148 Kwamina Abekah‐Carter       Migration, Aging, and Tourism Stud…            2\n149 Angela J. Hyde              Macrophage Migration Inhibitory Fa…            1\n150 Sylvia Moore                Climate Change, Adaptation, Migrat…            1\n151 Christopher Curran          Migration and Labor Dynamics                   4\n152 Katie Gillespie             Migration, Health and Trauma                   4\n153 Catherine Losier            Migration, Identity, and Health                4\n154 Catherine Losier            Migration, Health, Geopolitics, Hi…            1\n155 Barry C. Gaulton            Migration, Health, Geopolitics, Hi…            1\n156 August Carbonella           Migration, Ethnicity, and Economy              4\n157 August Carbonella           Multiculturalism, Politics, Migrat…            1\n158 Nicholas Lynch              Migration, Aging, and Tourism Stud…            1\n159 Russell Dawe                Migration, Health and Trauma                   1\n160 Kodjo Attikpoé              Migration and Exile Studies                    1\n161 Lorna Bennett               Migration, Health and Trauma                   1\n162 Jennifer L. Buckle          Migration, Health and Trauma                   3\n163 Mariya Lesiv                Diaspora, migration, transnational…            2\n164 Mariya Lesiv                Migration, Ethnicity, and Economy              1\n165 John Bodner                 Multiculturalism, Politics, Migrat…            1\n166 Calvin Hollett              Migration, Aging, and Tourism Stud…            1\n167 A. K. M. Shahidullah        Climate Change, Adaptation, Migrat…            1\n168 Rebecca J. Franklin         Migration, Ethnicity, and Economy              2\n169 Beth Leavenworth DuFault    Migration, Ethnicity, and Economy              1\n170 Raquel Ruiz‐Díaz            Climate Change, Adaptation, Migrat…            3\n171 Leanna Butters              Migration, Aging, and Tourism Stud…            5\n172 Jacqueline Hesson           Migration, Health and Trauma                   1\n173 Jennifer Thorburn           Diaspora, migration, transnational…            7\n174 Jennifer Thorburn           Migration and Labor Dynamics                   7\n175 Madonna M. Murphy           Migration, Health and Trauma                   1\n176 Roberta Buchanan            Multiculturalism, Politics, Migrat…            1\n177 Sean W. D. Gray             Migration, Refugees, and Integrati…            3\n178 Cory W. Thorne              Diaspora, migration, transnational…            1\n179 Michael Skipton             Migration, Policy, and Dickens Stu…            2\n180 Neil J. Vincent             Migration, Health and Trauma                   1\n181 Devonne Ryan                Migration, Aging, and Tourism Stud…            1\n182 Margo Wilson                Migration, Health and Trauma                   1\n183 Michael D. Kirkpatrick      Migration, Ethnicity, and Economy              1\n184 Kate Lahey                  Climate Change, Adaptation, Migrat…            1\n185 Elias Bartellas             Migration, Health and Trauma                   1\n186 Mohamed Salah Eddine Madiou Climate Change, Adaptation, Migrat…            1\n187 Elise Thorburn              Migration, Aging, and Tourism Stud…            1\n188 Leslie J. Cake              Migration, Aging, and Tourism Stud…            1\n189 Hua Que                     Migration, Health and Trauma                   6\n190 Hua Que                     Migration and Labor Dynamics                   3\n191 Hua Que                     Migration, Refugees, and Integrati…            2\n192 Caroline Guinard            Migration, Identity, and Health                1\n193 Ban Younghusband            Macrophage Migration Inhibitory Fa…            1\n194 Jessica Squires             Macrophage Migration Inhibitory Fa…            1\n195 Tyler R. Pritchard          Migration, Health and Trauma                   2\n196 Raleen Murphy               Migration, Health and Trauma                   2\n197 Darren Hynes                Migration, Health, Geopolitics, Hi…            1\n198 Halia Koo                   Multiculturalism, Politics, Migrat…            1\n199 Alka Agarwal-Mawal          Macrophage Migration Inhibitory Fa…            1\n200 Jieying Xiong               Macrophage Migration Inhibitory Fa…            1\n# ℹ 7 more rows\n\n\nLet’s store this subset of data for later.\n\nmigration_authors &lt;- authors_data %&gt;%\n    select(display_name, topics, works_count, cited_by_count) %&gt;%\n    unnest(topics, names_sep = \"_\") %&gt;%\n    filter(str_detect(topics_display_name, regex(search_topic, ignore_case = TRUE))) %&gt;%\n    select(display_name, topics_display_name, topics_count, topics_display_name)"
  },
  {
    "objectID": "lectures/lecture-15-notes.html#key-concepts-and-common-words",
    "href": "lectures/lecture-15-notes.html#key-concepts-and-common-words",
    "title": "Experiments and Surveys",
    "section": "1.5 Key Concepts and Common Words",
    "text": "1.5 Key Concepts and Common Words\nWhat are some of the key concepts that show up in research on migration conducted by Memorial researchers? One simple way to get at this idea is to simply take every unique word that appears across titles and count the number of times it appears. It’s crude, but a useful first pass to get a sense of what we have.\nTo do this, we’ll use another package: tidytext for “natural language processing”. We’ll load the library and then start our pipeline by piping the migration_authors data into the tidytext’s unnest_tokens() function. unnest_tokens() splits the topics_display_name column into individual words (tokens). Each word becomes a separate row in the dataset, and the new column is named word. Then we pipe that output into count(word, sort = TRUE) to counts the occurrences of each unique word in the word column. The sort = TRUE argument sorts the results in descending order of frequency.\n\nlibrary(tidytext)\n\nword_counts &lt;- migration_authors %&gt;%\n    unnest_tokens(word, topics_display_name) %&gt;%\n    count(word, sort = TRUE)\n\nprint(word_counts, n = 50)\n\n# A tibble: 48 × 2\n   word                 n\n   &lt;chr&gt;            &lt;int&gt;\n 1 migration          204\n 2 and                149\n 3 health              44\n 4 economy             36\n 5 ethnicity           36\n 6 trauma              33\n 7 studies             26\n 8 dynamics            24\n 9 identity            23\n10 labor               23\n11 aging               21\n12 tourism             21\n13 adaptation          16\n14 change              16\n15 climate             16\n16 diaspora            16\n17 transnational       16\n18 gender              12\n19 multiculturalism    12\n20 politics            12\n21 integration         10\n22 refugees            10\n23 factor               9\n24 inhibitory           9\n25 macrophage           9\n26 dickens              4\n27 geography            4\n28 geopolitics          4\n29 historical           4\n30 human                4\n31 policy               4\n32 rights               4\n33 social               4\n34 european             3\n35 immigration          3\n36 issues               3\n37 italian              3\n38 law                  3\n39 china's              2\n40 education            2\n41 global               2\n42 influence            2\n43 racism               2\n44 exile                1\n45 indigenous           1\n46 intercultural        1\n47 labour               1\n48 market               1"
  },
  {
    "objectID": "lectures/lecture-15-notes.html#visualizing-word-frequencies",
    "href": "lectures/lecture-15-notes.html#visualizing-word-frequencies",
    "title": "Experiments and Surveys",
    "section": "1.6 Visualizing Word Frequencies",
    "text": "1.6 Visualizing Word Frequencies\nLet’s make a horizontal bar graph (where the words are on the y-axis and word frequency is on the x-axis) to visualize this distribution of words. We’ll also remove “stop words” like “and,” “of,” etc.\n\ndata(\"stop_words\")\nfiltered_word_counts &lt;- word_counts %&gt;%\n    anti_join(stop_words, by = \"word\")\n\nAnd now for the bar graph!\n\nggplot(filtered_word_counts, aes(x = reorder(word, n), y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    labs(\n        title = \"Word Frequency in Migration Research\",\n        x = \"Words\",\n        y = \"Frequency\"\n    ) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nRemember you can save your plot with the ggsave function!\nggsave(\"migration_word_frequency.png\", width = 10, height = 8)"
  },
  {
    "objectID": "lectures/lecture-15-notes.html#fields",
    "href": "lectures/lecture-15-notes.html#fields",
    "title": "Experiments and Surveys",
    "section": "1.7 Fields",
    "text": "1.7 Fields\nThe topics data also include “field” classifications. These are multi-level labels attached to publications. By multi-level I mean that some labels are very high-level (e.g., social sciences, sociology) while others are most focused (e.g., sociology of gender, racial inequality). Let’s make a table counting the number of fields in the Memorial Data.\n\nfield_counts &lt;- authors_data %&gt;%\n    select(topics) %&gt;%\n    unnest(topics) %&gt;%\n    count(display_name, sort = TRUE)\n\nprint(field_counts, n = 30)\n\n# A tibble: 4,285 × 2\n   display_name                                             n\n   &lt;chr&gt;                                                &lt;int&gt;\n 1 Physical Sciences                                    19166\n 2 Social Sciences                                      19144\n 3 Health Sciences                                      11962\n 4 Medicine                                              9367\n 5 Life Sciences                                         7845\n 6 Engineering                                           5632\n 7 Environmental Science                                 3947\n 8 Biochemistry, Genetics and Molecular Biology          3740\n 9 Arts and Humanities                                   2519\n10 Computer Science                                      2375\n11 Earth and Planetary Sciences                          2334\n12 Health Professions                                    2107\n13 Agricultural and Biological Sciences                  2075\n14 Molecular Biology                                     1995\n15 Sociology and Political Science                       1958\n16 Psychology                                            1934\n17 Chemistry                                             1408\n18 General Health Professions                            1395\n19 Materials Science                                     1199\n20 Education                                             1189\n21 Neuroscience                                          1164\n22 Ecology                                               1147\n23 Physics and Astronomy                                 1121\n24 Electrical and Electronic Engineering                  943\n25 Surgery                                                903\n26 Genetics                                               894\n27 Public Health, Environmental and Occupational Health   890\n28 Economics, Econometrics and Finance                    885\n29 Business, Management and Accounting                    830\n30 Global and Planetary Change                            776\n# ℹ 4,255 more rows\n\n\nA few things jump out at me from this list of the top 30 topics. First, publication output in the physical and social sciences at Memorial are neck and neck! If you were to combine Health, Medicine, and Life Sciences, they would top the list. Arts and Humanities is pretty high on this list to, claiming the number 9 rank. Sociology and Political Science are at rank 15.\nLet’s ggplot!\n\ntop_n_fields &lt;- field_counts %&gt;%\n    top_n(100, n)\n\nggplot(top_n_fields, aes(x = reorder(display_name, n), y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    labs(\n        title = \"Top 30 Fields in Memorial University Publications\",\n        x = \"Fields\",\n        y = \"Count\"\n    ) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nWe’ll stop there for today. Tomorrow we’ll work on the second Data Stories assignment in class. It’s due on Monday March 10th."
  },
  {
    "objectID": "lectures/lecture-13-notes.html",
    "href": "lectures/lecture-13-notes.html",
    "title": "APIs, Scraping, and Parsing",
    "section": "",
    "text": "Required:   Ch 7\nRecommended:   Ch 7\nIn class activities focused on understanding the theory behind, and practical realities of,"
  },
  {
    "objectID": "lectures/lecture-13-notes.html#reading-assignment",
    "href": "lectures/lecture-13-notes.html#reading-assignment",
    "title": "APIs, Scraping, and Parsing",
    "section": "",
    "text": "Required:   Ch 7\nRecommended:   Ch 7"
  },
  {
    "objectID": "lectures/lecture-11-notes.html",
    "href": "lectures/lecture-11-notes.html",
    "title": "Measurement, Censuses, and Sampling",
    "section": "",
    "text": "Required:   Ch 6\nRecommended:   Ch 5\nIn class activities focused on understanding the theory behind, and practical realities of,"
  },
  {
    "objectID": "lectures/lecture-11-notes.html#reading-assignment",
    "href": "lectures/lecture-11-notes.html#reading-assignment",
    "title": "Measurement, Censuses, and Sampling",
    "section": "",
    "text": "Required:   Ch 6\nRecommended:   Ch 5"
  },
  {
    "objectID": "lectures/lecture-08-notes.html",
    "href": "lectures/lecture-08-notes.html",
    "title": "Writing and Developing Research Questions",
    "section": "",
    "text": "Required:   Ch 4\nRecommended:   Ch 3"
  },
  {
    "objectID": "lectures/lecture-08-notes.html#reading-assignment",
    "href": "lectures/lecture-08-notes.html#reading-assignment",
    "title": "Writing and Developing Research Questions",
    "section": "",
    "text": "Required:   Ch 4\nRecommended:   Ch 3"
  },
  {
    "objectID": "lectures/lecture-02-slides.html#references",
    "href": "lectures/lecture-02-slides.html#references",
    "title": "Telling Stories with Data + R and the Tidyverse",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-01-content.html",
    "href": "lectures/lecture-01-content.html",
    "title": "Who are you?",
    "section": "",
    "text": "My name is [John, Professor McLevey, Dr. McLevey] (he/him).\nProfessor & Head of Sociology New to Memorial after 11 years at University of Waterloo"
  },
  {
    "objectID": "lectures/lecture-01-content.html#welcome-to-soci-3040",
    "href": "lectures/lecture-01-content.html#welcome-to-soci-3040",
    "title": "Who are you?",
    "section": "",
    "text": "My name is [John, Professor McLevey, Dr. McLevey] (he/him).\nProfessor & Head of Sociology New to Memorial after 11 years at University of Waterloo"
  },
  {
    "objectID": "lectures/lecture-01-content.html#agenda.",
    "href": "lectures/lecture-01-content.html#agenda.",
    "title": "Who are you?",
    "section": "agenda.",
    "text": "agenda.\n\nWho are you? Background? Expectations?\nWhat is this course about?\nWhat will we do? Where is everything?"
  },
  {
    "objectID": "lectures/lecture-01-content.html#section",
    "href": "lectures/lecture-01-content.html#section",
    "title": "Who are you?",
    "section": "",
    "text": "Who are you? Do you have any previous quant courses / experience? What are your expectations for this course?"
  },
  {
    "objectID": "lectures/lecture-01-content.html#calendar-description",
    "href": "lectures/lecture-01-content.html#calendar-description",
    "title": "Who are you?",
    "section": "3040 Calendar Description",
    "text": "3040 Calendar Description\n\n\nSOCI 3040, Quantitative Research Methods, will familiarize students with the procedures for understanding and conducting quantitative social science research. It will introduce students to the quantitative research process, hypothesis development and testing, and the application of appropriate tools for analyzing quantitative data. All sections of this course count towards the HSS Quantitative Reasoning Requirement (see mun.ca/hss/qr). (PR: SOCI 1000 or the former SOCI 2000)"
  },
  {
    "objectID": "lectures/lecture-01-content.html#this-section-001",
    "href": "lectures/lecture-01-content.html#this-section-001",
    "title": "Who are you?",
    "section": "This Section (001)",
    "text": "This Section (001)\n\nThis section of SOCI 3440 is an introduction to quantitative research methods, from planning an analysis to sharing the final results. Following the workflow from Rohan Alexander’s [-@alexander2023telling] Telling Stories with Data, you will learn how to:\n\nplan an analysis and sketch your data and endpoint simulate some data to “force you into the details” acquire, assess, and prepare empirical data for analysis explore and analyze data by creating visualizations and fitting models share the results of your work with the world!\n\n\n\n\n\nflowchart LR\n    p[[Plan]]\n    sim[[Simulate]]\n    a[[Acquire]]\n    e[[Explore / Analyze]]\n    s[[Share]]\n\n    p --&gt; sim --&gt; a --&gt; e --&gt; s"
  },
  {
    "objectID": "lectures/lecture-01-content.html#this-section-001-1",
    "href": "lectures/lecture-01-content.html#this-section-001-1",
    "title": "Who are you?",
    "section": "This Section (001)",
    "text": "This Section (001)\n\n“A lack of clear communication sometimes reflects a failure by the researcher to understand what is going on, or even what they are doing.” [@alexander2023telling]\n\n\nCore foundation of quantitative research methods Bridge between analysis and understanding Essential skill for modern researchers"
  },
  {
    "objectID": "lectures/lecture-01-content.html#this-section-001-2",
    "href": "lectures/lecture-01-content.html#this-section-001-2",
    "title": "Who are you?",
    "section": "This Section (001)",
    "text": "This Section (001)\n\n\n\n\n\n\n\n You will use this workflow in the context of learning foundational quantitative research skills, including conducting exploratory data analyses and fitting, assessing, and interpreting linear and generalized linear models. Reproducibility and research ethics are considered throughout the workflow, and the entire course."
  },
  {
    "objectID": "lectures/lecture-01-content.html#common-concerns-key-questions",
    "href": "lectures/lecture-01-content.html#common-concerns-key-questions",
    "title": "Who are you?",
    "section": "Common Concerns & Key Questions",
    "text": "Common Concerns & Key Questions\n\nWhat is the dataset? Who generated it and why?\nWhat is the underlying process? What’s missing or has been poorly measured? Could other datasets have been generated, and if so, how different could they have been to the one that we have?\nWhat is the dataset trying to say? What else could it say?\nWhat do we want others to see? How do we convince them?\nWho is affected? Are they represented in the data? Have they been involved in the analysis?"
  },
  {
    "objectID": "lectures/lecture-01-content.html#core-workflow-components",
    "href": "lectures/lecture-01-content.html#core-workflow-components",
    "title": "Who are you?",
    "section": "Core Workflow Components",
    "text": "Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\n\nPlan and Sketch\ndeliberate, reasoned decisions purposeful adjustments even 10 minutes of planning is valuable\n\nPlanning and sketching an endpoint is the first crucial step in the workflow because it ensures we have a clear objective and direction for our analysis. By thoughtfully considering where we want to go, we stay focused and efficient, preventing aimless wandering and scope creep. Without a defined goal, any path will suffice, but we typically cannot afford to wander aimlessly. While our endpoint may change, having an initial objective allows for deliberate and reasoned adjustments. This planning doesn’t require extensive time—often just ten minutes with paper and pen can provide significant value."
  },
  {
    "objectID": "lectures/lecture-01-content.html#core-workflow-components-1",
    "href": "lectures/lecture-01-content.html#core-workflow-components-1",
    "title": "Who are you?",
    "section": "Core Workflow Components",
    "text": "Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\n\nSimulate Data\nForces detailed thinking Clarifies expected data structure and distributions. Helps with cleaning and preparation Identifies potential issues beforehand. Provides clear testing framework Ensures data meets expectations. “Almost free” with modern computing Provides “an intimate feeling for the situation” [@hamming1996]\n\nSimulating data is the second step, forcing us into the details of our analysis by focusing on expected data structures and distributions. By creating simulated data, we define clear features that our real dataset should satisfy, aiding in data cleaning and preparation. For example, simulating an age-group variable with specific categories allows us to test the real data for consistency. Simulation is also vital for validating statistical models; by applying models to data with known properties, we can ensure they perform as intended before using them on real data. Since simulation is inexpensive and quick with modern computing resources, it provides “an intimate feeling for the situation” and helps build confidence in our analytical tools."
  },
  {
    "objectID": "lectures/lecture-01-content.html#core-workflow-components-2",
    "href": "lectures/lecture-01-content.html#core-workflow-components-2",
    "title": "Who are you?",
    "section": "Core Workflow Components",
    "text": "Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\n\nAcquire and Prepare\nOften overlooked but crucial stage Many difficult decisions required: data sources, formats, permissions. Can significantly affect statistical results [@huntington2021influence] Common challenges: quantity (too little or too much data) and quality\n\nAcquiring and preparing the actual data is often an overlooked yet challenging stage of the workflow that requires many critical decisions. This phase can significantly affect statistical results, as the choices made determine the quality and usability of the data. Researchers may feel overwhelmed—either by having too little data, raising concerns about the feasibility of analysis, or by having too much data, making it difficult to manage and process. Careful consideration, thorough cleaning, and preparation at this stage are crucial for the success of subsequent analysis, ensuring that the data are suitable for the questions being asked."
  },
  {
    "objectID": "lectures/lecture-01-content.html#core-workflow-components-3",
    "href": "lectures/lecture-01-content.html#core-workflow-components-3",
    "title": "Who are you?",
    "section": "Core Workflow Components",
    "text": "Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\n\nExplore and Understand\nBegin with descriptive statistics Move to statistical models\nRemember: Models are tools, not truth, and they reflect our previous decisions, data acquisition choices, and cleaning procedures.\n\nIn the fourth step, we explore and understand the actual data by examining relationships within the dataset. This process typically starts with descriptive statistics and progresses to statistical modeling. It’s important to remember that statistical models are tools—not absolute truths—and they operate based on the instructions we provide. They help us understand the data more clearly but do not offer definitive results. At this stage, the models we develop are heavily influenced by prior decisions made during data acquisition and preparation. Sophisticated modelers understand that models are like the visible tip of an iceberg, reliant on the substantial groundwork laid in earlier stages. They recognize that modeling results are shaped by choices about data inclusion, measurement, and recording, reflecting broader aspects of the world even before data reach the workflow."
  },
  {
    "objectID": "lectures/lecture-01-content.html#core-workflow-components-4",
    "href": "lectures/lecture-01-content.html#core-workflow-components-4",
    "title": "Who are you?",
    "section": "Core Workflow Components",
    "text": "Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\n\nShare Findings\nHigh-fidelity communication is essential Document all decisions Build credibility through transparency\n\nInclude:\nWhat was done Why it was done What was found Weaknesses of the approach\n\nThe final step is to share what was done and what was found, communicating with as much clarity and fidelity as possible. Effective communication involves detailing the decisions made throughout the workflow, the reasons behind them, the findings, and the limitations of the approach. We aim to uncover something important, so it’s essential to document everything initially, even if other forms of communication supplement the written record later. Openness about the entire process—from data acquisition to analysis—builds credibility and ensures others can fully engage with and understand the work. Without clear communication, even excellent work can be overlooked or misunderstood. While the world may not always reward merit alone, thorough and transparent communication enhances the impact of our work, and achieving mastery in this area requires significant experience and practice."
  },
  {
    "objectID": "lectures/lecture-01-content.html#quantitative-research-essentials-1",
    "href": "lectures/lecture-01-content.html#quantitative-research-essentials-1",
    "title": "Who are you?",
    "section": "Quantitative Research Essentials",
    "text": "Quantitative Research Essentials\n\n\n\n Communication Reproducibility Ethics Questions Measurement Data Collection Data Cleaning Exploratory Data Analysis Modeling Scaling\n\n\n\n\n\n\nEssential foundation for the data storytelling workflow."
  },
  {
    "objectID": "lectures/lecture-01-content.html#communication-most-important",
    "href": "lectures/lecture-01-content.html#communication-most-important",
    "title": "Who are you?",
    "section": "Communication (Most Important)",
    "text": "Communication (Most Important)\n\n“Simple analysis, communicated well, is more valuable than complicated analysis communicated poorly.” [@alexander2023telling]\n\n\n“One challenge is that as you immerse yourself in the data, it can be difficult to remember what it was like when you first came to it.” [@alexander2023telling]\n\n\nWrite in plain language\nUse tables, graphs, and models effectively\nFocus on the audience’s perspective"
  },
  {
    "objectID": "lectures/lecture-01-content.html#reproducibility",
    "href": "lectures/lecture-01-content.html#reproducibility",
    "title": "Who are you?",
    "section": "Reproducibility",
    "text": "Reproducibility\nEverything must be independently repeatable.\n\nRequirements:\nOpen access to code Data availability or simulation Automated testing Clear documentation Aim for autonomous end-to-end reproducibility"
  },
  {
    "objectID": "lectures/lecture-01-content.html#ethics",
    "href": "lectures/lecture-01-content.html#ethics",
    "title": "Who are you?",
    "section": "Ethics",
    "text": "Ethics\n\n“This means considering things like: who is in the dataset, who is missing, and why? To what extent will our story perpetuate the past? And is this something that ought to happen?” [@alexander2023telling]\n\nConsider the full context of the dataset [@datafeminism2020] Acknowledge the social, cultural, and political forces [@crawford] Use data ethically with concern for impact and equity"
  },
  {
    "objectID": "lectures/lecture-01-content.html#questions",
    "href": "lectures/lecture-01-content.html#questions",
    "title": "Who are you?",
    "section": "Questions",
    "text": "Questions\nQuestions evolve through understanding Challenge of operationalizing variables Curiosity is essential, drives deeper exploration Value of “hybrid” knowledge that combines multiple disciplines Comfort with asking “dumb” questions\n\nCuriosity is a key source of internal motivation that drives us to thoroughly explore a dataset and its associated processes. As we delve deeper, each question we pose tends to generate additional questions, leading to continual improvement and refinement of our understanding. This iterative questioning contrasts with the traditional Popperian approach of fixed hypothesis testing often taught quantitative methods courses in the sciences; instead, questions evolve continuously throughout the exploration. Finding an initial research question can be challenging, especially when attempting to operationalize it into measurable and available variables.\nStrategies to overcome this include selecting an area of genuine interest, sketching broad claims that can be honed into specific questions, and combining insights from different fields. Developing comfort with the inherent messiness of real-world data allows us to ask new questions as the data evolve. Knowing a dataset in detail often reveals unexpected patterns or anomalies, which we can explore further with subject-matter experts. Becoming a “hybrid”—cultivating knowledge across various disciplines—and being comfortable with asking seemingly simple or “dumb” questions are particularly valuable in enhancing our understanding and fostering meaningful insights."
  },
  {
    "objectID": "lectures/lecture-01-content.html#measurement",
    "href": "lectures/lecture-01-content.html#measurement",
    "title": "Who are you?",
    "section": "Measurement",
    "text": "Measurement\n\n“The world is so vibrant that it is difficult to reduce it to something that is possible to consistently measure and collect.” [@alexander2023telling]\n\n\n\nMeasuring even simple things is challenging (e.g., measuring height: Shoes on or off? Time of day affects height. Different tools yield different results). More complex measurements are even harder. How do we measure happiness or pain?\n Measurement requires decisions and is not value-free. Context and purpose guide all measurement choices.\n\n\n\n\nPicasso’s dog and the challenges of reduction.\n\n\n\n\n\nMeasurement and data collection involve the complex task of deciding how to translate the vibrant, multifaceted world into quantifiable data. This process is challenging because even seemingly simple measurements, like a person’s height, can vary based on factors like the time of day or the tools used (e.g., tape measure versus laser), making consistent comparison difficult and often unfeasible. The difficulty intensifies with more abstract concepts such as sadness or pain, where defining and measuring them consistently is even more problematic. This reduction of the world into data is not value-free; it requires critical decisions about what to measure, how to measure it, and what to ignore, all influenced by context and purpose. Like Picasso’s minimalist drawings that capture the essence of a dog but lack details necessary for specific assessments (e.g., determining if the dog is sick), we must deeply understand and respect what we’re measuring, carefully deciding which features are essential and which can be stripped away to serve our research objectives."
  },
  {
    "objectID": "lectures/lecture-01-content.html#data-collection-cleaning",
    "href": "lectures/lecture-01-content.html#data-collection-cleaning",
    "title": "Who are you?",
    "section": "Data Collection & Cleaning",
    "text": "Data Collection & Cleaning\n\n“Data never speak for themselves; they are the puppets of the ventriloquists that cleaned and prepared them.” [@alexander2023telling]\n\nCollection determines possibilities What and how we measure matters.\nCleaning requires many decisions E.g., Handling “prefer not to say” and open-text responses.\nDocument every step To ensure transparency and reproducibility.\nConsider implications of choices E.g., ethics, representation.\n\nData cleaning and preparation is a critical and complex part of data analysis that requires careful attention and numerous decisions. Decisions such as whether to exclude “prefer not to say” responses (which would ignore certain participants) or how to categorize open-text entries (where merging them with other categories might disrespect respondents’ specific choices) have significant implications. There is no universally correct approach; choices depend on the context and purpose of the analysis. Therefore, it’s vital to meticulously record every step of the data cleaning process to ensure transparency and allow others to understand the decisions made. Ultimately, data do not speak for themselves; they reflect the interpretations and choices of those who prepare and analyze them."
  },
  {
    "objectID": "lectures/lecture-01-content.html#exploratory-data-analysis-eda",
    "href": "lectures/lecture-01-content.html#exploratory-data-analysis-eda",
    "title": "Who are you?",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\nIterative process Never truly complete Shapes understanding\n\nExploratory Data Analysis (EDA) is an open-ended, iterative process that involves immersing ourselves in the data to understand its shape and structure before formal modeling begins. It includes producing summary statistics, creating graphs and tables, and sometimes even preliminary modeling. EDA requires a variety of skills and never truly finishes, as there’s always more to explore. Although it’s challenging to delineate where EDA ends and formal statistical modeling begins—since our beliefs and understanding evolve continuously—EDA is foundational in shaping the story we tell about our data. While not typically included explicitly in the final narrative, it’s crucial that all steps taken during EDA are recorded and shared."
  },
  {
    "objectID": "lectures/lecture-01-content.html#modeling",
    "href": "lectures/lecture-01-content.html#modeling",
    "title": "Who are you?",
    "section": "Modeling",
    "text": "Modeling\nTool for understanding Not a recipe to follow Just one representation of reality Statistical significance \\(\\neq\\) scientific significance Statistical models help us explore the shape of the data; are like echolocation\n\nStatistical modeling builds upon the insights gained from EDA and has a rich history spanning hundreds of years. Statistics is not merely a collection of dry theorems and proofs; it’s a way of exploring and understanding the world. A statistical model is not a rigid recipe to follow mechanically but a tool for making sense of data. Modeling is usually required to infer statistical patterns, formally known as statistical inference—the process of using data to infer the distribution that generated them. Importantly, statistical significance does not equate to scientific significance, and relying on arbitrary pass/fail tests is rarely appropriate. Instead, we should use statistical modeling as a form of echolocation, listening to what the models tell us about the shape of the world while recognizing that they offer just one representation of reality."
  },
  {
    "objectID": "lectures/lecture-01-content.html#scaling",
    "href": "lectures/lecture-01-content.html#scaling",
    "title": "Who are you?",
    "section": "Scaling",
    "text": "Scaling\nUsing programming languages like R and Python\nHandle large datasets efficiently Automate repetitive tasks Share work widely and quickly Outputs can reach many people easily APIs can make analyses accessible in real-time\n\nScaling our work becomes feasible with the use of programming languages like R and Python, which allow us to handle vast amounts of data efficiently. Scaling refers to both inputs and outputs; it’s essentially as easy to analyze ten observations as it is to analyze a million. This capability enables us to quickly determine the extent to which our findings apply. Additionally, our outputs can be disseminated to a wide audience effortlessly—whether it’s one person or a hundred. By utilizing Application Programming Interfaces (APIs), our analyses and stories can be accessed thousands of times per second, greatly enhancing their impact and accessibility."
  },
  {
    "objectID": "lectures/lecture-01-content.html#how-do-our-worlds-become-data-1",
    "href": "lectures/lecture-01-content.html#how-do-our-worlds-become-data-1",
    "title": "Who are you?",
    "section": "How Do Our Worlds Become Data?",
    "text": "How Do Our Worlds Become Data?\n\nTo a certain extent we are wasting our time. We have a perfect model of the world—it is the world! But it is too complicated. If we knew perfectly how everything was affected by the uncountable factors that influence it, then we could forecast perfectly a coin toss, a dice roll, and every other seemingly random process each time. But we cannot. Instead, we must simplify things to that which is plausibly measurable, and it is that which we define as data. Our data are a simplification of the messy, complex world from which they were derived.  There are different approximations of “plausibly measurable”. Hence, datasets are always the result of choices. We must decide whether they are nonetheless reasonable for the task at hand. We use statistical models to help us think deeply about, explore, and hopefully come to better understand, our data. [@alexander2023telling]"
  },
  {
    "objectID": "lectures/lecture-01-content.html#how-do-our-worlds-become-data-2",
    "href": "lectures/lecture-01-content.html#how-do-our-worlds-become-data-2",
    "title": "Who are you?",
    "section": "How Do Our Worlds Become Data?",
    "text": "How Do Our Worlds Become Data?\n Through skillfulreduction 👨‍🍳\n\nJust as a chef reduces a rich sauce to concentrate its essential flavors, we simplify reality into data—plausibly measurable approximations that capture the essence of the complex world. This reduction process involves deliberate choices about what aspects of reality to include, much like deciding which ingredients to emphasize in a culinary reduction. Our datasets, therefore, are distilled versions of reality, highlighting specific components while inevitably leaving out others.\nAs we employ statistical models to explore and understand these datasets, it’s crucial to recognize both what the data include and what they omit. Similar to how a reduction in cooking intensifies certain flavors while others may be lost or muted, the process of data simplification can inadvertently exclude important nuances or perspectives. Particularly in data science, where human-generated data are prevalent, we must consider who or what is systematically missing from our datasets. Some individuals or phenomena may not fit neatly into our chosen methods and might be oversimplified or excluded entirely. The abstraction and simplification inherent in turning the world into data require careful judgment—much like a chef monitoring a reduction to achieve the desired consistency without overcooking—to determine when simplification is appropriate and when it risks losing critical information.\nMeasurement itself presents significant challenges, and those deeply involved in the data collection process often have less trust in the data than those removed from it. Just as the process of reducing a sauce demands constant attention to prevent burning or altering the intended flavor, converting the world into data involves numerous decisions and potential errors—from selecting what to measure to deciding on the methods and accuracy required. Advances in instruments—from telescopes in astronomy to real-time internet data collection—have expanded our ability to gather data, much like new culinary techniques enhance a chef’s ability to create complex dishes. However, the world still imperfectly becomes data, and to truly learn from it, we must actively seek to understand the imperfections in our datasets and consider how our “reduction” process may have altered or omitted important aspects of reality."
  },
  {
    "objectID": "lectures/lecture-01-content.html#embracing-the-challenge-1",
    "href": "lectures/lecture-01-content.html#embracing-the-challenge-1",
    "title": "Who are you?",
    "section": "Embracing the Challenge",
    "text": "Embracing the Challenge\n\n“Ultimately, we are all just telling stories with data, but these stories are increasingly among the most important in the world.” [@alexander2023telling]\n\nTelling good stories with data is difficult but rewarding.\nDevelop resilience and intrinsic motivation. Accept that failure is part of the process. Consider possibilities and probabilities. Learn to make trade-offs. No perfect analysis exists. Aim for transparency and continuous improvement."
  },
  {
    "objectID": "lectures/lecture-01-content.html#key-takeaways",
    "href": "lectures/lecture-01-content.html#key-takeaways",
    "title": "Who are you?",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nData storytelling bridges analysis and understanding\nEffective communication is paramount\nEthics and reproducibility are foundational\nAsk meaningful questions and measure thoughtfully and transparently\nData collection and cleaning shape your analysis\nEmbrace the iterative nature of exploration and modeling\nLeverage technology to scale and share your work\nBe mindful of the limitations of your data"
  },
  {
    "objectID": "lectures/lecture-01-content.html#section-1",
    "href": "lectures/lecture-01-content.html#section-1",
    "title": "Who are you?",
    "section": "",
    "text": "Brightspace Course materials website: johnmclevey.com/SOCI3040/"
  },
  {
    "objectID": "lectures/lecture-01-content.html#next-class",
    "href": "lectures/lecture-01-content.html#next-class",
    "title": "Who are you?",
    "section": "Next class",
    "text": "Next class\n\nBefore class: Complete the assigned reading In class: Introduction to R and RStudio"
  },
  {
    "objectID": "deliverables/submissions/assignment-4/example-submission-5.html",
    "href": "deliverables/submissions/assignment-4/example-submission-5.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\nNulla eget cursus ipsum. Vivamus porttitor leo diam, sed volutpat lectus facilisis sit amet. Maecenas et pulvinar metus. Ut at dignissim tellus. In in tincidunt elit. Etiam vulputate lobortis arcu, vel faucibus leo lobortis ac. Aliquam erat volutpat. In interdum orci ac est euismod euismod. Nunc eleifend tristique risus, at lacinia odio commodo in. Sed aliquet ligula odio, sed tempor neque ultricies sit amet.\nEtiam quis tortor luctus, pellentesque ante a, finibus dolor. Phasellus in nibh et magna pulvinar malesuada. Ut nisl ex, sagittis at sollicitudin et, sollicitudin id nunc. In id porta urna. Proin porta dolor dolor, vel dapibus nisi lacinia in. Pellentesque ante mauris, ornare non euismod a, fermentum ut sapien. Proin sed vehicula enim. Aliquam tortor odio, vestibulum vitae odio in, tempor molestie justo. Praesent maximus lacus nec leo maximus blandit."
  },
  {
    "objectID": "deliverables/submissions/assignment-4/example-submission-3.html",
    "href": "deliverables/submissions/assignment-4/example-submission-3.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nNulla eget cursus ipsum. Vivamus porttitor leo diam, sed volutpat lectus facilisis sit amet. Maecenas et pulvinar metus. Ut at dignissim tellus. In in tincidunt elit. Etiam vulputate lobortis arcu, vel faucibus leo lobortis ac. Aliquam erat volutpat. In interdum orci ac est euismod euismod. Nunc eleifend tristique risus, at lacinia odio commodo in. Sed aliquet ligula odio, sed tempor neque ultricies sit amet.\nEtiam quis tortor luctus, pellentesque ante a, finibus dolor. Phasellus in nibh et magna pulvinar malesuada. Ut nisl ex, sagittis at sollicitudin et, sollicitudin id nunc. In id porta urna. Proin porta dolor dolor, vel dapibus nisi lacinia in. Pellentesque ante mauris, ornare non euismod a, fermentum ut sapien. Proin sed vehicula enim. Aliquam tortor odio, vestibulum vitae odio in, tempor molestie justo. Praesent maximus lacus nec leo maximus blandit."
  },
  {
    "objectID": "deliverables/submissions/assignment-4/example-submission-1.html",
    "href": "deliverables/submissions/assignment-4/example-submission-1.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nAenean placerat luctus tortor vitae molestie. Nulla at aliquet nulla. Sed efficitur tellus orci, sed fringilla lectus laoreet eget. Vivamus maximus quam sit amet arcu dignissim, sed accumsan massa ullamcorper. Sed iaculis tincidunt feugiat. Nulla in est at nunc ultricies dictum ut vitae nunc. Aenean convallis vel diam at malesuada. Suspendisse arcu libero, vehicula tempus ultrices a, placerat sit amet tortor. Sed dictum id nulla commodo mattis. Aliquam mollis, nunc eu tristique faucibus, purus lacus tincidunt nulla, ac pretium lorem nunc ut enim. Curabitur eget mattis nisl, vitae sodales augue. Nam felis massa, bibendum sit amet nulla vel, vulputate rutrum lacus. Aenean convallis odio pharetra nulla mattis consequat.\nUt ut condimentum augue, nec eleifend nisl. Sed facilisis egestas odio ac pretium. Pellentesque consequat magna sed venenatis sagittis. Vivamus feugiat lobortis magna vitae accumsan. Pellentesque euismod malesuada hendrerit. Ut non mauris non arcu condimentum sodales vitae vitae dolor. Nullam dapibus, velit eget lacinia rutrum, ipsum justo malesuada odio, et lobortis sapien magna vel lacus. Nulla purus neque, hendrerit non malesuada eget, mattis vel erat. Suspendisse potenti."
  },
  {
    "objectID": "deliverables/submissions/assignment-3/example-submission-4.html",
    "href": "deliverables/submissions/assignment-3/example-submission-4.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\nEtiam quis tortor luctus, pellentesque ante a, finibus dolor. Phasellus in nibh et magna pulvinar malesuada. Ut nisl ex, sagittis at sollicitudin et, sollicitudin id nunc. In id porta urna. Proin porta dolor dolor, vel dapibus nisi lacinia in. Pellentesque ante mauris, ornare non euismod a, fermentum ut sapien. Proin sed vehicula enim. Aliquam tortor odio, vestibulum vitae odio in, tempor molestie justo. Praesent maximus lacus nec leo maximus blandit.\nMaecenas turpis velit, ultricies non elementum vel, luctus nec nunc. Nulla a diam interdum, faucibus sapien viverra, finibus metus. Donec non tortor diam. In ut elit aliquet, bibendum sem et, aliquam tortor. Donec congue, sem at rhoncus ultrices, nunc augue cursus erat, quis porttitor mauris libero ut ex. Nullam quis leo urna. Donec faucibus ligula eget pellentesque interdum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean rhoncus interdum erat ut ultricies. Aenean tempus ex non elit suscipit, quis dignissim enim efficitur. Proin laoreet enim massa, vitae laoreet nulla mollis quis."
  },
  {
    "objectID": "deliverables/submissions/assignment-3/example-submission-2.html",
    "href": "deliverables/submissions/assignment-3/example-submission-2.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nNullam dapibus cursus dolor sit amet consequat. Nulla facilisi. Curabitur vel nulla non magna lacinia tincidunt. Duis porttitor quam leo, et blandit velit efficitur ut. Etiam auctor tincidunt porttitor. Phasellus sed accumsan mi. Fusce ut erat dui. Suspendisse eu augue eget turpis condimentum finibus eu non lorem. Donec finibus eros eu ante condimentum, sed pharetra sapien sagittis. Phasellus non dolor ac ante mollis auctor nec et sapien. Pellentesque vulputate at nisi eu tincidunt. Vestibulum at dolor aliquam, hendrerit purus eu, eleifend massa. Morbi consectetur eros id tincidunt gravida. Fusce ut enim quis orci hendrerit lacinia sed vitae enim.\nNulla eget cursus ipsum. Vivamus porttitor leo diam, sed volutpat lectus facilisis sit amet. Maecenas et pulvinar metus. Ut at dignissim tellus. In in tincidunt elit. Etiam vulputate lobortis arcu, vel faucibus leo lobortis ac. Aliquam erat volutpat. In interdum orci ac est euismod euismod. Nunc eleifend tristique risus, at lacinia odio commodo in. Sed aliquet ligula odio, sed tempor neque ultricies sit amet."
  },
  {
    "objectID": "deliverables/submissions/assignment-2/example-submission-5.html",
    "href": "deliverables/submissions/assignment-2/example-submission-5.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\nNullam dapibus cursus dolor sit amet consequat. Nulla facilisi. Curabitur vel nulla non magna lacinia tincidunt. Duis porttitor quam leo, et blandit velit efficitur ut. Etiam auctor tincidunt porttitor. Phasellus sed accumsan mi. Fusce ut erat dui. Suspendisse eu augue eget turpis condimentum finibus eu non lorem. Donec finibus eros eu ante condimentum, sed pharetra sapien sagittis. Phasellus non dolor ac ante mollis auctor nec et sapien. Pellentesque vulputate at nisi eu tincidunt. Vestibulum at dolor aliquam, hendrerit purus eu, eleifend massa. Morbi consectetur eros id tincidunt gravida. Fusce ut enim quis orci hendrerit lacinia sed vitae enim.\nNulla eget cursus ipsum. Vivamus porttitor leo diam, sed volutpat lectus facilisis sit amet. Maecenas et pulvinar metus. Ut at dignissim tellus. In in tincidunt elit. Etiam vulputate lobortis arcu, vel faucibus leo lobortis ac. Aliquam erat volutpat. In interdum orci ac est euismod euismod. Nunc eleifend tristique risus, at lacinia odio commodo in. Sed aliquet ligula odio, sed tempor neque ultricies sit amet."
  },
  {
    "objectID": "deliverables/submissions/assignment-2/example-submission-3.html",
    "href": "deliverables/submissions/assignment-2/example-submission-3.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nEtiam quis tortor luctus, pellentesque ante a, finibus dolor. Phasellus in nibh et magna pulvinar malesuada. Ut nisl ex, sagittis at sollicitudin et, sollicitudin id nunc. In id porta urna. Proin porta dolor dolor, vel dapibus nisi lacinia in. Pellentesque ante mauris, ornare non euismod a, fermentum ut sapien. Proin sed vehicula enim. Aliquam tortor odio, vestibulum vitae odio in, tempor molestie justo. Praesent maximus lacus nec leo maximus blandit.\nMaecenas turpis velit, ultricies non elementum vel, luctus nec nunc. Nulla a diam interdum, faucibus sapien viverra, finibus metus. Donec non tortor diam. In ut elit aliquet, bibendum sem et, aliquam tortor. Donec congue, sem at rhoncus ultrices, nunc augue cursus erat, quis porttitor mauris libero ut ex. Nullam quis leo urna. Donec faucibus ligula eget pellentesque interdum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean rhoncus interdum erat ut ultricies. Aenean tempus ex non elit suscipit, quis dignissim enim efficitur. Proin laoreet enim massa, vitae laoreet nulla mollis quis."
  },
  {
    "objectID": "deliverables/submissions/assignment-2/example-submission-1.html",
    "href": "deliverables/submissions/assignment-2/example-submission-1.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nEtiam maximus accumsan gravida. Maecenas at nunc dignissim, euismod enim ac, bibendum ipsum. Maecenas vehicula velit in nisl aliquet ultricies. Nam eget massa interdum, maximus arcu vel, pretium erat. Maecenas sit amet tempor purus, vitae aliquet nunc. Vivamus cursus urna velit, eleifend dictum magna laoreet ut. Duis eu erat mollis, blandit magna id, tincidunt ipsum. Integer massa nibh, commodo eu ex vel, venenatis efficitur ligula. Integer convallis lacus elit, maximus eleifend lacus ornare ac. Vestibulum scelerisque viverra urna id lacinia. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget enim at diam bibendum tincidunt eu non purus. Nullam id magna ultrices, sodales metus viverra, tempus turpis.\nDuis ornare ex ac iaculis pretium. Maecenas sagittis odio id erat pharetra, sit amet consectetur quam sollicitudin. Vivamus pharetra quam purus, nec sagittis risus pretium at. Nullam feugiat, turpis ac accumsan interdum, sem tellus blandit neque, id vulputate diam quam semper nisl. Donec sit amet enim at neque porttitor aliquet. Phasellus facilisis nulla eget placerat eleifend. Vestibulum non egestas eros, eget lobortis ipsum. Nulla rutrum massa eget enim aliquam, id porttitor erat luctus. Nunc sagittis quis eros eu sagittis. Pellentesque dictum, erat at pellentesque sollicitudin, justo augue pulvinar metus, quis rutrum est mi nec felis. Vestibulum efficitur mi lorem, at elementum purus tincidunt a. Aliquam finibus enim magna, vitae pellentesque erat faucibus at. Nulla mauris tellus, imperdiet id lobortis et, dignissim condimentum ipsum. Morbi nulla orci, varius at aliquet sed, facilisis id tortor. Donec ut urna nisi."
  },
  {
    "objectID": "deliverables/submissions/assignment-1/example-submission-4.html",
    "href": "deliverables/submissions/assignment-1/example-submission-4.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti."
  },
  {
    "objectID": "deliverables/submissions/assignment-1/example-submission-2.html",
    "href": "deliverables/submissions/assignment-1/example-submission-2.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti."
  },
  {
    "objectID": "syllabus/schedule.html",
    "href": "syllabus/schedule.html",
    "title": " Course Schedule",
    "section": "",
    "text": "In the table below,\n\n refers to Alexander’s (2023) Telling Stories with Data (required)\n refers to Healy’s (2019) Data Visualization: A Practical Introduction (supplementary / optional)\n refers to McElreath’s (2023) Statistical Rethinking 2023 Lectures (supplementary / optional)\n\nEach file icon links directly to the assigned or supplementary materials.\n\n\n\n\n\n\n\n\n\nNo.\n\n\nClass Date\n\n\nClass & Lab Notes + Slides\n\n\n Required\n\n\n Recommended\n\n\nDue by 5:00 pm\n\n\n\n\n\n\n01\n\n\n1/7/25\n\n\nIntroduction + Telling Stories with Data\n\n\nBrowse this site\n\n\n \n\n\n \n\n\n\n\n02\n\n\n1/9/25\n\n\nTelling Stories with Data + R & the Tidyverse\n\n\n  Ch 1\n\n\n  Appendix A\n\n\n \n\n\n\n\n03\n\n\n1/14/25\n\n\nData Analysis Workflow – The Firehose\n\n\n  Ch 2\n\n\n  Ch 1\n\n\n \n\n\n\n\n04\n\n\n1/16/25\n\n\nData Analysis Workflow – The Firehose\n\n\n  Ch 2\n\n\n  Ch 1\n\n\n \n\n\n\n\n05\n\n\n1/21/25\n\n\nReproducible Workflows with R & RStudio\n\n\n  Ch 3\n\n\n  Ch 2\n\n\n \n\n\n\n\n06\n\n\n1/23/25\n\n\nReproducible Workflows with R & RStudio\n\n\n  Ch 3\n\n\n  Ch 2\n\n\n \n\n\n\n\n07\n\n\n1/28/25\n\n\nWriting and Developing Research Questions\n\n\n  Ch 4\n\n\n  Ch 3\n\n\n \n\n\n\n\n08\n\n\n1/30/25\n\n\nWriting and Developing Research Questions\n\n\n  Ch 4\n\n\n  Ch 3\n\n\nData Stories 1\n\n\n\n\n09\n\n\n2/4/25\n\n\nCreating Graphs, Tables, & Maps\n\n\n  Ch 5\n\n\n  Ch 4\n\n\n \n\n\n\n\n10\n\n\n2/6/25\n\n\nCreating Graphs, Tables, & Maps\n\n\n  Ch 5\n\n\n  Ch 4\n\n\n \n\n\n\n\n11\n\n\n2/11/25\n\n\nMeasurement, Censuses, and Sampling\n\n\n  Ch 6\n\n\n  Ch 5\n\n\n \n\n\n\n\n12\n\n\n2/13/25\n\n\nMeasurement, Censuses, and Sampling\n\n\n  Ch 6\n\n\n  Ch 5\n\n\n \n\n\n\n\n13\n\n\n2/18/25\n\n\nAPIs, Scraping, and Parsing\n\n\n  Ch 7\n\n\n  Ch 7\n\n\n \n\n\n\n\n14\n\n\n2/20/25\n\n\nAPIs, Scraping, and Parsing\n\n\n  Ch 7\n\n\n  Ch 7\n\n\nData Stories 2\n\n\n\n\n15\n\n\n3/4/25\n\n\nExperiments and Surveys\n\n\n  Ch 8\n\n\n  Ch 8\n\n\n \n\n\n\n\n16\n\n\n3/6/25\n\n\nExperiments and Surveys\n\n\n  Ch 8\n\n\n  Ch 8\n\n\n \n\n\n\n\n17\n\n\n3/11/25\n\n\nCleaning, Preparing, and Testing\n\n\n  Ch 9\n\n\n  Statistical Golems\n\n\n \n\n\n\n\n18\n\n\n3/13/25\n\n\nCleaning, Preparing, and Testing\n\n\n  Ch 9\n\n\n  Statistical Golems\n\n\n \n\n\n\n\n19\n\n\n3/18/25\n\n\nExploratory Data Analysis (EDA)\n\n\n  Ch 11\n\n\n  The Garden of Forking Data\n\n\n \n\n\n\n\n20\n\n\n3/20/25\n\n\nExploratory Data Analysis (EDA)\n\n\n  Ch 11\n\n\n  The Garden of Forking Data\n\n\nData Stories 3\n\n\n\n\n21\n\n\n3/25/25\n\n\nLinear Models\n\n\n  Ch 12\n\n\n  Geocentric Models\n\n\n \n\n\n\n\n22\n\n\n3/27/25\n\n\nLinear Models\n\n\n  Ch 12\n\n\n  Geocentric Models\n\n\n \n\n\n\n\n23\n\n\n4/1/25\n\n\nGeneralized Linear Models (GLMs)\n\n\n  Ch 13\n\n\n  Ch 6\n\n\n \n\n\n\n\n24\n\n\n4/3/25\n\n\nGeneralized Linear Models (GLMs)\n\n\n  Ch 13\n\n\n  Ch 6\n\n\n \n\n\n\n\n25\n\n\n4/8/25\n\n\nProject Work\n\n\n \n\n\n \n\n\nData Stories 4\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\nReferences\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nHealy, Kieran. 2019. Data Visualization: A Practical Introduction. Princeton University Press.\n\n\nMcElreath, Richard. 2023. “Statistical Rethinking Lectures.” YouTube. https://www.youtube.com/playlist?list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus.",
    "crumbs": [
      "Syllabus",
      "<strong>SYLLABUS</strong>",
      "&nbsp;&nbsp;Course Schedule"
    ]
  },
  {
    "objectID": "syllabus/computing.html",
    "href": "syllabus/computing.html",
    "title": " Computing",
    "section": "",
    "text": "R and Quarto 😁 – No Experience Necessary  You will learn to use R (a free/open source programming language and environment for statistical computing and graphics) and Quarto (a free/open source publishing system for creating dynamic and reproducible manuscripts, reports, websites, and presentations) in this course. Note that I assume no prior experience with R or Quarto. Everything you need to know about both will be introduced in the course. While some prior programming experience is an asset, it is by no means necessary.",
    "crumbs": [
      "Syllabus",
      "<strong>SYLLABUS</strong>",
      "&nbsp;&nbsp;Computing"
    ]
  },
  {
    "objectID": "lectures/list-lectures.html",
    "href": "lectures/list-lectures.html",
    "title": " Class & Lab Notes",
    "section": "",
    "text": "Introduction + Telling Stories with Data\n\n\n\nTuesday, January 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTelling Stories with Data + R & the Tidyverse\n\n\n\nThursday, January 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nData Analysis Workflow – The Firehose\n\n\n\nTuesday, January 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nData Analysis Workflow – The Firehose\n\n\n\nThursday, January 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nReproducible Workflows with R & RStudio\n\n\n\nTuesday, January 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nReproducible Workflows with R & RStudio\n\n\n\nThursday, January 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nWriting and Developing Research Questions\n\n\n\nTuesday, January 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nWriting and Developing Research Questions\n\n\n\nThursday, January 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Graphs, Tables, & Maps\n\n\n\nTuesday, February 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Graphs, Tables, & Maps\n\n\n\nThursday, February 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMeasurement, Censuses, and Sampling\n\n\n\nTuesday, February 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMeasurement, Censuses, and Sampling\n\n\n\nThursday, February 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs, Scraping, and Parsing\n\n\n\nTuesday, February 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs, Scraping, and Parsing\n\n\n\nThursday, February 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nExperiments and Surveys\n\n\n\nTuesday, March 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nExperiments and Surveys\n\n\n\nThursday, March 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCleaning, Preparing, and Testing\n\n\n\nTuesday, March 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCleaning, Preparing, and Testing\n\n\n\nThursday, March 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis (EDA)\n\n\n\nTuesday, March 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis (EDA)\n\n\n\nThursday, March 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Models\n\n\n\nTuesday, March 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Models\n\n\n\nThursday, March 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nGeneralized Linear Models (GLMs)\n\n\n\nTuesday, April 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nGeneralized Linear Models (GLMs)\n\n\n\nThursday, April 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nProject Work\n\n\n\nTuesday, April 8, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lectures/lecture-24-slides.html#references",
    "href": "lectures/lecture-24-slides.html#references",
    "title": "Generalized Linear Models (GLMs)",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-22-slides.html#references",
    "href": "lectures/lecture-22-slides.html#references",
    "title": "Linear Models",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-20-slides.html#references",
    "href": "lectures/lecture-20-slides.html#references",
    "title": "Generalized Linear Models (Count Outcomes)",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-18-slides.html#references",
    "href": "lectures/lecture-18-slides.html#references",
    "title": "Cleaning, Preparing, and Testing",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-16-slides.html#references",
    "href": "lectures/lecture-16-slides.html#references",
    "title": "Experiments and Surveys",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-14-slides.html#references",
    "href": "lectures/lecture-14-slides.html#references",
    "title": "APIs, Scraping, and Parsing",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-12-slides.html#references",
    "href": "lectures/lecture-12-slides.html#references",
    "title": "Measurement, Censuses, and Sampling",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-10-slides.html#references",
    "href": "lectures/lecture-10-slides.html#references",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-08-slides.html#references",
    "href": "lectures/lecture-08-slides.html#references",
    "title": "Writing and Developing Research Questions",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-06-slides.html#references",
    "href": "lectures/lecture-06-slides.html#references",
    "title": "Reproducible Workflows with R and RStudio",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-04-slides.html#references",
    "href": "lectures/lecture-04-slides.html#references",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "deliverables/assignment-4.html",
    "href": "deliverables/assignment-4.html",
    "title": " Data Stories 4",
    "section": "",
    "text": "Assignment information will be provided in class on March 27th. We will work on the assignment in class and then you will finish and submit the assignment by end of day on Monday April 8th.",
    "crumbs": [
      "Syllabus",
      "<strong>ASSIGNMENTS</strong>",
      "&nbsp;&nbsp;Data Stories  4"
    ]
  },
  {
    "objectID": "deliverables/assignment-4.html#assignment-instructions",
    "href": "deliverables/assignment-4.html#assignment-instructions",
    "title": " Data Stories 4",
    "section": "",
    "text": "Assignment information will be provided in class on March 27th. We will work on the assignment in class and then you will finish and submit the assignment by end of day on Monday April 8th.",
    "crumbs": [
      "Syllabus",
      "<strong>ASSIGNMENTS</strong>",
      "&nbsp;&nbsp;Data Stories  4"
    ]
  },
  {
    "objectID": "deliverables/assignment-2.html",
    "href": "deliverables/assignment-2.html",
    "title": " Data Stories 2",
    "section": "",
    "text": "Assignment information will be provided in class on March 6th. We will work on the assignment in class and then you will finish and submit the assignment by end of day on Monday March 10th.",
    "crumbs": [
      "Syllabus",
      "<strong>ASSIGNMENTS</strong>",
      "&nbsp;&nbsp;Data Stories 2"
    ]
  },
  {
    "objectID": "deliverables/assignment-2.html#assignment-instructions",
    "href": "deliverables/assignment-2.html#assignment-instructions",
    "title": " Data Stories 2",
    "section": "",
    "text": "Assignment information will be provided in class on March 6th. We will work on the assignment in class and then you will finish and submit the assignment by end of day on Monday March 10th.",
    "crumbs": [
      "Syllabus",
      "<strong>ASSIGNMENTS</strong>",
      "&nbsp;&nbsp;Data Stories 2"
    ]
  },
  {
    "objectID": "lectures/lecture-14-content.html",
    "href": "lectures/lecture-14-content.html",
    "title": "🔥 Quantitative Research Methods",
    "section": "",
    "text": "In class activities focused on introducing basic knowledge of the web as a foundation for understanding APIs and scraping-based approaches to data collection. Used OpenAlex and The Guardian as example for APIs."
  },
  {
    "objectID": "lectures/lecture-12-content.html",
    "href": "lectures/lecture-12-content.html",
    "title": "🔥 Quantitative Research Methods",
    "section": "",
    "text": "John sick, class cancelled."
  },
  {
    "objectID": "lectures/lecture-10-content.html",
    "href": "lectures/lecture-10-content.html",
    "title": "🔥 Quantitative Research Methods",
    "section": "",
    "text": "Review Class"
  },
  {
    "objectID": "lectures/lecture-07-content.html",
    "href": "lectures/lecture-07-content.html",
    "title": "Work on Assignment 1 in Class",
    "section": "",
    "text": "Work on Assignment 1 in Class\nYou may complete the assignment individually or in groups of 2-3. If working collaboratively, each member must submit their own assignment with the group’s names listed in the author metadata above.\nSteps to Complete the Assignment:\n\nCreate a free or student account ($5/month) with PositCloud.\nCreate a new workspace.\nIn the workspace, create a new project from a Github repository using this link: https://github.com/mclevey/3040-2025-assignment-1-posit.git.\nOpen assignment-1.qmd and update the author metadata at the top of the file.\nFollow the instructions in the notebook, executing the code cells as you go. Note that one of the instructions asks you to insert a citation to the assigned reading. Citation information is already entered into the refs.bib file.\n“Knit” your document to an HTML file. Make sure it executes without errors and preview the result.\nSave the HTML file and upload it to the Dropbox on Brightspace."
  },
  {
    "objectID": "lectures/lecture-05-content.html",
    "href": "lectures/lecture-05-content.html",
    "title": "🔥 Quantitative Research Methods",
    "section": "",
    "text": "Sociology Student Society? Rep?\nHave made some decisions about pacing and assignments\n\npacing and delivery: more walkthroughs, pace seems OK so far?\nfirst assignment: basic use of RStudio, the workflow components, more writing, limited code, will not include Git or GitHub\n\n\nToday:\n\nR Projects\nQuarto – examples form chapter, more metadata\nLoad the data from last class"
  },
  {
    "objectID": "lectures/lecture-08-content.html",
    "href": "lectures/lecture-08-content.html",
    "title": "Work on Assignment 1 in Class",
    "section": "",
    "text": "Work on Assignment 1 in Class\nYou may complete the assignment individually or in groups of 2-3. If working collaboratively, each member must submit their own assignment with the group’s names listed in the author metadata above.\nSteps to Complete the Assignment:\n\nCreate a free or student account ($5/month) with PositCloud.\nCreate a new workspace.\nIn the workspace, create a new project from a Github repository using this link: https://github.com/mclevey/3040-2025-assignment-1-posit.git.\nOpen assignment-1.qmd and update the author metadata at the top of the file.\nFollow the instructions in the notebook, executing the code cells as you go. Note that one of the instructions asks you to insert a citation to the assigned reading. Citation information is already entered into the refs.bib file.\n“Knit” your document to an HTML file. Make sure it executes without errors and preview the result.\nSave the HTML file and upload it to the Dropbox on Brightspace."
  },
  {
    "objectID": "lectures/lecture-11-content.html",
    "href": "lectures/lecture-11-content.html",
    "title": "🔥 Quantitative Research Methods",
    "section": "",
    "text": "In class activities focused on understanding the theory behind, and practical realities of,\n\ncensus data\nsimple random sampling\nstratified random sampling\ncluster-based sampling\nmulti-stage cluster sampling"
  },
  {
    "objectID": "lectures/lecture-13-content.html",
    "href": "lectures/lecture-13-content.html",
    "title": "🔥 Quantitative Research Methods",
    "section": "",
    "text": "In class activities focused on understanding the theory behind, and practical realities of,\n\ncensus data\nsimple random sampling\nstratified random sampling\ncluster-based sampling\nmulti-stage cluster sampling"
  },
  {
    "objectID": "deliverables/assignment-1.html",
    "href": "deliverables/assignment-1.html",
    "title": " Data Stories 1",
    "section": "",
    "text": "You may complete the assignment individually or in groups of 2-3. If working collaboratively, each member must submit their own assignment with the group’s names listed in the author metadata above.\nSteps to Complete the Assignment:\n\nCreate a free or student account ($5/month) with PositCloud.\nCreate a new workspace.\nIn the workspace, create a new project from a Github repository using this link: https://github.com/mclevey/3040-2025-assignment-1-posit.git.\nOpen assignment-1.qmd and update the author metadata at the top of the file.\nFollow the instructions in the notebook, executing the code cells as you go. Note that one of the instructions asks you to insert a citation to the assigned reading. Citation information is already entered into the refs.bib file.\n“Knit” your document to an HTML file. Make sure it executes without errors and preview the result.\nSave the HTML file and upload it to the Dropbox on Brightspace.",
    "crumbs": [
      "Syllabus",
      "<strong>ASSIGNMENTS</strong>",
      "&nbsp;&nbsp;Data Stories 1"
    ]
  },
  {
    "objectID": "deliverables/assignment-1.html#assignment-1-overview",
    "href": "deliverables/assignment-1.html#assignment-1-overview",
    "title": " Data Stories 1",
    "section": "",
    "text": "You may complete the assignment individually or in groups of 2-3. If working collaboratively, each member must submit their own assignment with the group’s names listed in the author metadata above.\nSteps to Complete the Assignment:\n\nCreate a free or student account ($5/month) with PositCloud.\nCreate a new workspace.\nIn the workspace, create a new project from a Github repository using this link: https://github.com/mclevey/3040-2025-assignment-1-posit.git.\nOpen assignment-1.qmd and update the author metadata at the top of the file.\nFollow the instructions in the notebook, executing the code cells as you go. Note that one of the instructions asks you to insert a citation to the assigned reading. Citation information is already entered into the refs.bib file.\n“Knit” your document to an HTML file. Make sure it executes without errors and preview the result.\nSave the HTML file and upload it to the Dropbox on Brightspace.",
    "crumbs": [
      "Syllabus",
      "<strong>ASSIGNMENTS</strong>",
      "&nbsp;&nbsp;Data Stories 1"
    ]
  },
  {
    "objectID": "deliverables/assignment-3.html",
    "href": "deliverables/assignment-3.html",
    "title": " Data Stories 3",
    "section": "",
    "text": "Assignment information will be provided in class on March 18th. We will work on the assignment in class and then you will finish and submit the assignment by end of day on Monday March 24th.",
    "crumbs": [
      "Syllabus",
      "<strong>ASSIGNMENTS</strong>",
      "&nbsp;&nbsp;Data Stories 3"
    ]
  },
  {
    "objectID": "deliverables/assignment-3.html#assignment-instructions",
    "href": "deliverables/assignment-3.html#assignment-instructions",
    "title": " Data Stories 3",
    "section": "",
    "text": "Assignment information will be provided in class on March 18th. We will work on the assignment in class and then you will finish and submit the assignment by end of day on Monday March 24th.",
    "crumbs": [
      "Syllabus",
      "<strong>ASSIGNMENTS</strong>",
      "&nbsp;&nbsp;Data Stories 3"
    ]
  },
  {
    "objectID": "deliverables/assignment-5.html",
    "href": "deliverables/assignment-5.html",
    "title": " Final Exam",
    "section": "",
    "text": "Not yet scheduled!\nInformation coming soon…\n\nMultiple choice\nTrue / false\nShort answer\nSketch models and graphs\nInterpret models and graphs\nExplain code snippets at a high-level"
  },
  {
    "objectID": "lectures/lecture-05-slides.html#references",
    "href": "lectures/lecture-05-slides.html#references",
    "title": "Reproducible Workflows with R and RStudio",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-07-slides.html#references",
    "href": "lectures/lecture-07-slides.html#references",
    "title": "Writing and Developing Research Questions",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-09-slides.html#references",
    "href": "lectures/lecture-09-slides.html#references",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-11-slides.html#references",
    "href": "lectures/lecture-11-slides.html#references",
    "title": "Measurement, Censuses, and Sampling",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-13-slides.html#references",
    "href": "lectures/lecture-13-slides.html#references",
    "title": "APIs, Scraping, and Parsing",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-15-slides.html#references",
    "href": "lectures/lecture-15-slides.html#references",
    "title": "Experiments and Surveys",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-17-slides.html#references",
    "href": "lectures/lecture-17-slides.html#references",
    "title": "Cleaning, Preparing, and Testing",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-19-slides.html#references",
    "href": "lectures/lecture-19-slides.html#references",
    "title": "Generalized Linear Models (Binary Outcomes)",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-21-slides.html#references",
    "href": "lectures/lecture-21-slides.html#references",
    "title": "Linear Models",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-23-slides.html#references",
    "href": "lectures/lecture-23-slides.html#references",
    "title": "Generalized Linear Models (GLMs)",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "lectures/lecture-25-slides.html#references",
    "href": "lectures/lecture-25-slides.html#references",
    "title": "Project Work",
    "section": "1 References",
    "text": "1 References"
  },
  {
    "objectID": "syllabus/assessment.html",
    "href": "syllabus/assessment.html",
    "title": " Assessment",
    "section": "",
    "text": "There are four lab assignments (i.e., “Data Stories”) and a final exam in this course.\n\n\n\nDue (on or before)\nBy\nAssignment\nWeight\n\n\n\n\nJanuary 28, 2025\n11:59 pm\nData Stories 1\n10%\n\n\nFebruary 20, 2025\n11:59 pm\nData Stories 2\n15%\n\n\nMarch 20, 2025\n11:59 pm\nData Stories 3\n25%\n\n\nApril 8, 2025\n11:59 pm\nData Stories 4\n25%\n\n\nTBA\nTBA\nFinal Exam\n25%\n\n\n\n\n\n Data Stories 1\nAssignment information will be posted after the second class. Work will be done in and outside of class. \n\n\n Data Stories 2\nAssignment information will be posted after the second class. Work will be done in and outside of class.\n\n\n\n Data Stories 3\nAssignment information will be posted after the second class. Work will be done in and outside of class.\n\n\n\n Data Stories 4\nAssignment information will be posted after the second class. Work will be done in and outside of class.\n\n\n\nFinal Exam\nNot yet scheduled. Will be in the final exam block scheduled by the Registrars Office (RO).\n\nMultiple choice\nTrue / false\nShort answer questions\nSketch models and graphs\nInterpret models and graphs\nExplain code snippets at a high-level",
    "crumbs": [
      "Syllabus",
      "<strong>SYLLABUS</strong>",
      "&nbsp;&nbsp;Assessment"
    ]
  },
  {
    "objectID": "syllabus/conventions.html",
    "href": "syllabus/conventions.html",
    "title": " Conventions",
    "section": "",
    "text": "This page will develop as needed as the course progresses."
  },
  {
    "objectID": "syllabus/policies.html#department-and-faculty-policies",
    "href": "syllabus/policies.html#department-and-faculty-policies",
    "title": " Policies",
    "section": "Department and Faculty Policies",
    "text": "Department and Faculty Policies",
    "crumbs": [
      "Syllabus",
      "<strong>SYLLABUS</strong>",
      "&nbsp;&nbsp;Policies"
    ]
  },
  {
    "objectID": "syllabus/policies.html#university-policies",
    "href": "syllabus/policies.html#university-policies",
    "title": " Policies",
    "section": "University Policies",
    "text": "University Policies",
    "crumbs": [
      "Syllabus",
      "<strong>SYLLABUS</strong>",
      "&nbsp;&nbsp;Policies"
    ]
  },
  {
    "objectID": "deliverables/submissions/assignment-1/example-submission-1.html",
    "href": "deliverables/submissions/assignment-1/example-submission-1.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti."
  },
  {
    "objectID": "deliverables/submissions/assignment-1/example-submission-3.html",
    "href": "deliverables/submissions/assignment-1/example-submission-3.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti."
  },
  {
    "objectID": "deliverables/submissions/assignment-1/example-submission-5.html",
    "href": "deliverables/submissions/assignment-1/example-submission-5.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\nEtiam maximus accumsan gravida. Maecenas at nunc dignissim, euismod enim ac, bibendum ipsum. Maecenas vehicula velit in nisl aliquet ultricies. Nam eget massa interdum, maximus arcu vel, pretium erat. Maecenas sit amet tempor purus, vitae aliquet nunc. Vivamus cursus urna velit, eleifend dictum magna laoreet ut. Duis eu erat mollis, blandit magna id, tincidunt ipsum. Integer massa nibh, commodo eu ex vel, venenatis efficitur ligula. Integer convallis lacus elit, maximus eleifend lacus ornare ac. Vestibulum scelerisque viverra urna id lacinia. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget enim at diam bibendum tincidunt eu non purus. Nullam id magna ultrices, sodales metus viverra, tempus turpis.\nDuis ornare ex ac iaculis pretium. Maecenas sagittis odio id erat pharetra, sit amet consectetur quam sollicitudin. Vivamus pharetra quam purus, nec sagittis risus pretium at. Nullam feugiat, turpis ac accumsan interdum, sem tellus blandit neque, id vulputate diam quam semper nisl. Donec sit amet enim at neque porttitor aliquet. Phasellus facilisis nulla eget placerat eleifend. Vestibulum non egestas eros, eget lobortis ipsum. Nulla rutrum massa eget enim aliquam, id porttitor erat luctus. Nunc sagittis quis eros eu sagittis. Pellentesque dictum, erat at pellentesque sollicitudin, justo augue pulvinar metus, quis rutrum est mi nec felis. Vestibulum efficitur mi lorem, at elementum purus tincidunt a. Aliquam finibus enim magna, vitae pellentesque erat faucibus at. Nulla mauris tellus, imperdiet id lobortis et, dignissim condimentum ipsum. Morbi nulla orci, varius at aliquet sed, facilisis id tortor. Donec ut urna nisi."
  },
  {
    "objectID": "deliverables/submissions/assignment-2/example-submission-2.html",
    "href": "deliverables/submissions/assignment-2/example-submission-2.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nEtiam maximus accumsan gravida. Maecenas at nunc dignissim, euismod enim ac, bibendum ipsum. Maecenas vehicula velit in nisl aliquet ultricies. Nam eget massa interdum, maximus arcu vel, pretium erat. Maecenas sit amet tempor purus, vitae aliquet nunc. Vivamus cursus urna velit, eleifend dictum magna laoreet ut. Duis eu erat mollis, blandit magna id, tincidunt ipsum. Integer massa nibh, commodo eu ex vel, venenatis efficitur ligula. Integer convallis lacus elit, maximus eleifend lacus ornare ac. Vestibulum scelerisque viverra urna id lacinia. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget enim at diam bibendum tincidunt eu non purus. Nullam id magna ultrices, sodales metus viverra, tempus turpis.\nDuis ornare ex ac iaculis pretium. Maecenas sagittis odio id erat pharetra, sit amet consectetur quam sollicitudin. Vivamus pharetra quam purus, nec sagittis risus pretium at. Nullam feugiat, turpis ac accumsan interdum, sem tellus blandit neque, id vulputate diam quam semper nisl. Donec sit amet enim at neque porttitor aliquet. Phasellus facilisis nulla eget placerat eleifend. Vestibulum non egestas eros, eget lobortis ipsum. Nulla rutrum massa eget enim aliquam, id porttitor erat luctus. Nunc sagittis quis eros eu sagittis. Pellentesque dictum, erat at pellentesque sollicitudin, justo augue pulvinar metus, quis rutrum est mi nec felis. Vestibulum efficitur mi lorem, at elementum purus tincidunt a. Aliquam finibus enim magna, vitae pellentesque erat faucibus at. Nulla mauris tellus, imperdiet id lobortis et, dignissim condimentum ipsum. Morbi nulla orci, varius at aliquet sed, facilisis id tortor. Donec ut urna nisi."
  },
  {
    "objectID": "deliverables/submissions/assignment-2/example-submission-4.html",
    "href": "deliverables/submissions/assignment-2/example-submission-4.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\nEtiam quis tortor luctus, pellentesque ante a, finibus dolor. Phasellus in nibh et magna pulvinar malesuada. Ut nisl ex, sagittis at sollicitudin et, sollicitudin id nunc. In id porta urna. Proin porta dolor dolor, vel dapibus nisi lacinia in. Pellentesque ante mauris, ornare non euismod a, fermentum ut sapien. Proin sed vehicula enim. Aliquam tortor odio, vestibulum vitae odio in, tempor molestie justo. Praesent maximus lacus nec leo maximus blandit.\nMaecenas turpis velit, ultricies non elementum vel, luctus nec nunc. Nulla a diam interdum, faucibus sapien viverra, finibus metus. Donec non tortor diam. In ut elit aliquet, bibendum sem et, aliquam tortor. Donec congue, sem at rhoncus ultrices, nunc augue cursus erat, quis porttitor mauris libero ut ex. Nullam quis leo urna. Donec faucibus ligula eget pellentesque interdum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean rhoncus interdum erat ut ultricies. Aenean tempus ex non elit suscipit, quis dignissim enim efficitur. Proin laoreet enim massa, vitae laoreet nulla mollis quis."
  },
  {
    "objectID": "deliverables/submissions/assignment-3/example-submission-1.html",
    "href": "deliverables/submissions/assignment-3/example-submission-1.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nNullam dapibus cursus dolor sit amet consequat. Nulla facilisi. Curabitur vel nulla non magna lacinia tincidunt. Duis porttitor quam leo, et blandit velit efficitur ut. Etiam auctor tincidunt porttitor. Phasellus sed accumsan mi. Fusce ut erat dui. Suspendisse eu augue eget turpis condimentum finibus eu non lorem. Donec finibus eros eu ante condimentum, sed pharetra sapien sagittis. Phasellus non dolor ac ante mollis auctor nec et sapien. Pellentesque vulputate at nisi eu tincidunt. Vestibulum at dolor aliquam, hendrerit purus eu, eleifend massa. Morbi consectetur eros id tincidunt gravida. Fusce ut enim quis orci hendrerit lacinia sed vitae enim.\nNulla eget cursus ipsum. Vivamus porttitor leo diam, sed volutpat lectus facilisis sit amet. Maecenas et pulvinar metus. Ut at dignissim tellus. In in tincidunt elit. Etiam vulputate lobortis arcu, vel faucibus leo lobortis ac. Aliquam erat volutpat. In interdum orci ac est euismod euismod. Nunc eleifend tristique risus, at lacinia odio commodo in. Sed aliquet ligula odio, sed tempor neque ultricies sit amet."
  },
  {
    "objectID": "deliverables/submissions/assignment-3/example-submission-3.html",
    "href": "deliverables/submissions/assignment-3/example-submission-3.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nEtiam quis tortor luctus, pellentesque ante a, finibus dolor. Phasellus in nibh et magna pulvinar malesuada. Ut nisl ex, sagittis at sollicitudin et, sollicitudin id nunc. In id porta urna. Proin porta dolor dolor, vel dapibus nisi lacinia in. Pellentesque ante mauris, ornare non euismod a, fermentum ut sapien. Proin sed vehicula enim. Aliquam tortor odio, vestibulum vitae odio in, tempor molestie justo. Praesent maximus lacus nec leo maximus blandit.\nMaecenas turpis velit, ultricies non elementum vel, luctus nec nunc. Nulla a diam interdum, faucibus sapien viverra, finibus metus. Donec non tortor diam. In ut elit aliquet, bibendum sem et, aliquam tortor. Donec congue, sem at rhoncus ultrices, nunc augue cursus erat, quis porttitor mauris libero ut ex. Nullam quis leo urna. Donec faucibus ligula eget pellentesque interdum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean rhoncus interdum erat ut ultricies. Aenean tempus ex non elit suscipit, quis dignissim enim efficitur. Proin laoreet enim massa, vitae laoreet nulla mollis quis."
  },
  {
    "objectID": "deliverables/submissions/assignment-3/example-submission-5.html",
    "href": "deliverables/submissions/assignment-3/example-submission-5.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\nAenean placerat luctus tortor vitae molestie. Nulla at aliquet nulla. Sed efficitur tellus orci, sed fringilla lectus laoreet eget. Vivamus maximus quam sit amet arcu dignissim, sed accumsan massa ullamcorper. Sed iaculis tincidunt feugiat. Nulla in est at nunc ultricies dictum ut vitae nunc. Aenean convallis vel diam at malesuada. Suspendisse arcu libero, vehicula tempus ultrices a, placerat sit amet tortor. Sed dictum id nulla commodo mattis. Aliquam mollis, nunc eu tristique faucibus, purus lacus tincidunt nulla, ac pretium lorem nunc ut enim. Curabitur eget mattis nisl, vitae sodales augue. Nam felis massa, bibendum sit amet nulla vel, vulputate rutrum lacus. Aenean convallis odio pharetra nulla mattis consequat.\nUt ut condimentum augue, nec eleifend nisl. Sed facilisis egestas odio ac pretium. Pellentesque consequat magna sed venenatis sagittis. Vivamus feugiat lobortis magna vitae accumsan. Pellentesque euismod malesuada hendrerit. Ut non mauris non arcu condimentum sodales vitae vitae dolor. Nullam dapibus, velit eget lacinia rutrum, ipsum justo malesuada odio, et lobortis sapien magna vel lacus. Nulla purus neque, hendrerit non malesuada eget, mattis vel erat. Suspendisse potenti."
  },
  {
    "objectID": "deliverables/submissions/assignment-4/example-submission-2.html",
    "href": "deliverables/submissions/assignment-4/example-submission-2.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\n\nAenean placerat luctus tortor vitae molestie. Nulla at aliquet nulla. Sed efficitur tellus orci, sed fringilla lectus laoreet eget. Vivamus maximus quam sit amet arcu dignissim, sed accumsan massa ullamcorper. Sed iaculis tincidunt feugiat. Nulla in est at nunc ultricies dictum ut vitae nunc. Aenean convallis vel diam at malesuada. Suspendisse arcu libero, vehicula tempus ultrices a, placerat sit amet tortor. Sed dictum id nulla commodo mattis. Aliquam mollis, nunc eu tristique faucibus, purus lacus tincidunt nulla, ac pretium lorem nunc ut enim. Curabitur eget mattis nisl, vitae sodales augue. Nam felis massa, bibendum sit amet nulla vel, vulputate rutrum lacus. Aenean convallis odio pharetra nulla mattis consequat.\nUt ut condimentum augue, nec eleifend nisl. Sed facilisis egestas odio ac pretium. Pellentesque consequat magna sed venenatis sagittis. Vivamus feugiat lobortis magna vitae accumsan. Pellentesque euismod malesuada hendrerit. Ut non mauris non arcu condimentum sodales vitae vitae dolor. Nullam dapibus, velit eget lacinia rutrum, ipsum justo malesuada odio, et lobortis sapien magna vel lacus. Nulla purus neque, hendrerit non malesuada eget, mattis vel erat. Suspendisse potenti."
  },
  {
    "objectID": "deliverables/submissions/assignment-4/example-submission-4.html",
    "href": "deliverables/submissions/assignment-4/example-submission-4.html",
    "title": "This is an Example Submission",
    "section": "",
    "text": "Example Submission\nNulla eget cursus ipsum. Vivamus porttitor leo diam, sed volutpat lectus facilisis sit amet. Maecenas et pulvinar metus. Ut at dignissim tellus. In in tincidunt elit. Etiam vulputate lobortis arcu, vel faucibus leo lobortis ac. Aliquam erat volutpat. In interdum orci ac est euismod euismod. Nunc eleifend tristique risus, at lacinia odio commodo in. Sed aliquet ligula odio, sed tempor neque ultricies sit amet.\nEtiam quis tortor luctus, pellentesque ante a, finibus dolor. Phasellus in nibh et magna pulvinar malesuada. Ut nisl ex, sagittis at sollicitudin et, sollicitudin id nunc. In id porta urna. Proin porta dolor dolor, vel dapibus nisi lacinia in. Pellentesque ante mauris, ornare non euismod a, fermentum ut sapien. Proin sed vehicula enim. Aliquam tortor odio, vestibulum vitae odio in, tempor molestie justo. Praesent maximus lacus nec leo maximus blandit."
  },
  {
    "objectID": "lectures/lecture-05-notes.html",
    "href": "lectures/lecture-05-notes.html",
    "title": "Reproducible Workflows with R & RStudio",
    "section": "",
    "text": "Required:   Ch 3\nRecommended:   Ch 2\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-05-notes.html#reading-assignment",
    "href": "lectures/lecture-05-notes.html#reading-assignment",
    "title": "Reproducible Workflows with R & RStudio",
    "section": "",
    "text": "Required:   Ch 3\nRecommended:   Ch 2"
  },
  {
    "objectID": "lectures/lecture-05-notes.html#lecture-slides",
    "href": "lectures/lecture-05-notes.html#lecture-slides",
    "title": "Reproducible Workflows with R & RStudio",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#welcome-to-soci-3040",
    "href": "lectures/lecture-01-slides.html#welcome-to-soci-3040",
    "title": "Introduction + Telling Stories with Data",
    "section": "👋 Welcome to SOCI 3040!",
    "text": "👋 Welcome to SOCI 3040!\n\nMy name is [John, Professor McLevey, Dr. McLevey] (he/him).\nProfessor & Head of Sociology New to Memorial after 11 years at University of Waterloo"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#agenda.",
    "href": "lectures/lecture-01-slides.html#agenda.",
    "title": "Introduction + Telling Stories with Data",
    "section": "agenda.",
    "text": "agenda.\n\nWho are you? Background? Expectations?\nWhat is this course about?\nWhat will we do? Where is everything?"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#section",
    "href": "lectures/lecture-01-slides.html#section",
    "title": "Introduction + Telling Stories with Data",
    "section": "",
    "text": "Who are you? Do you have any previous quant courses / experience? What are your expectations for this course?"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#calendar-description",
    "href": "lectures/lecture-01-slides.html#calendar-description",
    "title": "Introduction + Telling Stories with Data",
    "section": "3040 Calendar Description",
    "text": "3040 Calendar Description\n\n\nSOCI 3040, Quantitative Research Methods, will familiarize students with the procedures for understanding and conducting quantitative social science research. It will introduce students to the quantitative research process, hypothesis development and testing, and the application of appropriate tools for analyzing quantitative data. All sections of this course count towards the HSS Quantitative Reasoning Requirement (see mun.ca/hss/qr). (PR: SOCI 1000 or the former SOCI 2000)"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#this-section-001",
    "href": "lectures/lecture-01-slides.html#this-section-001",
    "title": "Introduction + Telling Stories with Data",
    "section": "This Section (001)",
    "text": "This Section (001)\n\nThis section of SOCI 3440 is an introduction to quantitative research methods, from planning an analysis to sharing the final results. Following the workflow from Rohan Alexander’s (2023) Telling Stories with Data, you will learn how to:\n\nplan an analysis and sketch your data and endpoint simulate some data to “force you into the details” acquire, assess, and prepare empirical data for analysis explore and analyze data by creating visualizations and fitting models share the results of your work with the world!\n\n\n\n\n\nflowchart LR\n    p[[Plan]]\n    sim[[Simulate]]\n    a[[Acquire]]\n    e[[Explore / Analyze]]\n    s[[Share]]\n\n    p --&gt; sim --&gt; a --&gt; e --&gt; s"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#this-section-001-1",
    "href": "lectures/lecture-01-slides.html#this-section-001-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "This Section (001)",
    "text": "This Section (001)\n\n“A lack of clear communication sometimes reflects a failure by the researcher to understand what is going on, or even what they are doing.” (Alexander 2023)\n\n\nCore foundation of quantitative research methods Bridge between analysis and understanding Essential skill for modern researchers"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#this-section-001-2",
    "href": "lectures/lecture-01-slides.html#this-section-001-2",
    "title": "Introduction + Telling Stories with Data",
    "section": "This Section (001)",
    "text": "This Section (001)\n\n\n\n\n\n\n\n You will use this workflow in the context of learning foundational quantitative research skills, including conducting exploratory data analyses and fitting, assessing, and interpreting linear and generalized linear models. Reproducibility and research ethics are considered throughout the workflow, and the entire course."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#common-concerns-key-questions",
    "href": "lectures/lecture-01-slides.html#common-concerns-key-questions",
    "title": "Introduction + Telling Stories with Data",
    "section": "Common Concerns & Key Questions",
    "text": "Common Concerns & Key Questions\n\nWhat is the dataset? Who generated it and why?\nWhat is the underlying process? What’s missing or has been poorly measured? Could other datasets have been generated, and if so, how different could they have been to the one that we have?\nWhat is the dataset trying to say? What else could it say?\nWhat do we want others to see? How do we convince them?\nWho is affected? Are they represented in the data? Have they been involved in the analysis?"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#core-workflow-components",
    "href": "lectures/lecture-01-slides.html#core-workflow-components",
    "title": "Introduction + Telling Stories with Data",
    "section": "Core Workflow Components",
    "text": "Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\nPlan and Sketch\ndeliberate, reasoned decisions purposeful adjustments even 10 minutes of planning is valuable\n\nPlanning and sketching an endpoint is the first crucial step in the workflow because it ensures we have a clear objective and direction for our analysis. By thoughtfully considering where we want to go, we stay focused and efficient, preventing aimless wandering and scope creep. Without a defined goal, any path will suffice, but we typically cannot afford to wander aimlessly. While our endpoint may change, having an initial objective allows for deliberate and reasoned adjustments. This planning doesn’t require extensive time—often just ten minutes with paper and pen can provide significant value."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#core-workflow-components-1",
    "href": "lectures/lecture-01-slides.html#core-workflow-components-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "Core Workflow Components",
    "text": "Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\nSimulate Data\nForces detailed thinking Clarifies expected data structure and distributions. Helps with cleaning and preparation Identifies potential issues beforehand. Provides clear testing framework Ensures data meets expectations. “Almost free” with modern computing Provides “an intimate feeling for the situation” (Hamming [1997] 2020)\n\nSimulating data is the second step, forcing us into the details of our analysis by focusing on expected data structures and distributions. By creating simulated data, we define clear features that our real dataset should satisfy, aiding in data cleaning and preparation. For example, simulating an age-group variable with specific categories allows us to test the real data for consistency. Simulation is also vital for validating statistical models; by applying models to data with known properties, we can ensure they perform as intended before using them on real data. Since simulation is inexpensive and quick with modern computing resources, it provides “an intimate feeling for the situation” and helps build confidence in our analytical tools."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#core-workflow-components-2",
    "href": "lectures/lecture-01-slides.html#core-workflow-components-2",
    "title": "Introduction + Telling Stories with Data",
    "section": "Core Workflow Components",
    "text": "Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\nAcquire and Prepare\nOften overlooked but crucial stage Many difficult decisions required: data sources, formats, permissions. Can significantly affect statistical results (Huntington-Klein et al. 2021) Common challenges: quantity (too little or too much data) and quality\n\nAcquiring and preparing the actual data is often an overlooked yet challenging stage of the workflow that requires many critical decisions. This phase can significantly affect statistical results, as the choices made determine the quality and usability of the data. Researchers may feel overwhelmed—either by having too little data, raising concerns about the feasibility of analysis, or by having too much data, making it difficult to manage and process. Careful consideration, thorough cleaning, and preparation at this stage are crucial for the success of subsequent analysis, ensuring that the data are suitable for the questions being asked."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#core-workflow-components-3",
    "href": "lectures/lecture-01-slides.html#core-workflow-components-3",
    "title": "Introduction + Telling Stories with Data",
    "section": "Core Workflow Components",
    "text": "Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\nExplore and Understand\nBegin with descriptive statistics Move to statistical models\nRemember: Models are tools, not truth, and they reflect our previous decisions, data acquisition choices, and cleaning procedures.\n\nIn the fourth step, we explore and understand the actual data by examining relationships within the dataset. This process typically starts with descriptive statistics and progresses to statistical modeling. It’s important to remember that statistical models are tools—not absolute truths—and they operate based on the instructions we provide. They help us understand the data more clearly but do not offer definitive results. At this stage, the models we develop are heavily influenced by prior decisions made during data acquisition and preparation. Sophisticated modelers understand that models are like the visible tip of an iceberg, reliant on the substantial groundwork laid in earlier stages. They recognize that modeling results are shaped by choices about data inclusion, measurement, and recording, reflecting broader aspects of the world even before data reach the workflow."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#core-workflow-components-4",
    "href": "lectures/lecture-01-slides.html#core-workflow-components-4",
    "title": "Introduction + Telling Stories with Data",
    "section": "Core Workflow Components",
    "text": "Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\nShare Findings\nHigh-fidelity communication is essential Document all decisions Build credibility through transparency\n\nInclude:\nWhat was done Why it was done What was found Weaknesses of the approach\n\nThe final step is to share what was done and what was found, communicating with as much clarity and fidelity as possible. Effective communication involves detailing the decisions made throughout the workflow, the reasons behind them, the findings, and the limitations of the approach. We aim to uncover something important, so it’s essential to document everything initially, even if other forms of communication supplement the written record later. Openness about the entire process—from data acquisition to analysis—builds credibility and ensures others can fully engage with and understand the work. Without clear communication, even excellent work can be overlooked or misunderstood. While the world may not always reward merit alone, thorough and transparent communication enhances the impact of our work, and achieving mastery in this area requires significant experience and practice."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#quantitative-research-essentials-1",
    "href": "lectures/lecture-01-slides.html#quantitative-research-essentials-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "Quantitative Research Essentials",
    "text": "Quantitative Research Essentials\n\n\n\n Communication Reproducibility Ethics Questions Measurement Data Collection Data Cleaning Exploratory Data Analysis Modeling Scaling\n\n\n\n\n\n\nEssential foundation for the data storytelling workflow."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#communication-most-important",
    "href": "lectures/lecture-01-slides.html#communication-most-important",
    "title": "Introduction + Telling Stories with Data",
    "section": "Communication (Most Important)",
    "text": "Communication (Most Important)\n\n“Simple analysis, communicated well, is more valuable than complicated analysis communicated poorly.” (Alexander 2023)\n\n\n“One challenge is that as you immerse yourself in the data, it can be difficult to remember what it was like when you first came to it.” (Alexander 2023)\n\n\nWrite in plain language\nUse tables, graphs, and models effectively\nFocus on the audience’s perspective"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#reproducibility",
    "href": "lectures/lecture-01-slides.html#reproducibility",
    "title": "Introduction + Telling Stories with Data",
    "section": "Reproducibility",
    "text": "Reproducibility\nEverything must be independently repeatable.\n\nRequirements:\nOpen access to code Data availability or simulation Automated testing Clear documentation Aim for autonomous end-to-end reproducibility"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#ethics",
    "href": "lectures/lecture-01-slides.html#ethics",
    "title": "Introduction + Telling Stories with Data",
    "section": "Ethics",
    "text": "Ethics\n\n“This means considering things like: who is in the dataset, who is missing, and why? To what extent will our story perpetuate the past? And is this something that ought to happen?” (Alexander 2023)\n\nConsider the full context of the dataset (D’Ignazio and Klein 2020) Acknowledge the social, cultural, and political forces (Crawford 2021) Use data ethically with concern for impact and equity"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#questions",
    "href": "lectures/lecture-01-slides.html#questions",
    "title": "Introduction + Telling Stories with Data",
    "section": "Questions",
    "text": "Questions\nQuestions evolve through understanding Challenge of operationalizing variables Curiosity is essential, drives deeper exploration Value of “hybrid” knowledge that combines multiple disciplines Comfort with asking “dumb” questions\n\nCuriosity is a key source of internal motivation that drives us to thoroughly explore a dataset and its associated processes. As we delve deeper, each question we pose tends to generate additional questions, leading to continual improvement and refinement of our understanding. This iterative questioning contrasts with the traditional Popperian approach of fixed hypothesis testing often taught quantitative methods courses in the sciences; instead, questions evolve continuously throughout the exploration. Finding an initial research question can be challenging, especially when attempting to operationalize it into measurable and available variables.\nStrategies to overcome this include selecting an area of genuine interest, sketching broad claims that can be honed into specific questions, and combining insights from different fields. Developing comfort with the inherent messiness of real-world data allows us to ask new questions as the data evolve. Knowing a dataset in detail often reveals unexpected patterns or anomalies, which we can explore further with subject-matter experts. Becoming a “hybrid”—cultivating knowledge across various disciplines—and being comfortable with asking seemingly simple or “dumb” questions are particularly valuable in enhancing our understanding and fostering meaningful insights."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#measurement",
    "href": "lectures/lecture-01-slides.html#measurement",
    "title": "Introduction + Telling Stories with Data",
    "section": "Measurement",
    "text": "Measurement\n\n“The world is so vibrant that it is difficult to reduce it to something that is possible to consistently measure and collect.” (Alexander 2023)\n\n\n\nMeasuring even simple things is challenging (e.g., measuring height: Shoes on or off? Time of day affects height. Different tools yield different results). More complex measurements are even harder. How do we measure happiness or pain?\n Measurement requires decisions and is not value-free. Context and purpose guide all measurement choices.\n\n\n\n\nPicasso’s dog and the challenges of reduction.\n\n\n\n\nMeasurement and data collection involve the complex task of deciding how to translate the vibrant, multifaceted world into quantifiable data. This process is challenging because even seemingly simple measurements, like a person’s height, can vary based on factors like the time of day or the tools used (e.g., tape measure versus laser), making consistent comparison difficult and often unfeasible. The difficulty intensifies with more abstract concepts such as sadness or pain, where defining and measuring them consistently is even more problematic. This reduction of the world into data is not value-free; it requires critical decisions about what to measure, how to measure it, and what to ignore, all influenced by context and purpose. Like Picasso’s minimalist drawings that capture the essence of a dog but lack details necessary for specific assessments (e.g., determining if the dog is sick), we must deeply understand and respect what we’re measuring, carefully deciding which features are essential and which can be stripped away to serve our research objectives."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#data-collection-cleaning",
    "href": "lectures/lecture-01-slides.html#data-collection-cleaning",
    "title": "Introduction + Telling Stories with Data",
    "section": "Data Collection & Cleaning",
    "text": "Data Collection & Cleaning\n\n“Data never speak for themselves; they are the puppets of the ventriloquists that cleaned and prepared them.” (Alexander 2023)\n\nCollection determines possibilities What and how we measure matters.\nCleaning requires many decisions E.g., Handling “prefer not to say” and open-text responses.\nDocument every step To ensure transparency and reproducibility.\nConsider implications of choices E.g., ethics, representation.\n\nData cleaning and preparation is a critical and complex part of data analysis that requires careful attention and numerous decisions. Decisions such as whether to exclude “prefer not to say” responses (which would ignore certain participants) or how to categorize open-text entries (where merging them with other categories might disrespect respondents’ specific choices) have significant implications. There is no universally correct approach; choices depend on the context and purpose of the analysis. Therefore, it’s vital to meticulously record every step of the data cleaning process to ensure transparency and allow others to understand the decisions made. Ultimately, data do not speak for themselves; they reflect the interpretations and choices of those who prepare and analyze them."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#exploratory-data-analysis-eda",
    "href": "lectures/lecture-01-slides.html#exploratory-data-analysis-eda",
    "title": "Introduction + Telling Stories with Data",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\nIterative process Never truly complete Shapes understanding\n\nExploratory Data Analysis (EDA) is an open-ended, iterative process that involves immersing ourselves in the data to understand its shape and structure before formal modeling begins. It includes producing summary statistics, creating graphs and tables, and sometimes even preliminary modeling. EDA requires a variety of skills and never truly finishes, as there’s always more to explore. Although it’s challenging to delineate where EDA ends and formal statistical modeling begins—since our beliefs and understanding evolve continuously—EDA is foundational in shaping the story we tell about our data. While not typically included explicitly in the final narrative, it’s crucial that all steps taken during EDA are recorded and shared."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#modeling",
    "href": "lectures/lecture-01-slides.html#modeling",
    "title": "Introduction + Telling Stories with Data",
    "section": "Modeling",
    "text": "Modeling\nTool for understanding Not a recipe to follow Just one representation of reality Statistical significance \\(\\neq\\) scientific significance Statistical models help us explore the shape of the data; are like echolocation\n\nStatistical modeling builds upon the insights gained from EDA and has a rich history spanning hundreds of years. Statistics is not merely a collection of dry theorems and proofs; it’s a way of exploring and understanding the world. A statistical model is not a rigid recipe to follow mechanically but a tool for making sense of data. Modeling is usually required to infer statistical patterns, formally known as statistical inference—the process of using data to infer the distribution that generated them. Importantly, statistical significance does not equate to scientific significance, and relying on arbitrary pass/fail tests is rarely appropriate. Instead, we should use statistical modeling as a form of echolocation, listening to what the models tell us about the shape of the world while recognizing that they offer just one representation of reality."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#scaling",
    "href": "lectures/lecture-01-slides.html#scaling",
    "title": "Introduction + Telling Stories with Data",
    "section": "Scaling",
    "text": "Scaling\nUsing programming languages like R and Python\nHandle large datasets efficiently Automate repetitive tasks Share work widely and quickly Outputs can reach many people easily APIs can make analyses accessible in real-time\n\nScaling our work becomes feasible with the use of programming languages like R and Python, which allow us to handle vast amounts of data efficiently. Scaling refers to both inputs and outputs; it’s essentially as easy to analyze ten observations as it is to analyze a million. This capability enables us to quickly determine the extent to which our findings apply. Additionally, our outputs can be disseminated to a wide audience effortlessly—whether it’s one person or a hundred. By utilizing Application Programming Interfaces (APIs), our analyses and stories can be accessed thousands of times per second, greatly enhancing their impact and accessibility."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#how-do-our-worlds-become-data-1",
    "href": "lectures/lecture-01-slides.html#how-do-our-worlds-become-data-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "How Do Our Worlds Become Data?",
    "text": "How Do Our Worlds Become Data?\n\nTo a certain extent we are wasting our time. We have a perfect model of the world—it is the world! But it is too complicated. If we knew perfectly how everything was affected by the uncountable factors that influence it, then we could forecast perfectly a coin toss, a dice roll, and every other seemingly random process each time. But we cannot. Instead, we must simplify things to that which is plausibly measurable, and it is that which we define as data. Our data are a simplification of the messy, complex world from which they were derived.  There are different approximations of “plausibly measurable”. Hence, datasets are always the result of choices. We must decide whether they are nonetheless reasonable for the task at hand. We use statistical models to help us think deeply about, explore, and hopefully come to better understand, our data. (Alexander 2023)"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#how-do-our-worlds-become-data-2",
    "href": "lectures/lecture-01-slides.html#how-do-our-worlds-become-data-2",
    "title": "Introduction + Telling Stories with Data",
    "section": "How Do Our Worlds Become Data?",
    "text": "How Do Our Worlds Become Data?\n Through skillfulreduction 👨‍🍳\n\nJust as a chef reduces a rich sauce to concentrate its essential flavors, we simplify reality into data—plausibly measurable approximations that capture the essence of the complex world. This reduction process involves deliberate choices about what aspects of reality to include, much like deciding which ingredients to emphasize in a culinary reduction. Our datasets, therefore, are distilled versions of reality, highlighting specific components while inevitably leaving out others.\nAs we employ statistical models to explore and understand these datasets, it’s crucial to recognize both what the data include and what they omit. Similar to how a reduction in cooking intensifies certain flavors while others may be lost or muted, the process of data simplification can inadvertently exclude important nuances or perspectives. Particularly in data science, where human-generated data are prevalent, we must consider who or what is systematically missing from our datasets. Some individuals or phenomena may not fit neatly into our chosen methods and might be oversimplified or excluded entirely. The abstraction and simplification inherent in turning the world into data require careful judgment—much like a chef monitoring a reduction to achieve the desired consistency without overcooking—to determine when simplification is appropriate and when it risks losing critical information.\nMeasurement itself presents significant challenges, and those deeply involved in the data collection process often have less trust in the data than those removed from it. Just as the process of reducing a sauce demands constant attention to prevent burning or altering the intended flavor, converting the world into data involves numerous decisions and potential errors—from selecting what to measure to deciding on the methods and accuracy required. Advances in instruments—from telescopes in astronomy to real-time internet data collection—have expanded our ability to gather data, much like new culinary techniques enhance a chef’s ability to create complex dishes. However, the world still imperfectly becomes data, and to truly learn from it, we must actively seek to understand the imperfections in our datasets and consider how our “reduction” process may have altered or omitted important aspects of reality."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#embracing-the-challenge-1",
    "href": "lectures/lecture-01-slides.html#embracing-the-challenge-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "Embracing the Challenge",
    "text": "Embracing the Challenge\n\n“Ultimately, we are all just telling stories with data, but these stories are increasingly among the most important in the world.” (Alexander 2023)\n\nTelling good stories with data is difficult but rewarding.\nDevelop resilience and intrinsic motivation. Accept that failure is part of the process. Consider possibilities and probabilities. Learn to make trade-offs. No perfect analysis exists. Aim for transparency and continuous improvement."
  },
  {
    "objectID": "lectures/lecture-01-slides.html#key-takeaways",
    "href": "lectures/lecture-01-slides.html#key-takeaways",
    "title": "Introduction + Telling Stories with Data",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nData storytelling bridges analysis and understanding\nEffective communication is paramount\nEthics and reproducibility are foundational\nAsk meaningful questions and measure thoughtfully and transparently\nData collection and cleaning shape your analysis\nEmbrace the iterative nature of exploration and modeling\nLeverage technology to scale and share your work\nBe mindful of the limitations of your data"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#section-1",
    "href": "lectures/lecture-01-slides.html#section-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "",
    "text": "Brightspace Course materials website: johnmclevey.com/SOCI3040/"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#next-class",
    "href": "lectures/lecture-01-slides.html#next-class",
    "title": "Introduction + Telling Stories with Data",
    "section": "Next class",
    "text": "Next class\n\nBefore class: Complete the assigned reading In class: Introduction to R and RStudio"
  },
  {
    "objectID": "lectures/lecture-01-slides.html#references",
    "href": "lectures/lecture-01-slides.html#references",
    "title": "Introduction + Telling Stories with Data",
    "section": "References",
    "text": "References\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nCrawford, Kate. 2021. Atlas of AI. 1st ed. New Haven: Yale University Press.\n\n\nD’Ignazio, Catherine, and Lauren Klein. 2020. Data Feminism. Massachusetts: The MIT Press. https://data-feminism.mitpress.mit.edu.\n\n\nHamming, Richard. (1997) 2020. The Art of Doing Science and Engineering. 2nd ed. Stripe Press.\n\n\nHuntington-Klein, Nick, Andreu Arenas, Emily Beam, Marco Bertoni, Jeffrey Bloem, Pralhad Burli, Naibin Chen, et al. 2021. “The Influence of Hidden Researcher Decisions in Applied Microeconomics.” Economic Inquiry 59: 944–60. https://doi.org/10.1111/ecin.12992."
  },
  {
    "objectID": "lectures/lecture-07-notes.html",
    "href": "lectures/lecture-07-notes.html",
    "title": "Writing and Developing Research Questions",
    "section": "",
    "text": "Required:   Ch 4\nRecommended:   Ch 3"
  },
  {
    "objectID": "lectures/lecture-07-notes.html#reading-assignment",
    "href": "lectures/lecture-07-notes.html#reading-assignment",
    "title": "Writing and Developing Research Questions",
    "section": "",
    "text": "Required:   Ch 4\nRecommended:   Ch 3"
  },
  {
    "objectID": "lectures/lecture-10-notes.html",
    "href": "lectures/lecture-10-notes.html",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "",
    "text": "Required:   Ch 5\nRecommended:   Ch 4\nReview Class"
  },
  {
    "objectID": "lectures/lecture-10-notes.html#reading-assignment",
    "href": "lectures/lecture-10-notes.html#reading-assignment",
    "title": "Creating Graphs, Tables, & Maps",
    "section": "",
    "text": "Required:   Ch 5\nRecommended:   Ch 4"
  },
  {
    "objectID": "lectures/lecture-12-notes.html",
    "href": "lectures/lecture-12-notes.html",
    "title": "Measurement, Censuses, and Sampling",
    "section": "",
    "text": "Required:   Ch 6\nRecommended:   Ch 5\nJohn sick, class cancelled."
  },
  {
    "objectID": "lectures/lecture-12-notes.html#reading-assignment",
    "href": "lectures/lecture-12-notes.html#reading-assignment",
    "title": "Measurement, Censuses, and Sampling",
    "section": "",
    "text": "Required:   Ch 6\nRecommended:   Ch 5"
  },
  {
    "objectID": "lectures/lecture-14-notes.html",
    "href": "lectures/lecture-14-notes.html",
    "title": "APIs, Scraping, and Parsing",
    "section": "",
    "text": "Required:   Ch 7\nRecommended:   Ch 7\nIn class activities focused on introducing basic knowledge of the web as a foundation for understanding APIs and scraping-based approaches to data collection. Used OpenAlex and The Guardian as example for APIs."
  },
  {
    "objectID": "lectures/lecture-14-notes.html#reading-assignment",
    "href": "lectures/lecture-14-notes.html#reading-assignment",
    "title": "APIs, Scraping, and Parsing",
    "section": "",
    "text": "Required:   Ch 7\nRecommended:   Ch 7"
  },
  {
    "objectID": "lectures/lecture-01-notes.html",
    "href": "lectures/lecture-01-notes.html",
    "title": "Introduction + Telling Stories with Data",
    "section": "",
    "text": "Required: Browse this site\nRecommended: \n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#reading-assignment",
    "href": "lectures/lecture-01-notes.html#reading-assignment",
    "title": "Introduction + Telling Stories with Data",
    "section": "",
    "text": "Required: Browse this site\nRecommended:"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#lecture-slides",
    "href": "lectures/lecture-01-notes.html#lecture-slides",
    "title": "Introduction + Telling Stories with Data",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#welcome-to-soci-3040",
    "href": "lectures/lecture-01-notes.html#welcome-to-soci-3040",
    "title": "Introduction + Telling Stories with Data",
    "section": "0.1 👋 Welcome to SOCI 3040!",
    "text": "0.1 👋 Welcome to SOCI 3040!\n\nMy name is [John, Professor McLevey, Dr. McLevey] (he/him).\nProfessor & Head of Sociology New to Memorial after 11 years at University of Waterloo"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#agenda.",
    "href": "lectures/lecture-01-notes.html#agenda.",
    "title": "Introduction + Telling Stories with Data",
    "section": "0.2 agenda.",
    "text": "0.2 agenda.\n\nWho are you? Background? Expectations?\nWhat is this course about?\nWhat will we do? Where is everything?"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#section",
    "href": "lectures/lecture-01-notes.html#section",
    "title": "Introduction + Telling Stories with Data",
    "section": "1.1 ",
    "text": "1.1 \n\nWho are you? Do you have any previous quant courses / experience? What are your expectations for this course?"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#calendar-description",
    "href": "lectures/lecture-01-notes.html#calendar-description",
    "title": "Introduction + Telling Stories with Data",
    "section": "2.1 3040 Calendar Description",
    "text": "2.1 3040 Calendar Description\n\n\nSOCI 3040, Quantitative Research Methods, will familiarize students with the procedures for understanding and conducting quantitative social science research. It will introduce students to the quantitative research process, hypothesis development and testing, and the application of appropriate tools for analyzing quantitative data. All sections of this course count towards the HSS Quantitative Reasoning Requirement (see mun.ca/hss/qr). (PR: SOCI 1000 or the former SOCI 2000)"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#this-section-001",
    "href": "lectures/lecture-01-notes.html#this-section-001",
    "title": "Introduction + Telling Stories with Data",
    "section": "2.2 This Section (001)",
    "text": "2.2 This Section (001)\n\nThis section of SOCI 3440 is an introduction to quantitative research methods, from planning an analysis to sharing the final results. Following the workflow from Rohan Alexander’s (2023) Telling Stories with Data, you will learn how to:\n\nplan an analysis and sketch your data and endpoint simulate some data to “force you into the details” acquire, assess, and prepare empirical data for analysis explore and analyze data by creating visualizations and fitting models share the results of your work with the world!\n\n\n\n\n\nflowchart LR\n    p[[Plan]]\n    sim[[Simulate]]\n    a[[Acquire]]\n    e[[Explore / Analyze]]\n    s[[Share]]\n\n    p --&gt; sim --&gt; a --&gt; e --&gt; s"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#this-section-001-1",
    "href": "lectures/lecture-01-notes.html#this-section-001-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "2.3 This Section (001)",
    "text": "2.3 This Section (001)\n\n“A lack of clear communication sometimes reflects a failure by the researcher to understand what is going on, or even what they are doing.” (Alexander 2023)\n\n\nCore foundation of quantitative research methods Bridge between analysis and understanding Essential skill for modern researchers"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#this-section-001-2",
    "href": "lectures/lecture-01-notes.html#this-section-001-2",
    "title": "Introduction + Telling Stories with Data",
    "section": "2.4 This Section (001)",
    "text": "2.4 This Section (001)\n\n\n\n\n\n\n\n You will use this workflow in the context of learning foundational quantitative research skills, including conducting exploratory data analyses and fitting, assessing, and interpreting linear and generalized linear models. Reproducibility and research ethics are considered throughout the workflow, and the entire course."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#common-concerns-key-questions",
    "href": "lectures/lecture-01-notes.html#common-concerns-key-questions",
    "title": "Introduction + Telling Stories with Data",
    "section": "2.5 Common Concerns & Key Questions",
    "text": "2.5 Common Concerns & Key Questions\n\nWhat is the dataset? Who generated it and why?\nWhat is the underlying process? What’s missing or has been poorly measured? Could other datasets have been generated, and if so, how different could they have been to the one that we have?\nWhat is the dataset trying to say? What else could it say?\nWhat do we want others to see? How do we convince them?\nWho is affected? Are they represented in the data? Have they been involved in the analysis?"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#core-workflow-components",
    "href": "lectures/lecture-01-notes.html#core-workflow-components",
    "title": "Introduction + Telling Stories with Data",
    "section": "3.1 Core Workflow Components",
    "text": "3.1 Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\n\n3.1.1 Plan and Sketch\ndeliberate, reasoned decisions purposeful adjustments even 10 minutes of planning is valuable\n\nPlanning and sketching an endpoint is the first crucial step in the workflow because it ensures we have a clear objective and direction for our analysis. By thoughtfully considering where we want to go, we stay focused and efficient, preventing aimless wandering and scope creep. Without a defined goal, any path will suffice, but we typically cannot afford to wander aimlessly. While our endpoint may change, having an initial objective allows for deliberate and reasoned adjustments. This planning doesn’t require extensive time—often just ten minutes with paper and pen can provide significant value."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#core-workflow-components-1",
    "href": "lectures/lecture-01-notes.html#core-workflow-components-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "3.2 Core Workflow Components",
    "text": "3.2 Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\n\n3.2.1 Simulate Data\nForces detailed thinking Clarifies expected data structure and distributions. Helps with cleaning and preparation Identifies potential issues beforehand. Provides clear testing framework Ensures data meets expectations. “Almost free” with modern computing Provides “an intimate feeling for the situation” (Hamming [1997] 2020)\n\nSimulating data is the second step, forcing us into the details of our analysis by focusing on expected data structures and distributions. By creating simulated data, we define clear features that our real dataset should satisfy, aiding in data cleaning and preparation. For example, simulating an age-group variable with specific categories allows us to test the real data for consistency. Simulation is also vital for validating statistical models; by applying models to data with known properties, we can ensure they perform as intended before using them on real data. Since simulation is inexpensive and quick with modern computing resources, it provides “an intimate feeling for the situation” and helps build confidence in our analytical tools."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#core-workflow-components-2",
    "href": "lectures/lecture-01-notes.html#core-workflow-components-2",
    "title": "Introduction + Telling Stories with Data",
    "section": "3.3 Core Workflow Components",
    "text": "3.3 Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\n\n3.3.1 Acquire and Prepare\nOften overlooked but crucial stage Many difficult decisions required: data sources, formats, permissions. Can significantly affect statistical results (Huntington-Klein et al. 2021) Common challenges: quantity (too little or too much data) and quality\n\nAcquiring and preparing the actual data is often an overlooked yet challenging stage of the workflow that requires many critical decisions. This phase can significantly affect statistical results, as the choices made determine the quality and usability of the data. Researchers may feel overwhelmed—either by having too little data, raising concerns about the feasibility of analysis, or by having too much data, making it difficult to manage and process. Careful consideration, thorough cleaning, and preparation at this stage are crucial for the success of subsequent analysis, ensuring that the data are suitable for the questions being asked."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#core-workflow-components-3",
    "href": "lectures/lecture-01-notes.html#core-workflow-components-3",
    "title": "Introduction + Telling Stories with Data",
    "section": "3.4 Core Workflow Components",
    "text": "3.4 Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\n\n3.4.1 Explore and Understand\nBegin with descriptive statistics Move to statistical models\nRemember: Models are tools, not truth, and they reflect our previous decisions, data acquisition choices, and cleaning procedures.\n\nIn the fourth step, we explore and understand the actual data by examining relationships within the dataset. This process typically starts with descriptive statistics and progresses to statistical modeling. It’s important to remember that statistical models are tools—not absolute truths—and they operate based on the instructions we provide. They help us understand the data more clearly but do not offer definitive results. At this stage, the models we develop are heavily influenced by prior decisions made during data acquisition and preparation. Sophisticated modelers understand that models are like the visible tip of an iceberg, reliant on the substantial groundwork laid in earlier stages. They recognize that modeling results are shaped by choices about data inclusion, measurement, and recording, reflecting broader aspects of the world even before data reach the workflow."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#core-workflow-components-4",
    "href": "lectures/lecture-01-notes.html#core-workflow-components-4",
    "title": "Introduction + Telling Stories with Data",
    "section": "3.5 Core Workflow Components",
    "text": "3.5 Core Workflow Components\nPlan, Simulate, Acquire, Explore / Analyze, Share\n\n\n3.5.1 Share Findings\nHigh-fidelity communication is essential Document all decisions Build credibility through transparency\n\nInclude:\nWhat was done Why it was done What was found Weaknesses of the approach\n\nThe final step is to share what was done and what was found, communicating with as much clarity and fidelity as possible. Effective communication involves detailing the decisions made throughout the workflow, the reasons behind them, the findings, and the limitations of the approach. We aim to uncover something important, so it’s essential to document everything initially, even if other forms of communication supplement the written record later. Openness about the entire process—from data acquisition to analysis—builds credibility and ensures others can fully engage with and understand the work. Without clear communication, even excellent work can be overlooked or misunderstood. While the world may not always reward merit alone, thorough and transparent communication enhances the impact of our work, and achieving mastery in this area requires significant experience and practice."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#quantitative-research-essentials-1",
    "href": "lectures/lecture-01-notes.html#quantitative-research-essentials-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "4.1 Quantitative Research Essentials",
    "text": "4.1 Quantitative Research Essentials\n\n\n\n Communication Reproducibility Ethics Questions Measurement Data Collection Data Cleaning Exploratory Data Analysis Modeling Scaling\n\n\n\n\n\n\nEssential foundation for the data storytelling workflow."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#communication-most-important",
    "href": "lectures/lecture-01-notes.html#communication-most-important",
    "title": "Introduction + Telling Stories with Data",
    "section": "4.2 Communication (Most Important)",
    "text": "4.2 Communication (Most Important)\n\n“Simple analysis, communicated well, is more valuable than complicated analysis communicated poorly.” (Alexander 2023)\n\n\n“One challenge is that as you immerse yourself in the data, it can be difficult to remember what it was like when you first came to it.” (Alexander 2023)\n\n\nWrite in plain language\nUse tables, graphs, and models effectively\nFocus on the audience’s perspective"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#reproducibility",
    "href": "lectures/lecture-01-notes.html#reproducibility",
    "title": "Introduction + Telling Stories with Data",
    "section": "4.3 Reproducibility",
    "text": "4.3 Reproducibility\nEverything must be independently repeatable.\n\nRequirements:\nOpen access to code Data availability or simulation Automated testing Clear documentation Aim for autonomous end-to-end reproducibility"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#ethics",
    "href": "lectures/lecture-01-notes.html#ethics",
    "title": "Introduction + Telling Stories with Data",
    "section": "4.4 Ethics",
    "text": "4.4 Ethics\n\n“This means considering things like: who is in the dataset, who is missing, and why? To what extent will our story perpetuate the past? And is this something that ought to happen?” (Alexander 2023)\n\nConsider the full context of the dataset (D’Ignazio and Klein 2020) Acknowledge the social, cultural, and political forces (Crawford 2021) Use data ethically with concern for impact and equity"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#questions",
    "href": "lectures/lecture-01-notes.html#questions",
    "title": "Introduction + Telling Stories with Data",
    "section": "4.5 Questions",
    "text": "4.5 Questions\nQuestions evolve through understanding Challenge of operationalizing variables Curiosity is essential, drives deeper exploration Value of “hybrid” knowledge that combines multiple disciplines Comfort with asking “dumb” questions\n\nCuriosity is a key source of internal motivation that drives us to thoroughly explore a dataset and its associated processes. As we delve deeper, each question we pose tends to generate additional questions, leading to continual improvement and refinement of our understanding. This iterative questioning contrasts with the traditional Popperian approach of fixed hypothesis testing often taught quantitative methods courses in the sciences; instead, questions evolve continuously throughout the exploration. Finding an initial research question can be challenging, especially when attempting to operationalize it into measurable and available variables.\nStrategies to overcome this include selecting an area of genuine interest, sketching broad claims that can be honed into specific questions, and combining insights from different fields. Developing comfort with the inherent messiness of real-world data allows us to ask new questions as the data evolve. Knowing a dataset in detail often reveals unexpected patterns or anomalies, which we can explore further with subject-matter experts. Becoming a “hybrid”—cultivating knowledge across various disciplines—and being comfortable with asking seemingly simple or “dumb” questions are particularly valuable in enhancing our understanding and fostering meaningful insights."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#measurement",
    "href": "lectures/lecture-01-notes.html#measurement",
    "title": "Introduction + Telling Stories with Data",
    "section": "4.6 Measurement",
    "text": "4.6 Measurement\n\n“The world is so vibrant that it is difficult to reduce it to something that is possible to consistently measure and collect.” (Alexander 2023)\n\n\n\nMeasuring even simple things is challenging (e.g., measuring height: Shoes on or off? Time of day affects height. Different tools yield different results). More complex measurements are even harder. How do we measure happiness or pain?\n Measurement requires decisions and is not value-free. Context and purpose guide all measurement choices.\n\n\n\n\nPicasso’s dog and the challenges of reduction.\n\n\n\n\n\nMeasurement and data collection involve the complex task of deciding how to translate the vibrant, multifaceted world into quantifiable data. This process is challenging because even seemingly simple measurements, like a person’s height, can vary based on factors like the time of day or the tools used (e.g., tape measure versus laser), making consistent comparison difficult and often unfeasible. The difficulty intensifies with more abstract concepts such as sadness or pain, where defining and measuring them consistently is even more problematic. This reduction of the world into data is not value-free; it requires critical decisions about what to measure, how to measure it, and what to ignore, all influenced by context and purpose. Like Picasso’s minimalist drawings that capture the essence of a dog but lack details necessary for specific assessments (e.g., determining if the dog is sick), we must deeply understand and respect what we’re measuring, carefully deciding which features are essential and which can be stripped away to serve our research objectives."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#data-collection-cleaning",
    "href": "lectures/lecture-01-notes.html#data-collection-cleaning",
    "title": "Introduction + Telling Stories with Data",
    "section": "4.7 Data Collection & Cleaning",
    "text": "4.7 Data Collection & Cleaning\n\n“Data never speak for themselves; they are the puppets of the ventriloquists that cleaned and prepared them.” (Alexander 2023)\n\nCollection determines possibilities What and how we measure matters.\nCleaning requires many decisions E.g., Handling “prefer not to say” and open-text responses.\nDocument every step To ensure transparency and reproducibility.\nConsider implications of choices E.g., ethics, representation.\n\nData cleaning and preparation is a critical and complex part of data analysis that requires careful attention and numerous decisions. Decisions such as whether to exclude “prefer not to say” responses (which would ignore certain participants) or how to categorize open-text entries (where merging them with other categories might disrespect respondents’ specific choices) have significant implications. There is no universally correct approach; choices depend on the context and purpose of the analysis. Therefore, it’s vital to meticulously record every step of the data cleaning process to ensure transparency and allow others to understand the decisions made. Ultimately, data do not speak for themselves; they reflect the interpretations and choices of those who prepare and analyze them."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#exploratory-data-analysis-eda",
    "href": "lectures/lecture-01-notes.html#exploratory-data-analysis-eda",
    "title": "Introduction + Telling Stories with Data",
    "section": "5.1 Exploratory Data Analysis (EDA)",
    "text": "5.1 Exploratory Data Analysis (EDA)\nIterative process Never truly complete Shapes understanding\n\nExploratory Data Analysis (EDA) is an open-ended, iterative process that involves immersing ourselves in the data to understand its shape and structure before formal modeling begins. It includes producing summary statistics, creating graphs and tables, and sometimes even preliminary modeling. EDA requires a variety of skills and never truly finishes, as there’s always more to explore. Although it’s challenging to delineate where EDA ends and formal statistical modeling begins—since our beliefs and understanding evolve continuously—EDA is foundational in shaping the story we tell about our data. While not typically included explicitly in the final narrative, it’s crucial that all steps taken during EDA are recorded and shared."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#modeling",
    "href": "lectures/lecture-01-notes.html#modeling",
    "title": "Introduction + Telling Stories with Data",
    "section": "5.2 Modeling",
    "text": "5.2 Modeling\nTool for understanding Not a recipe to follow Just one representation of reality Statistical significance \\(\\neq\\) scientific significance Statistical models help us explore the shape of the data; are like echolocation\n\nStatistical modeling builds upon the insights gained from EDA and has a rich history spanning hundreds of years. Statistics is not merely a collection of dry theorems and proofs; it’s a way of exploring and understanding the world. A statistical model is not a rigid recipe to follow mechanically but a tool for making sense of data. Modeling is usually required to infer statistical patterns, formally known as statistical inference—the process of using data to infer the distribution that generated them. Importantly, statistical significance does not equate to scientific significance, and relying on arbitrary pass/fail tests is rarely appropriate. Instead, we should use statistical modeling as a form of echolocation, listening to what the models tell us about the shape of the world while recognizing that they offer just one representation of reality."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#scaling",
    "href": "lectures/lecture-01-notes.html#scaling",
    "title": "Introduction + Telling Stories with Data",
    "section": "5.3 Scaling",
    "text": "5.3 Scaling\nUsing programming languages like R and Python\nHandle large datasets efficiently Automate repetitive tasks Share work widely and quickly Outputs can reach many people easily APIs can make analyses accessible in real-time\n\nScaling our work becomes feasible with the use of programming languages like R and Python, which allow us to handle vast amounts of data efficiently. Scaling refers to both inputs and outputs; it’s essentially as easy to analyze ten observations as it is to analyze a million. This capability enables us to quickly determine the extent to which our findings apply. Additionally, our outputs can be disseminated to a wide audience effortlessly—whether it’s one person or a hundred. By utilizing Application Programming Interfaces (APIs), our analyses and stories can be accessed thousands of times per second, greatly enhancing their impact and accessibility."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#how-do-our-worlds-become-data-1",
    "href": "lectures/lecture-01-notes.html#how-do-our-worlds-become-data-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "6.1 How Do Our Worlds Become Data?",
    "text": "6.1 How Do Our Worlds Become Data?\n\nTo a certain extent we are wasting our time. We have a perfect model of the world—it is the world! But it is too complicated. If we knew perfectly how everything was affected by the uncountable factors that influence it, then we could forecast perfectly a coin toss, a dice roll, and every other seemingly random process each time. But we cannot. Instead, we must simplify things to that which is plausibly measurable, and it is that which we define as data. Our data are a simplification of the messy, complex world from which they were derived.  There are different approximations of “plausibly measurable”. Hence, datasets are always the result of choices. We must decide whether they are nonetheless reasonable for the task at hand. We use statistical models to help us think deeply about, explore, and hopefully come to better understand, our data. (Alexander 2023)"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#how-do-our-worlds-become-data-2",
    "href": "lectures/lecture-01-notes.html#how-do-our-worlds-become-data-2",
    "title": "Introduction + Telling Stories with Data",
    "section": "6.2 How Do Our Worlds Become Data?",
    "text": "6.2 How Do Our Worlds Become Data?\n Through skillfulreduction 👨‍🍳\n\nJust as a chef reduces a rich sauce to concentrate its essential flavors, we simplify reality into data—plausibly measurable approximations that capture the essence of the complex world. This reduction process involves deliberate choices about what aspects of reality to include, much like deciding which ingredients to emphasize in a culinary reduction. Our datasets, therefore, are distilled versions of reality, highlighting specific components while inevitably leaving out others.\nAs we employ statistical models to explore and understand these datasets, it’s crucial to recognize both what the data include and what they omit. Similar to how a reduction in cooking intensifies certain flavors while others may be lost or muted, the process of data simplification can inadvertently exclude important nuances or perspectives. Particularly in data science, where human-generated data are prevalent, we must consider who or what is systematically missing from our datasets. Some individuals or phenomena may not fit neatly into our chosen methods and might be oversimplified or excluded entirely. The abstraction and simplification inherent in turning the world into data require careful judgment—much like a chef monitoring a reduction to achieve the desired consistency without overcooking—to determine when simplification is appropriate and when it risks losing critical information.\nMeasurement itself presents significant challenges, and those deeply involved in the data collection process often have less trust in the data than those removed from it. Just as the process of reducing a sauce demands constant attention to prevent burning or altering the intended flavor, converting the world into data involves numerous decisions and potential errors—from selecting what to measure to deciding on the methods and accuracy required. Advances in instruments—from telescopes in astronomy to real-time internet data collection—have expanded our ability to gather data, much like new culinary techniques enhance a chef’s ability to create complex dishes. However, the world still imperfectly becomes data, and to truly learn from it, we must actively seek to understand the imperfections in our datasets and consider how our “reduction” process may have altered or omitted important aspects of reality."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#embracing-the-challenge-1",
    "href": "lectures/lecture-01-notes.html#embracing-the-challenge-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "7.1 Embracing the Challenge",
    "text": "7.1 Embracing the Challenge\n\n“Ultimately, we are all just telling stories with data, but these stories are increasingly among the most important in the world.” (Alexander 2023)\n\nTelling good stories with data is difficult but rewarding.\nDevelop resilience and intrinsic motivation. Accept that failure is part of the process. Consider possibilities and probabilities. Learn to make trade-offs. No perfect analysis exists. Aim for transparency and continuous improvement."
  },
  {
    "objectID": "lectures/lecture-01-notes.html#key-takeaways",
    "href": "lectures/lecture-01-notes.html#key-takeaways",
    "title": "Introduction + Telling Stories with Data",
    "section": "7.2 Key Takeaways",
    "text": "7.2 Key Takeaways\n\nData storytelling bridges analysis and understanding\nEffective communication is paramount\nEthics and reproducibility are foundational\nAsk meaningful questions and measure thoughtfully and transparently\nData collection and cleaning shape your analysis\nEmbrace the iterative nature of exploration and modeling\nLeverage technology to scale and share your work\nBe mindful of the limitations of your data"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#section-1",
    "href": "lectures/lecture-01-notes.html#section-1",
    "title": "Introduction + Telling Stories with Data",
    "section": "8.1 ",
    "text": "8.1 \n\nBrightspace Course materials website: johnmclevey.com/SOCI3040/"
  },
  {
    "objectID": "lectures/lecture-01-notes.html#next-class",
    "href": "lectures/lecture-01-notes.html#next-class",
    "title": "Introduction + Telling Stories with Data",
    "section": "8.2 Next class",
    "text": "8.2 Next class\n\nBefore class: Complete the assigned reading In class: Introduction to R and RStudio"
  },
  {
    "objectID": "lectures/lecture-06-notes.html",
    "href": "lectures/lecture-06-notes.html",
    "title": "Reproducible Workflows with R & RStudio",
    "section": "",
    "text": "Required:   Ch 3\nRecommended:   Ch 2\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-06-notes.html#reading-assignment",
    "href": "lectures/lecture-06-notes.html#reading-assignment",
    "title": "Reproducible Workflows with R & RStudio",
    "section": "",
    "text": "Required:   Ch 3\nRecommended:   Ch 2"
  },
  {
    "objectID": "lectures/lecture-06-notes.html#lecture-slides",
    "href": "lectures/lecture-06-notes.html#lecture-slides",
    "title": "Reproducible Workflows with R & RStudio",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-16-notes.html",
    "href": "lectures/lecture-16-notes.html",
    "title": "Experiments and Surveys",
    "section": "",
    "text": "Required:   Ch 8\nRecommended:   Ch 8\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-16-notes.html#reading-assignment",
    "href": "lectures/lecture-16-notes.html#reading-assignment",
    "title": "Experiments and Surveys",
    "section": "",
    "text": "Required:   Ch 8\nRecommended:   Ch 8"
  },
  {
    "objectID": "lectures/lecture-16-notes.html#lecture-slides",
    "href": "lectures/lecture-16-notes.html#lecture-slides",
    "title": "Experiments and Surveys",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-18-notes.html",
    "href": "lectures/lecture-18-notes.html",
    "title": "Cleaning, Preparing, and Testing",
    "section": "",
    "text": "Required:   Ch 9\nRecommended:   Statistical Golems\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-18-notes.html#reading-assignment",
    "href": "lectures/lecture-18-notes.html#reading-assignment",
    "title": "Cleaning, Preparing, and Testing",
    "section": "",
    "text": "Required:   Ch 9\nRecommended:   Statistical Golems"
  },
  {
    "objectID": "lectures/lecture-18-notes.html#lecture-slides",
    "href": "lectures/lecture-18-notes.html#lecture-slides",
    "title": "Cleaning, Preparing, and Testing",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-20-notes.html",
    "href": "lectures/lecture-20-notes.html",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Required:   Ch 11\nRecommended:   The Garden of Forking Data\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-20-notes.html#reading-assignment",
    "href": "lectures/lecture-20-notes.html#reading-assignment",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Required:   Ch 11\nRecommended:   The Garden of Forking Data"
  },
  {
    "objectID": "lectures/lecture-20-notes.html#lecture-slides",
    "href": "lectures/lecture-20-notes.html#lecture-slides",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-22-notes.html",
    "href": "lectures/lecture-22-notes.html",
    "title": "Linear Models",
    "section": "",
    "text": "Required:   Ch 12\nRecommended:   Geocentric Models\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-22-notes.html#reading-assignment",
    "href": "lectures/lecture-22-notes.html#reading-assignment",
    "title": "Linear Models",
    "section": "",
    "text": "Required:   Ch 12\nRecommended:   Geocentric Models"
  },
  {
    "objectID": "lectures/lecture-22-notes.html#lecture-slides",
    "href": "lectures/lecture-22-notes.html#lecture-slides",
    "title": "Linear Models",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-24-notes.html",
    "href": "lectures/lecture-24-notes.html",
    "title": "Generalized Linear Models (GLMs)",
    "section": "",
    "text": "Required:   Ch 13\nRecommended:   Ch 6\n\n\n\n\n    View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-24-notes.html#reading-assignment",
    "href": "lectures/lecture-24-notes.html#reading-assignment",
    "title": "Generalized Linear Models (GLMs)",
    "section": "",
    "text": "Required:   Ch 13\nRecommended:   Ch 6"
  },
  {
    "objectID": "lectures/lecture-24-notes.html#lecture-slides",
    "href": "lectures/lecture-24-notes.html#lecture-slides",
    "title": "Generalized Linear Models (GLMs)",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#the-firehose",
    "href": "lectures/lecture-03-slides.html#the-firehose",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.1 the firehose",
    "text": "1.1 the firehose\n\n\n\n\n\nflowchart LR\n  p[[Plan]]\n  sim[[Simulate]]\n  a[[Acquire]]\n  e[[Explore/Understand]]\n  s[[Share]]\n\n  p --&gt; sim --&gt; a --&gt; e --&gt; s\n\n\n Rohan Alexander’s (2023) Telling Stories with Data workflow \n\n\n\n\n\nAustralian elections\nToronto shelters\nNeonatal mortality rates (NMR)"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#the-firehose-1",
    "href": "lectures/lecture-03-slides.html#the-firehose-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.2 the firehose",
    "text": "1.2 the firehose\n\nWhenever you’re learning a new tool, for a long time, you’re going to suck\\(\\dots\\) But the good news is that is typical; that’s something that happens to everyone, and it’s only temporary.\nHadley Wickham as quoted by Barrett (2021)\n\n\n\nYou will be guided thoroughly here. Hopefully by experiencing the excitement of telling stories with data, you will feel empowered to stick with it.\nRohan Alexander (2023)"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#import-libraries",
    "href": "lectures/lecture-03-slides.html#import-libraries",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.3 import libraries",
    "text": "1.3 import libraries\n\n\nlibrary(\"janitor\")\nlibrary(\"knitr\")\nlibrary(\"lubridate\")\nlibrary(\"opendatatoronto\")\nlibrary(\"tidyverse\")\nlibrary(\"here\")"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#plan-1",
    "href": "lectures/lecture-03-slides.html#plan-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "2.1 plan",
    "text": "2.1 plan\n\n2.1.1 Australian Elections\n\n\n\nHow many seats did each political party win in the 2022 Australian Federal Election?\n\n\n\n Australia is a parliamentary democracywith 151 seats in the House of Representatives. \nMajor parties: Liberal and Labour Minor parties: Nationals and Greens Many smaller parties and independents"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#plan-2",
    "href": "lectures/lecture-03-slides.html#plan-2",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "2.2 plan",
    "text": "2.2 plan\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch of a possible dataset to create a graph\n\n\n\n\n\n\n\n\n\n\n\n(b) Sketch of a possible graph to answer our question\n\n\n\n\n\n\n\nFigure 1: Sketches of a potential dataset and graph related to an Australian election. The basic requirement for the dataset is that it has the name of the seat (i.e., a “division” in Australia) and the party of the person elected."
  },
  {
    "objectID": "lectures/lecture-03-slides.html#simulate-1",
    "href": "lectures/lecture-03-slides.html#simulate-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "3.1 simulate",
    "text": "3.1 simulate\n\n\nlibrary(tidyverse)\nlibrary(janitor)"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#simulate-2",
    "href": "lectures/lecture-03-slides.html#simulate-2",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "3.2 simulate",
    "text": "3.2 simulate\n\nWe’ll simulate a dataset with two variables,Division and Party, and some values for each.\n\ndivisionthe name of one of the 131 Australian divisions  partythe name of one of the political partiesLiberal, Labor, National, Green, or Other"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#simulate-3",
    "href": "lectures/lecture-03-slides.html#simulate-3",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "3.3 simulate",
    "text": "3.3 simulate\n\n\nsimulated_data &lt;-\n    tibble(\n        # Use 1 through to 151 to represent each division\n        \"Division\" = 1:151,\n        # Randomly pick an option, with replacement, 151 times\n        \"Party\" = sample(\n            x = c(\"Liberal\", \"Labor\", \"National\", \"Green\", \"Other\"),\n            size = 151,\n            replace = TRUE\n        )\n    )\n\n\nThe &lt;- symbol is an assignment operator in R. It assigns the value on the right to the variable name on the left. Here, we’re creating a new data object called simulated_data, which will store a table of simulated information.\ntibble() is a function from the tidyverse package that creates a data frame, which is a type of table used to organize data. Unlike traditional data frames, tibble handles data more cleanly and is especially useful in data analysis.\nInside the tibble() function, we specify columns and the values we want in each. On Line 4, we create a column named “Division”. 1:151 generates a sequence of numbers from 1 to 151. This sequence will represent each unique division (or group) in our simulated dataset and helps to identify each row in the data.\nThen we create another column in our tibble called Party. sample() is a function that randomly selects values from a specified set. Here, it’s used to pick a political party for each division, simulating party representation across divisions.\nx defines the set of values that sample() will pick from. The c() function combines these five options — “Liberal”, “Labor”, “National”, “Green”, and “Other” — into a list of possible parties. In other words, each division will be randomly assigned one of these five party names, representing the political party that wins the division in our simulation. size = 151 specifies that sample() should generate 151 random selections, matching the number of divisions we created in the “Division” column.\nWhen sampling, replace = TRUE allows each party name to be selected multiple times, as though we’re picking “with replacement” (i.e., once we sample a party name, it goes back into the bag so it can be drawn again). Without this, each party could only be chosen once, which wouldn’t match our goal of assigning a random party to each division.\nWe can print the simulated_data object to view the simulated dataset. When we run this line, R will display the table with two columns, Division and Party, where each division is assigned one of the five parties randomly."
  },
  {
    "objectID": "lectures/lecture-03-slides.html#simulate-4",
    "href": "lectures/lecture-03-slides.html#simulate-4",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "3.4 simulate",
    "text": "3.4 simulate\n🤘 We have our fake data!\n\nsimulated_data\n\n# A tibble: 151 × 2\n   Division Party  \n      &lt;int&gt; &lt;chr&gt;  \n 1        1 Labor  \n 2        2 Liberal\n 3        3 Green  \n 4        4 Green  \n 5        5 Liberal\n 6        6 Green  \n 7        7 Liberal\n 8        8 Green  \n 9        9 Other  \n10       10 Other  \n# ℹ 141 more rows"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-1",
    "href": "lectures/lecture-03-slides.html#acquire-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.1 acquire",
    "text": "4.1 acquire\n\nThe data we want is provided by the Australian Electoral Commission (AEC), which is the non-partisan agency that organizes Australian federal elections. We can download the data using this link, but we want to do it programatically, storing the results to a dataframe object called raw_elections_data.\n\n\ndata_url &lt;- \"https://results.aec.gov.au/27966/website/Downloads/HouseMembersElectedDownload-27966.csv\"\n\nraw_elections_data &lt;-\n    read_csv(\n        file = data_url,\n        show_col_types = FALSE,\n        skip = 1\n    )"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-2",
    "href": "lectures/lecture-03-slides.html#acquire-2",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.2 acquire",
    "text": "4.2 acquire\n\nWe’ll save the data as a CSV file.\n\nlibrary(here)\n\nwrite_csv(\n    x = raw_elections_data,\n    file = here(\"data\", \"australian_voting.csv\")\n)\n\n\n\n\n\n✌️ R Tip\nThe here() function, from the here library, simplifies file paths by always referencing the root directory for a project. This makes code more reproducible and eliminates issues with working directories, especially when you are using more than one machine, collaborating, or sharing code with someone else. Jenny Bryan wrote a brief “Ode to the here package,” “here here,” which you can read… here."
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-3",
    "href": "lectures/lecture-03-slides.html#acquire-3",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.3 acquire",
    "text": "4.3 acquire\n🤘 We have our real data!\n\n\nraw_elections_data\n\n# A tibble: 151 × 8\n   DivisionID DivisionNm StateAb CandidateID GivenNm Surname\n        &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1        179 Adelaide   SA            36973 Steve   GEORGA…\n 2        197 Aston      VIC           36704 Alan    TUDGE  \n 3        198 Ballarat   VIC           36409 Cather… KING   \n 4        103 Banks      NSW           37018 David   COLEMAN\n 5        180 Barker     SA            37083 Tony    PASIN  \n 6        104 Barton     NSW           36820 Linda   BURNEY \n 7        192 Bass       TAS           37134 Bridge… ARCHER \n 8        318 Bean       ACT           36231 David   SMITH  \n 9        200 Bendigo    VIC           36424 Lisa    CHESTE…\n10        105 Bennelong  NSW           36827 Jerome  LAXALE \n# ℹ 141 more rows\n# ℹ 2 more variables: PartyNm &lt;chr&gt;, PartyAb &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-4",
    "href": "lectures/lecture-03-slides.html#acquire-4",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.4 acquire",
    "text": "4.4 acquire\nhead() shows the first six rows.\n\n\nhead(raw_elections_data)\n\n# A tibble: 6 × 8\n  DivisionID DivisionNm StateAb CandidateID GivenNm  Surname\n       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  \n1        179 Adelaide   SA            36973 Steve    GEORGA…\n2        197 Aston      VIC           36704 Alan     TUDGE  \n3        198 Ballarat   VIC           36409 Catheri… KING   \n4        103 Banks      NSW           37018 David    COLEMAN\n5        180 Barker     SA            37083 Tony     PASIN  \n6        104 Barton     NSW           36820 Linda    BURNEY \n# ℹ 2 more variables: PartyNm &lt;chr&gt;, PartyAb &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-5",
    "href": "lectures/lecture-03-slides.html#acquire-5",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.5 acquire",
    "text": "4.5 acquire\ntail() shows the last six rows.\n\n\ntail(raw_elections_data)\n\n# A tibble: 6 × 8\n  DivisionID DivisionNm StateAb CandidateID GivenNm  Surname\n       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  \n1        152 Wentworth  NSW           37451 Allegra  SPENDER\n2        153 Werriwa    NSW           36810 Anne Ma… STANLEY\n3        150 Whitlam    NSW           36811 Stephen  JONES  \n4        178 Wide Bay   QLD           37506 Llew     O'BRIEN\n5        234 Wills      VIC           36452 Peter    KHALIL \n6        316 Wright     QLD           37500 Scott    BUCHHO…\n# ℹ 2 more variables: PartyNm &lt;chr&gt;, PartyAb &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-6",
    "href": "lectures/lecture-03-slides.html#acquire-6",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.6 acquire",
    "text": "4.6 acquire\n\n“We are trying to make it similar to the dataset that we thought we wanted in the planning stage. While it is fine to move away from the plan, this needs to be a deliberate, reasoned decision.” (Alexander 2023)\n\n\nLet’s clean.\n\naus_voting_data &lt;- here(\"data\", \"australian_voting.csv\")\n\nraw_elections_data &lt;-\n    read_csv(\n        file = aus_voting_data,\n        show_col_types = FALSE\n    )"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-7",
    "href": "lectures/lecture-03-slides.html#acquire-7",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.7 acquire",
    "text": "4.7 acquire\n\nclean_names() makes variables easier to type.\n\ncleaned_elections_data &lt;- clean_names(raw_elections_data)\n\n Let’s look at the first 6 rows.\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 8\n  division_id division_nm state_ab candidate_id given_nm \n        &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;    \n1         179 Adelaide    SA              36973 Steve    \n2         197 Aston       VIC             36704 Alan     \n3         198 Ballarat    VIC             36409 Catherine\n4         103 Banks       NSW             37018 David    \n5         180 Barker      SA              37083 Tony     \n6         104 Barton      NSW             36820 Linda    \n# ℹ 3 more variables: surname &lt;chr&gt;, party_nm &lt;chr&gt;,\n#   party_ab &lt;chr&gt;"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-8",
    "href": "lectures/lecture-03-slides.html#acquire-8",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.8 acquire",
    "text": "4.8 acquire\n\n\n\n✌️ R Tip\nWe can choose certain variables of interest with select() from dplyr, which we loaded as part of the tidyverse. The pipe operator |&gt; pushes the output of one line to be the first input of the function on the next line.\n\n\n\n\nWe are primarily interested in two variables:\ndivision_nm (division name)party_nm (party name)\n\n\ncleaned_elections_data &lt;-\n    cleaned_elections_data |&gt;\n    select(\n        division_nm,\n        party_nm\n    )"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-9",
    "href": "lectures/lecture-03-slides.html#acquire-9",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.9 acquire",
    "text": "4.9 acquire\n\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division_nm party_nm              \n  &lt;chr&gt;       &lt;chr&gt;                 \n1 Adelaide    Australian Labor Party\n2 Aston       Liberal               \n3 Ballarat    Australian Labor Party\n4 Banks       Liberal               \n5 Barker      Liberal               \n6 Barton      Australian Labor Party\n\n\n\nThis looks good, but some of the variable names are still not obvious because they are abbreviated."
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-10",
    "href": "lectures/lecture-03-slides.html#acquire-10",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.10 acquire",
    "text": "4.10 acquire\n\n\n\n\n✌️ R Tip\nWe can look at the names of the columns (i.e., variables) in a dataset using names(). We can change them using rename() from dplyr.\n\n\n\n\nnames(cleaned_elections_data)\n\n[1] \"division_nm\" \"party_nm\"   \n\n\n\nLet’s rename."
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-11",
    "href": "lectures/lecture-03-slides.html#acquire-11",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.11 acquire",
    "text": "4.11 acquire\n\n\ncleaned_elections_data &lt;-\n    cleaned_elections_data |&gt;\n    rename(\n        division = division_nm,\n        elected_party = party_nm\n    )\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division elected_party         \n  &lt;chr&gt;    &lt;chr&gt;                 \n1 Adelaide Australian Labor Party\n2 Aston    Liberal               \n3 Ballarat Australian Labor Party\n4 Banks    Liberal               \n5 Barker   Liberal               \n6 Barton   Australian Labor Party"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-12",
    "href": "lectures/lecture-03-slides.html#acquire-12",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.12 acquire",
    "text": "4.12 acquire\n\nWhat are the unique values in elected_party?\n\ncleaned_elections_data$elected_party |&gt;\n    unique()\n\n[1] \"Australian Labor Party\"              \n[2] \"Liberal\"                             \n[3] \"Liberal National Party of Queensland\"\n[4] \"The Greens\"                          \n[5] \"The Nationals\"                       \n[6] \"Independent\"                         \n[7] \"Katter's Australian Party (KAP)\"     \n[8] \"Centre Alliance\"                     \n\n\n\nCool, but let’s simplify the party names in elected_party to match what we simulated. We can do this with case_match() from dplyr."
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-13",
    "href": "lectures/lecture-03-slides.html#acquire-13",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.13 acquire",
    "text": "4.13 acquire\n\n\ncleaned_elections_data &lt;-\n    cleaned_elections_data |&gt;\n    mutate(\n        elected_party =\n            case_match(\n                elected_party,\n                \"Australian Labor Party\" ~ \"Labor\",\n                \"Liberal National Party of Queensland\" ~ \"Liberal\",\n                \"Liberal\" ~ \"Liberal\",\n                \"The Nationals\" ~ \"Nationals\",\n                \"The Greens\" ~ \"Greens\",\n                \"Independent\" ~ \"Other\",\n                \"Katter's Australian Party (KAP)\" ~ \"Other\",\n                \"Centre Alliance\" ~ \"Other\"\n            )\n    )"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#acquire-14",
    "href": "lectures/lecture-03-slides.html#acquire-14",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.14 acquire",
    "text": "4.14 acquire\n\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division elected_party\n  &lt;chr&gt;    &lt;chr&gt;        \n1 Adelaide Labor        \n2 Aston    Liberal      \n3 Ballarat Labor        \n4 Banks    Liberal      \n5 Barker   Liberal      \n6 Barton   Labor        \n\n\n\nOur data now matches our plan! 😎"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#aus_elections_clean_path",
    "href": "lectures/lecture-03-slides.html#aus_elections_clean_path",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "4.15 acquire",
    "text": "4.15 acquire\n\nLet’s save the cleaned data so that we can start with it data in the next stage. We’ll use a new filename to preserve the original and make it easy to identify the clean version.\n\naus_elections_clean_path &lt;- here(\"data\", \"cleaned_elections_data.csv\")\n\nwrite_csv(\n    x = cleaned_elections_data,\n    file = aus_elections_clean_path\n)"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#explore-understand-1",
    "href": "lectures/lecture-03-slides.html#explore-understand-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.1 explore / understand",
    "text": "5.1 explore / understand\n\n\n\n How do we build the graph that we planned?"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#explore-understand-2",
    "href": "lectures/lecture-03-slides.html#explore-understand-2",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.2 explore / understand",
    "text": "5.2 explore / understand\n\nFirst, we read in the cleaned dataset that we just created.\n\ncleaned_elections_data &lt;-\n    read_csv(\n        file = aus_elections_clean_path,\n        show_col_types = FALSE\n    )\n\n\n\n\n\n✌️ R Tip\n\n\nI’m using the filepath object I previously created: aus_elections_clean_path.\n\naus_elections_clean_path\n\n[1] \"/Users/johnmclevey/SOCI3040/data/cleaned_elections_data.csv\"\n\n\n This won’t work in a new script unless we re-create the object. Can you explain why?"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#explore-understand-3",
    "href": "lectures/lecture-03-slides.html#explore-understand-3",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.3 explore / understand",
    "text": "5.3 explore / understand\n\n\nhead(cleaned_elections_data)\n\n# A tibble: 6 × 2\n  division elected_party\n  &lt;chr&gt;    &lt;chr&gt;        \n1 Adelaide Labor        \n2 Aston    Liberal      \n3 Ballarat Labor        \n4 Banks    Liberal      \n5 Barker   Liberal      \n6 Barton   Labor        \n\n\n😎"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#explore-understand-4",
    "href": "lectures/lecture-03-slides.html#explore-understand-4",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.4 explore / understand",
    "text": "5.4 explore / understand\n\n\n\nHow many seats did each party win?\n\n\n\n\nWe can get a quick count with count() from dplyr.\n\ncleaned_elections_data |&gt;\n    count(elected_party)\n\n# A tibble: 5 × 2\n  elected_party     n\n  &lt;chr&gt;         &lt;int&gt;\n1 Greens            4\n2 Labor            77\n3 Liberal          48\n4 Nationals        10\n5 Other            12"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#explore-understand-5",
    "href": "lectures/lecture-03-slides.html#explore-understand-5",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.5 explore / understand",
    "text": "5.5 explore / understand\n\n\n\n\n\n\nRemember, we’re trying to make something like this.\n\n\n\n\n\n\n✌️ R Tip\n\n\nThe grammar of graphics is a conceptual framework for constructing data visualizations. It breaks down plots to their most basic elements, like data, scales, geoms (geometric objects), coordinates, and statistical transformations. The idea is to plan and build our vizualizations by layering these basic elements together rather than mindlessly relying on generic chart types.\nggplot2, a data visualization library from the tidyverse, is designed around the grammar of graphics idea. We build data visualizations by layering the desired elements of our plots. For example, we use aes() to specify aesthetic mappings that link our data to visual elements like position, color, size, shape, and transparency. We can create and tweak just about any visualization we want by layering data, aesthetics, and geoms using the add operator, +.\n\n\n\n\n\n, allowing the viewer to interpret the values and relationships in the dataset visually. By mapping data to these properties, we can layer information on the same plot and enhance the viewer’s understanding of patterns, trends, and differences.\nIn ggplot2, aesthetics are specified within the aes() function, where each aesthetic is mapped to a data variable. For instance, x and y represent positions on the axes, while color, fill, size, and shape control other visual aspects. By carefully selecting aesthetics, we can add depth to the plot without clutter, guiding the viewer’s eye to the most important parts."
  },
  {
    "objectID": "lectures/lecture-03-slides.html#explore-understand-6",
    "href": "lectures/lecture-03-slides.html#explore-understand-6",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.6 explore / understand",
    "text": "5.6 explore / understand\n\nLet’s visualize the counts as vertical bars using geom_bar() from ggplot2.\n\nggplot(\n    cleaned_elections_data, # specify the data\n    aes(x = elected_party) # specify aesthetics\n) + # add a layer with the + operator\n    geom_bar() # specify a geometric shape (bar)\n\n\nBut it’s cleaner to use the pipe operator |&gt;.\n\ncleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar()"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#explore-understand-6-output",
    "href": "lectures/lecture-03-slides.html#explore-understand-6-output",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.6 explore / understand",
    "text": "5.6 explore / understand\n\n\n\n\n\n\n\nFigure 2: Meh. We can do better."
  },
  {
    "objectID": "lectures/lecture-03-slides.html#explore-understand-7",
    "href": "lectures/lecture-03-slides.html#explore-understand-7",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.7 explore / understand",
    "text": "5.7 explore / understand\n\n\ncleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar() +\n    theme_minimal() + # Improve the theme\n    labs(x = \"Party\", y = \"Number of seats\") # Improve the labels"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#explore-understand-7-output",
    "href": "lectures/lecture-03-slides.html#explore-understand-7-output",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.7 explore / understand",
    "text": "5.7 explore / understand\n\n\n\n\n\n\n\nFigure 3: Number of seats won, by political party, at the 2022 Australian Federal Election. 😎"
  },
  {
    "objectID": "lectures/lecture-03-slides.html#section",
    "href": "lectures/lecture-03-slides.html#section",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "5.8 ",
    "text": "5.8 \ncleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar()\n\ncleaned_elections_data |&gt;\n    ggplot(aes(x = elected_party)) +\n    geom_bar() +\n    theme_minimal() +\n    labs(x = \"Party\", y = \"Number of seats\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Default theme and labels\n\n\n\n\n\n\n\n\n\n\n\n(b) Improved theme and labels\n\n\n\n\n\n\n\nFigure 4: Both versions of the plot, and the code that produced them, side-by-side for comparison."
  },
  {
    "objectID": "lectures/lecture-03-slides.html#share-1",
    "href": "lectures/lecture-03-slides.html#share-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "6.1 share",
    "text": "6.1 share\nExample taken directly from Alexander (2023), here.\n\n\n\nAustralia is a parliamentary democracy with 151 seats in the House of Representatives, which is the house from which government is formed. There are two major parties—“Liberal” and “Labor”—two minor parties—“Nationals” and “Greens”—and many smaller parties. The 2022 Federal Election occurred on 21 May, and around 15 million votes were cast. We were interested in the number of seats that were won by each party.\nWe downloaded the results, on a seat-specific basis, from the Australian Electoral Commission website. We cleaned and tidied the dataset using the statistical programming language R (R Core Team 2023) including the tidyverse (Wickham et al. 2019) and janitor (Firke 2023). We then created a graph of the number of seats that each political party won (Figure 3).\nWe found that the Labor Party won 77 seats, followed by the Liberal Party with 48 seats. The minor parties won the following number of seats: the Nationals won 10 seats and the Greens won 4 seats. Finally, there were 10 Independents elected as well as candidates from smaller parties.\nThe distribution of seats is skewed toward the two major parties which could reflect relatively stable preferences on the part of Australian voters, or possibly inertia due to the benefits of already being a major party such a national network or funding. A better understanding of the reasons for this distribution are of interest in future work. While the dataset consists of everyone who voted, it worth noting that in Australia some are systematically excluded from voting, and it is much more difficult for some to vote than others.\n\n\n\n\nOne aspect to be especially concerned with is making sure that this communication is focused on the needs of the audience and telling a story. Data journalism provides some excellent examples of how analysis needs to be tailored to the audience, for instance, Cardoso (2020) and Bronner (2020)."
  },
  {
    "objectID": "lectures/lecture-03-slides.html#references",
    "href": "lectures/lecture-03-slides.html#references",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "6.2 References",
    "text": "6.2 References\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nBarrett, Malcolm. 2021. Data Science as an Atomic Habit. https://malco.io/articles/2021-01-04-data-science-as-an-atomic-habit.\n\n\nBronner, Laura. 2020. “Why Statistics Don’t Capture the Full Extent of the Systemic Bias in Policing.” FiveThirtyEight, June. https://fivethirtyeight.com/features/why-statistics-dont-capture-the-full-extent-of-the-systemic-bias-in-policing/.\n\n\nCardoso, Tom. 2020. “Bias behind bars: A Globe investigation finds a prison system stacked against Black and Indigenous inmates.” The Globe and Mail, October. https://www.theglobeandmail.com/canada/article-investigation-racial-bias-in-canadian-prison-risk-assessments/.\n\n\nFirke, Sam. 2023. janitor: Simple Tools for Examining and Cleaning Dirty Data. https://CRAN.R-project.org/package=janitor.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nWickham, Hadley, Mara Averick, Jenny Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the Tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686."
  },
  {
    "objectID": "lectures/lecture-04-notes.html",
    "href": "lectures/lecture-04-notes.html",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "",
    "text": "Required:   Ch 2\nRecommended:   Ch 1\n\n\n\n\nIn class work in RStudio! See notes below."
  },
  {
    "objectID": "lectures/lecture-04-notes.html#reading-assignment",
    "href": "lectures/lecture-04-notes.html#reading-assignment",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "",
    "text": "Required:   Ch 2\nRecommended:   Ch 1"
  },
  {
    "objectID": "lectures/lecture-04-notes.html#lecture-slides",
    "href": "lectures/lecture-04-notes.html#lecture-slides",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "",
    "text": "In class work in RStudio! See notes below."
  },
  {
    "objectID": "lectures/lecture-04-notes.html#import-libraries",
    "href": "lectures/lecture-04-notes.html#import-libraries",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.1 Import Libraries",
    "text": "1.1 Import Libraries\nYou might see a lot of text print to the console when you import these libraries. You can ignore that for now!\n\nlibrary(\"janitor\") # For cleaning and formatting column names and data.\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(\"knitr\") # For creating tables and reports.\nlibrary(\"lubridate\") # For working with dates and times.\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(\"opendatatoronto\") # For accessing Toronto's open data directly.\nlibrary(\"tidyverse\") # A collection of R packages for data manipulation, visualization, and more.\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr   1.1.4     ✔ readr   2.1.5\n✔ forcats 1.0.0     ✔ stringr 1.5.1\n✔ ggplot2 3.5.1     ✔ tibble  3.2.1\n✔ purrr   1.0.2     ✔ tidyr   1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(\"here\") # For managing file paths in a project-oriented workflow.\n\nhere() starts at /Users/johnmclevey/SOCI3040\n\n\nThe libraries listed here are essential for managing the workflow. Each library serves a specific purpose:\n\njanitor: Simplifies data cleaning tasks, such as renaming columns or identifying missing values.\nknitr: Provides functionality to integrate R code into reports and create professional tables.\nlubridate: Makes working with dates easier, such as extracting months or years from a date column.\nopendatatoronto: Offers tools to download and work with datasets provided by the City of Toronto.\ntidyverse: A suite of tools for data science, including dplyr for data manipulation and ggplot2 for visualization.\nhere: Ensures consistent file paths regardless of the working directory."
  },
  {
    "objectID": "lectures/lecture-04-notes.html#plan",
    "href": "lectures/lecture-04-notes.html#plan",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.2 Plan",
    "text": "1.2 Plan\nThe dataset we are interested in needs to have the date, the shelter, and the number of beds that were occupied that night. A quick sketch of a dataset that would work is shown in Figure Figure 1.\n\n\n\n\n\n\nFigure 1: Quick sketch of a dataset\n\n\n\nWe aim to create a table summarizing the monthly average number of beds occupied each night. A sketch of such a table is shown in Figure Figure 2.\n\n\n\n\n\n\nFigure 2: Quick sketch of a table\n\n\n\nThese sketches provide a conceptual understanding of the expected output and guide the workflow. First, we simulate data to refine our understanding of the data-generating process."
  },
  {
    "objectID": "lectures/lecture-04-notes.html#simulate",
    "href": "lectures/lecture-04-notes.html#simulate",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.3 Simulate",
    "text": "1.3 Simulate\nSimulation is a crucial step for understanding the problem before analyzing real data. It allows us to:\n\nDefine assumptions about the data.\nCreate a test dataset that mimics the real dataset’s structure.\n\nHere, we simulate a dataset representing the daily occupancy of three shelters over one year (2021):\n\nset.seed(853)\n\nsimulated_occupancy_data &lt;-\n    tibble(\n        date = rep(x = as.Date(\"2021-01-01\") + c(0:364), times = 3),\n        shelter = c(\n            rep(x = \"Shelter 1\", times = 365),\n            rep(x = \"Shelter 2\", times = 365),\n            rep(x = \"Shelter 3\", times = 365)\n        ),\n        number_occupied =\n            rpois(\n                n = 365 * 3,\n                lambda = 30\n            )\n    )\n\nsimulated_occupancy_data\n\n# A tibble: 1,095 × 3\n   date       shelter   number_occupied\n   &lt;date&gt;     &lt;chr&gt;               &lt;int&gt;\n 1 2021-01-01 Shelter 1              28\n 2 2021-01-02 Shelter 1              29\n 3 2021-01-03 Shelter 1              35\n 4 2021-01-04 Shelter 1              25\n 5 2021-01-05 Shelter 1              21\n 6 2021-01-06 Shelter 1              30\n 7 2021-01-07 Shelter 1              28\n 8 2021-01-08 Shelter 1              31\n 9 2021-01-09 Shelter 1              27\n10 2021-01-10 Shelter 1              27\n# ℹ 1,085 more rows\n\n\n\n1.3.1 Code Breakdown:\n\nset.seed(853): Ensures reproducibility of random numbers.\ndate column:\n\nas.Date(\"2021-01-01\"): Creates the starting date (January 1, 2021).\n+ c(0:364): Adds consecutive days to generate a sequence for the entire year.\nrep(..., times = 3): Repeats the year-long sequence for three shelters.\n\nshelter column:\n\nCategorical variable indicating which shelter the data belongs to.\nrep(..., times = 365): Repeats the shelter name for each day of the year.\n\nnumber_occupied column:\n\nSimulated using the Poisson distribution (rpois).\nlambda = 30: Assumes an average of 30 beds occupied per shelter per day.\n\n\nThe simulated dataset has three columns:\n\ndate: The date of observation.\nshelter: The shelter’s name.\nnumber_occupied: The number of beds occupied on that date."
  },
  {
    "objectID": "lectures/lecture-04-notes.html#acquire",
    "href": "lectures/lecture-04-notes.html#acquire",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.4 Acquire",
    "text": "1.4 Acquire\nThe next step is to download and process the real dataset from Toronto’s Open Data portal.\n\ntoronto_shelters &lt;-\n    list_package_resources(\"21c83b32-d5a8-4106-a54f-010dbe49f6f2\") |&gt;\n    filter(name == \"daily-shelter-overnight-service-occupancy-capacity-2021.csv\") |&gt;\n    get_resource()\n\nwrite_csv(\n    x = toronto_shelters,\n    file = here(\"data\", \"toronto_shelters.csv\")\n)\n\n\n1.4.1 Code Breakdown:\n\nlist_package_resources():\n\nRetrieves metadata for datasets in the specified package.\nThe package ID is specific to the Toronto shelter data.\n\nfilter():\n\nExtracts the 2021 dataset by matching the dataset name.\n\nget_resource():\n\nDownloads the selected dataset.\n\nwrite_csv():\n\nSaves the dataset locally for future use.\n\n\nNext, we clean the dataset:\n\ntoronto_shelters &lt;-\n    read_csv(\n        here(\"data\", \"toronto_shelters.csv\"),\n        show_col_types = FALSE\n    )\n\nhead(toronto_shelters)\n\n# A tibble: 6 × 32\n   X_id OCCUPANCY_DATE ORGANIZATION_ID ORGANIZATION_NAME        SHELTER_ID\n  &lt;dbl&gt; &lt;chr&gt;                    &lt;dbl&gt; &lt;chr&gt;                         &lt;dbl&gt;\n1     1 21-01-01                    24 COSTI Immigrant Services         40\n2     2 21-01-01                    24 COSTI Immigrant Services         40\n3     3 21-01-01                    24 COSTI Immigrant Services         40\n4     4 21-01-01                    24 COSTI Immigrant Services         40\n5     5 21-01-01                    24 COSTI Immigrant Services         40\n6     6 21-01-01                    24 COSTI Immigrant Services         40\n# ℹ 27 more variables: SHELTER_GROUP &lt;chr&gt;, LOCATION_ID &lt;dbl&gt;,\n#   LOCATION_NAME &lt;chr&gt;, LOCATION_ADDRESS &lt;chr&gt;, LOCATION_POSTAL_CODE &lt;chr&gt;,\n#   LOCATION_CITY &lt;chr&gt;, LOCATION_PROVINCE &lt;chr&gt;, PROGRAM_ID &lt;dbl&gt;,\n#   PROGRAM_NAME &lt;chr&gt;, SECTOR &lt;chr&gt;, PROGRAM_MODEL &lt;chr&gt;,\n#   OVERNIGHT_SERVICE_TYPE &lt;chr&gt;, PROGRAM_AREA &lt;chr&gt;, SERVICE_USER_COUNT &lt;dbl&gt;,\n#   CAPACITY_TYPE &lt;chr&gt;, CAPACITY_ACTUAL_BED &lt;dbl&gt;, CAPACITY_FUNDING_BED &lt;dbl&gt;,\n#   OCCUPIED_BEDS &lt;dbl&gt;, UNOCCUPIED_BEDS &lt;dbl&gt;, UNAVAILABLE_BEDS &lt;dbl&gt;, …\n\ntoronto_shelters_clean &lt;-\n    clean_names(toronto_shelters) |&gt;\n    mutate(occupancy_date = ymd(occupancy_date)) |&gt;\n    select(occupancy_date, occupied_beds)\n\nhead(toronto_shelters_clean)\n\n# A tibble: 6 × 2\n  occupancy_date occupied_beds\n  &lt;date&gt;                 &lt;dbl&gt;\n1 2021-01-01                NA\n2 2021-01-01                NA\n3 2021-01-01                NA\n4 2021-01-01                NA\n5 2021-01-01                NA\n6 2021-01-01                 6\n\nwrite_csv(\n    x = toronto_shelters_clean,\n    file = here(\"data\", \"cleaned_toronto_shelters.csv\")\n)\n\n\n\n1.4.2 Code Breakdown:\n\nread_csv(): Reads the downloaded CSV file.\nclean_names(): Converts column names to snake_case for easier handling.\nmutate(): Converts the occupancy_date column to a date format.\nselect(): Retains only the relevant columns (occupancy_date and occupied_beds)."
  },
  {
    "objectID": "lectures/lecture-04-notes.html#exploreunderstand",
    "href": "lectures/lecture-04-notes.html#exploreunderstand",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.5 Explore/Understand",
    "text": "1.5 Explore/Understand\nThe cleaned dataset is now ready for exploration. We compute the monthly average number of occupied beds:\n\ntoronto_shelters_clean &lt;-\n    read_csv(\n        here(\"data\", \"cleaned_toronto_shelters.csv\"),\n        show_col_types = FALSE\n    )\n\n#| label: tbl-homelessoccupancyd-2\n#| tbl-cap: \"Shelter usage in Toronto in 2021\"\n\ntoronto_shelters_clean |&gt;\n    mutate(occupancy_month = month(\n        occupancy_date,\n        label = TRUE,\n        abbr = FALSE\n    )) |&gt;\n    arrange(month(occupancy_date)) |&gt;\n    drop_na(occupied_beds) |&gt;\n    summarise(\n        number_occupied = mean(occupied_beds),\n        .by = occupancy_month\n    ) |&gt;\n    kable()\n\n\n\n\noccupancy_month\nnumber_occupied\n\n\n\n\nJanuary\n28.55708\n\n\nFebruary\n27.73821\n\n\nMarch\n27.18521\n\n\nApril\n26.31561\n\n\nMay\n27.42596\n\n\nJune\n28.88300\n\n\nJuly\n29.67137\n\n\nAugust\n30.83975\n\n\nSeptember\n31.65405\n\n\nOctober\n32.32991\n\n\nNovember\n33.26980\n\n\nDecember\n33.52426\n\n\n\n\n\n\n1.5.1 Code Breakdown:\n\nmutate():\n\nAdds a new column, occupancy_month, extracted from the occupancy_date.\nUses month() from lubridate to get the month name.\n\ndrop_na(): Removes rows with missing values in occupied_beds.\nsummarise(): Groups data by month and calculates the mean.\nkable(): Creates a neatly formatted table.\n\nThe table provides insights into monthly shelter usage."
  },
  {
    "objectID": "lectures/lecture-04-notes.html#share",
    "href": "lectures/lecture-04-notes.html#share",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.6 Share",
    "text": "1.6 Share\nThe findings are summarized in a brief report:\n\n\n\n\n\n\n“Toronto has a large unhoused population. Freezing winters mean it is critical there are enough places in shelters. We are interested to understand how usage of shelters changes in colder months, compared with warmer months.\nWe use data provided by the City of Toronto about Toronto shelter bed occupancy. Specifically, at 4 a.m. each night a count is made of the occupied beds. We are interested in averaging this over the month. We cleaned, tidied, and analyzed the dataset using the statistical programming language R as well as the tidyverse, janitor, opendatatoronto, lubridate, and knitr. We then made a table of the average number of occupied beds each night for each month.\nWe found that the daily average number of occupied beds was higher in December 2021 than July 2021, with 34 occupied beds in December, compared with 30 in July. More generally, there was a steady increase in the daily average number of occupied beds between July and December, with a slight overall increase each month.”"
  },
  {
    "objectID": "lectures/lecture-04-notes.html#share-1",
    "href": "lectures/lecture-04-notes.html#share-1",
    "title": "Data Analysis Workflow – The Firehose",
    "section": "1.7 SHARE!",
    "text": "1.7 SHARE!\nYour turn…"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": " Quantitative Research Methods",
    "section": "",
    "text": "Course Instructor John McLevey (he/him) Professor, Department of Sociology Memorial University\n\n  mclevey@mun.ca Note: I do not check or respond to email in the evenings or on weekends.\n\n\nGraduate Assistant Felix Morrow, PhD Student Department of Sociology, Memorial University fpcmorrow@mun.ca\n\nWhere is class? CP-2003 (Chemistry-Physics, Computer Lab) When is class? Tuesdays & Thursdays, 1:30 - 2:50 pm Office Hours: A4054, Tuesdays & Thursdays, 3:00 - 4:00 pm\n\nSOCI 3040, Quantitative Research Methods, will familiarize students with the procedures for understanding and conducting quantitative social science research. It will introduce students to the quantitative research process, hypothesis development and testing, and the application of appropriate tools for analyzing quantitative data. All sections of this course count towards the HSS Quantitative Reasoning Requirement (see mun.ca/hss/qr). (PR: SOCI 1000 or the former SOCI 2000)\n\n\n\n\n👋 Hello!\n\n\n\n\n\n\nThis course is built around Rohan Alexander’s (2023) Telling Stories with Data.\n\n\nThis section of SOCI 3440 is an introduction to quantitative research methods, from planning an analysis to sharing the final results. Following the workflow from Rohan Alexander’s (2023) Telling Stories with Data, you will learn how to:\n\nplan an analysis and sketch your data and endpoint\nsimulate some data to “force you into the details”\nacquire, assess, and prepare empirical data for analysis\nexplore and analyze data by creating visualizations and fitting models\nshare the results of your work with the world!\n\nYou will use this workflow in the context of learning foundational quantitative research skills, including conducting exploratory data analyses and fitting, assessing, and interpreting linear and generalized linear models. Reproducibility and research ethics are considered throughout the workflow, and the entire course.\n\n\nAbout the Instructor\nJohn McLevey (he/him) Pronounced like mic-Leave-ee\n\n\nLand Acknowledgement\nWe acknowledge that the lands on which Memorial University’s campuses are situated are in the traditional territories of diverse Indigenous groups, and we acknowledge with respect the diverse histories and cultures of the Beothuk, Mi’kmaq, Innu, and Inuit of this province.\n\n\n\n\n\nReferences\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC."
  },
  {
    "objectID": "lectures/lecture-09-content.html",
    "href": "lectures/lecture-09-content.html",
    "title": "Remember…",
    "section": "",
    "text": "Graphs are an essential component of data storytelling. They help us recognize patterns, understand distributions, and communicate findings effectively. This notebook introduces best practices for graphing in R using ggplot2 and demonstrates how summary statistics can sometimes be misleading if we do not visualize our data."
  },
  {
    "objectID": "lectures/lecture-09-content.html#learning-objectives",
    "href": "lectures/lecture-09-content.html#learning-objectives",
    "title": "Remember…",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this session, students will: - Understand the importance of graphing raw data before relying on summary statistics. - Learn to use ggplot2 for scatterplots, bar charts, line plots, and faceted plots. - Explore different themes, color palettes, and aesthetic modifications. - Apply these techniques to real-world datasets."
  },
  {
    "objectID": "lectures/lecture-09-content.html#setup-loading-required-packages",
    "href": "lectures/lecture-09-content.html#setup-loading-required-packages",
    "title": "Remember…",
    "section": "Setup: Loading Required Packages",
    "text": "Setup: Loading Required Packages\n\n# Load necessary libraries\nlibrary(tidyverse) # Core tidyverse package for data wrangling & visualization\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(datasauRus) # Fun dataset illustrating the importance of visualization\nlibrary(ggplot2) # Graphing package\nlibrary(janitor) # Cleaning column names\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(WDI) # Accessing World Bank economic indicators\nlibrary(carData) # British Election Panel Study dataset\nlibrary(patchwork) # Combining multiple plots\nlibrary(tidygeocoder) # Geocoding support\nlibrary(tinytable) # Nice formatted tables\n\n# Set theme for all plots\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "lectures/lecture-09-content.html#why-graphing-your-data-is-important",
    "href": "lectures/lecture-09-content.html#why-graphing-your-data-is-important",
    "title": "Remember…",
    "section": "Why Graphing Your Data is Important",
    "text": "Why Graphing Your Data is Important\n\nExample 1: The Datasaurus Dozen\nThe datasaurus_dozen dataset illustrates why we should always plot our data instead of relying solely on summary statistics.\n\n# Display the dataset\ndatasaurus_dozen\n\n# A tibble: 1,846 × 3\n   dataset     x     y\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 dino     55.4  97.2\n 2 dino     51.5  96.0\n 3 dino     46.2  94.5\n 4 dino     42.8  91.4\n 5 dino     40.8  88.3\n 6 dino     38.7  84.9\n 7 dino     35.6  79.9\n 8 dino     33.1  77.6\n 9 dino     29.0  74.5\n10 dino     26.2  71.4\n# ℹ 1,836 more rows\n\n\nEach subset of this dataset has the same mean and standard deviation for x and y, yet their visual patterns are completely different.\n\nComputing Summary Statistics\nThis code below is a pipeline that processes the datasaurus_dozen dataset to compute and display summary statistics (mean and standard deviation) for four selected datasets: “dino”, “star”, “away”, and “bullseye”. The pipeline begins by using filter(dataset %in% c(“dino”, “star”, “away”, “bullseye”)), which subsets the data to only include these four specific datasets. The summarise() function then calculates the mean and standard deviation for both the x and y variables, applying the across() function to compute these statistics for each dataset separately. The .by = dataset argument ensures that the summary statistics are grouped by dataset, so each subset receives its own computed values.\nAfter computing the summary statistics, the code formats the output into a visually appealing table. The tt() function (from the tinytable package) is used to create a neatly formatted table, and style_tt(j = 2:5, align = “r”) aligns the numeric columns (x mean, x sd, y mean, y sd) to the right for better readability. The format_tt(digits = 1, num_fmt = “decimal”) function ensures that numerical values are displayed with one decimal place. Finally, setNames(c(“Dataset”, “x mean”, “x sd”, “y mean”, “y sd”)) renames the columns to more descriptive labels for clarity. This pipeline efficiently extracts, summarizes, and presents key statistical insights from the datasaurus_dozen dataset while emphasizing the importance of looking beyond summary statistics to understand data distributions visually.\n\ndatasaurus_dozen |&gt;\n    filter(dataset %in% c(\"dino\", \"star\", \"away\", \"bullseye\")) |&gt;\n    summarise(\n        across(c(x, y), list(mean = mean, sd = sd)),\n        .by = dataset\n    ) |&gt;\n    tt() |&gt;\n    style_tt(j = 2:5, align = \"r\") |&gt;\n    format_tt(digits = 1, num_fmt = \"decimal\") |&gt;\n    setNames(c(\"Dataset\", \"x mean\", \"x sd\", \"y mean\", \"y sd\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Dataset\n                x mean\n                x sd\n                y mean\n                y sd\n              \n        \n        \n        \n                \n                  dino\n                  54.3\n                  16.8\n                  47.8\n                  26.9\n                \n                \n                  away\n                  54.3\n                  16.8\n                  47.8\n                  26.9\n                \n                \n                  star\n                  54.3\n                  16.8\n                  47.8\n                  26.9\n                \n                \n                  bullseye\n                  54.3\n                  16.8\n                  47.8\n                  26.9\n                \n        \n      \n    \n\n\n\n👉 Key Takeaway: These datasets appear identical in summary statistics, but let’s plot them.\nRecall that the mean, or average, is a measure of central tendency that represents the typical value in a dataset. It is calculated by adding up all the values and dividing by the total number of values. The mean gives us a sense of where most of the data points are centered. The standard deviation measures how spread out the values are from the mean. If the standard deviation is small, most values are close to the mean; if it’s large, the values are more spread out.\nIn short:\n\nlow standard deviation = data points are close together\nhigh standard deviation = data points are more spread out\n\nThese concepts help us understand how typical or how varied our data is.\n\n\nVisualizing the Datasaurus Dozen\n\n# Plot the datasets\ndatasaurus_dozen |&gt;\n    filter(dataset %in% c(\"dino\", \"star\", \"away\", \"bullseye\")) |&gt;\n    ggplot(aes(x = x, y = y, colour = dataset)) +\n    geom_point() +\n    facet_wrap(vars(dataset), nrow = 2, ncol = 2) +\n    labs(color = \"Dataset\")\n\n\n\n\n\n\n\n\n👉 Observation: Despite having identical summary statistics, each dataset has a distinct shape!\n\n\n\nExample 2: Anscombe’s Quartet\nFrank Anscombe developed Anscombe’s Quartet to highlight the same issue.\n\nhead(anscombe)\n\n  x1 x2 x3 x4   y1   y2    y3   y4\n1 10 10 10  8 8.04 9.14  7.46 6.58\n2  8  8  8  8 6.95 8.14  6.77 5.76\n3 13 13 13  8 7.58 8.74 12.74 7.71\n4  9  9  9  8 8.81 8.77  7.11 8.84\n5 11 11 11  8 8.33 9.26  7.81 8.47\n6 14 14 14  8 9.96 8.10  8.84 7.04\n\n\nThis dataset contains four sets of (x, y) values that share identical means, variances, and regression lines.\n\nTidying the Data\nWe use pivot_longer() to convert it into tidy format.\n\ntidy_anscombe &lt;- anscombe |&gt; pivot_longer(\n    everything(),\n    names_to = c(\".value\", \"set\"),\n    names_pattern = \"(.)(.)\"\n)\ntidy_anscombe\n\n# A tibble: 44 × 3\n   set       x     y\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 1        10  8.04\n 2 2        10  9.14\n 3 3        10  7.46\n 4 4         8  6.58\n 5 1         8  6.95\n 6 2         8  8.14\n 7 3         8  6.77\n 8 4         8  5.76\n 9 1        13  7.58\n10 2        13  8.74\n# ℹ 34 more rows\n\n\nThis code reshapes the anscombe dataset into a tidy format using the pivot_longer() function. The tidy format (or tidy data) is a structured way of organizing data where each row represents an observation, each column represents a variable, and each cell contains a single value. This format, introduced by Hadley Wickham, makes data easier to manipulate, visualize, and analyze using tools like ggplot2 and dplyr. For example, in a non-tidy format, you might have separate columns for x1, y1, x2, y2, etc. (like in Anscombe’s Quartet). In a tidy format, you would restructure the data so that there are only three columns: set (indicating the dataset), x, and y, with each row representing one observation. Tidy data is particularly useful because it works seamlessly with the tidyverse, allowing for easier grouping, filtering, summarizing, and plotting.\nThe everything() argument ensures that all columns in the dataset are transformed. The names_to = c(“.value”, “set”) argument tells pivot_longer() to split the original column names into two parts: one representing the variable (x or y) and the other representing the dataset number (1, 2, 3, or 4). The names_pattern = “(.)(.)” uses regular expressions to separate column names based on their structure (e.g., x1, y1 → x, y for dataset 1). As a result, the tidy_anscombe dataset now has three columns: set (identifying the dataset number), x (the independent variable), and y (the dependent variable). This transformation makes the data more structured and easier to work with, particularly for grouped analysis and visualization in ggplot2.\n\n\nComputing Summary Statistics\n\ntidy_anscombe |&gt;\n    summarise(\n        across(c(x, y), list(mean = mean, sd = sd)),\n        .by = set\n    ) |&gt;\n    tt() |&gt;\n    style_tt(j = 2:5, align = \"r\") |&gt;\n    format_tt(digits = 1, num_fmt = \"decimal\") |&gt;\n    setNames(c(\"Dataset\", \"x mean\", \"x sd\", \"y mean\", \"y sd\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Dataset\n                x mean\n                x sd\n                y mean\n                y sd\n              \n        \n        \n        \n                \n                  1\n                  9\n                  3.3\n                  7.5\n                  2\n                \n                \n                  2\n                  9\n                  3.3\n                  7.5\n                  2\n                \n                \n                  3\n                  9\n                  3.3\n                  7.5\n                  2\n                \n                \n                  4\n                  9\n                  3.3\n                  7.5\n                  2\n                \n        \n      \n    \n\n\n\n\n\nVisualizing Anscombe’s Quartet\n\ntidy_anscombe |&gt;\n    ggplot(aes(x = x, y = y, colour = set)) +\n    geom_point() +\n    geom_smooth(method = lm, se = FALSE) +\n    facet_wrap(vars(set), nrow = 2, ncol = 2) +\n    labs(colour = \"Dataset\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n👉 Insight: Again, summary statistics don’t tell the full story!"
  },
  {
    "objectID": "lectures/lecture-09-content.html#bar-charts-comparing-categorical-variables",
    "href": "lectures/lecture-09-content.html#bar-charts-comparing-categorical-variables",
    "title": "Remember…",
    "section": "Bar Charts: Comparing Categorical Variables",
    "text": "Bar Charts: Comparing Categorical Variables\nWe now explore bar charts using the British Election Panel Study.\n\nLoading and Cleaning the Data\n\nbeps &lt;-\n    BEPS |&gt;\n    as_tibble() |&gt;\n    clean_names() |&gt;\n    select(age, vote, gender, political_knowledge)\n\n\n\nCreating Age Groups\n\nbeps &lt;- beps |&gt;\n    mutate(\n        age_group = case_when(\n            age &lt; 35 ~ \"&lt;35\",\n            age &lt; 50 ~ \"35-49\",\n            age &lt; 65 ~ \"50-64\",\n            age &lt; 80 ~ \"65-79\",\n            age &lt; 100 ~ \"80-99\"\n        ),\n        age_group = factor(age_group, levels = c(\"&lt;35\", \"35-49\", \"50-64\", \"65-79\", \"80-99\"))\n    )\n\n\n\nPlotting the Distribution of Age Groups\n\nbeps |&gt; ggplot(aes(x = age_group)) +\n    geom_bar() +\n    labs(x = \"Age group\", y = \"Number of respondents\")"
  },
  {
    "objectID": "lectures/lecture-09-content.html#scatterplots-exploring-relationships-between-variables",
    "href": "lectures/lecture-09-content.html#scatterplots-exploring-relationships-between-variables",
    "title": "Remember…",
    "section": "Scatterplots: Exploring Relationships Between Variables",
    "text": "Scatterplots: Exploring Relationships Between Variables\nUsing World Bank Data, we analyze GDP growth and inflation.\n\nDownloading the Data\n\nworld_bank_data &lt;- WDI(\n    indicator = c(\"FP.CPI.TOTL.ZG\", \"NY.GDP.MKTP.KD.ZG\"),\n    country = c(\"AU\", \"ET\", \"IN\", \"US\")\n) |&gt;\n    rename(inflation = FP.CPI.TOTL.ZG, gdp_growth = NY.GDP.MKTP.KD.ZG)\n\n\n\nPlotting GDP Growth vs. Inflation\n\nworld_bank_data |&gt;\n    ggplot(aes(x = gdp_growth, y = inflation, color = country)) +\n    geom_point() +\n    labs(x = \"GDP Growth\", y = \"Inflation\", color = \"Country\")\n\nWarning: Removed 9 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "lectures/lecture-09-content.html#line-plots-time-series-data",
    "href": "lectures/lecture-09-content.html#line-plots-time-series-data",
    "title": "Remember…",
    "section": "Line Plots: Time-Series Data",
    "text": "Line Plots: Time-Series Data\nLet’s analyze US GDP growth over time.\n\nworld_bank_data |&gt;\n    filter(country == \"United States\") |&gt;\n    ggplot(aes(x = year, y = gdp_growth)) +\n    geom_line() +\n    labs(x = \"Year\", y = \"GDP Growth\")\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`)."
  }
]